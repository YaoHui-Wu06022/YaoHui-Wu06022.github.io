<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>卷积神经网络 | がんばろう</title><meta name="author" content="今天睡够了吗"><meta name="copyright" content="今天睡够了吗"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="图像数据的每个样本都由一个二维像素网格组成，每个像素可能是一个或者多个数值，取决于是黑白还是彩色图像 之前仅仅通过将图像数据展平成一维向量而忽略了每个图像的空间结构信息，再将数据送入一个全连接的多层感知机中。因为这些网络特征元素的顺序是不变的，因此最优的结果是利用先验知识，即利用相近像素之间的相互关联性，从图像数据中学习得到有效的模型 **卷积神经网络(convolutional neural n">
<meta property="og:type" content="article">
<meta property="og:title" content="卷积神经网络">
<meta property="og:url" content="http://yhblogs.cn/posts/21309.html">
<meta property="og:site_name" content="がんばろう">
<meta property="og:description" content="图像数据的每个样本都由一个二维像素网格组成，每个像素可能是一个或者多个数值，取决于是黑白还是彩色图像 之前仅仅通过将图像数据展平成一维向量而忽略了每个图像的空间结构信息，再将数据送入一个全连接的多层感知机中。因为这些网络特征元素的顺序是不变的，因此最优的结果是利用先验知识，即利用相近像素之间的相互关联性，从图像数据中学习得到有效的模型 **卷积神经网络(convolutional neural n">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://wuyaohui06022.oss-cn-chengdu.aliyuncs.com/blogwebp/wallhaven-7jpjzv_1280x720.webp">
<meta property="article:published_time" content="2025-10-23T15:30:57.000Z">
<meta property="article:modified_time" content="2026-01-31T12:00:30.723Z">
<meta property="article:author" content="今天睡够了吗">
<meta property="article:tag" content="⌨️python">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://wuyaohui06022.oss-cn-chengdu.aliyuncs.com/blogwebp/wallhaven-7jpjzv_1280x720.webp"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="http://yhblogs.cn/posts/21309.html"><link rel="preconnect" href="//cdn.jsdelivr.net"><link rel="preconnect" href="//busuanzi.ibruce.info"><link rel="stylesheet" href="/css/index.css?v=4.13.0"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.5.1/css/all.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui@5.0.33/dist/fancybox/fancybox.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: {"path":"/search.xml","preload":false,"top_n_per_article":1,"unescape":false,"languages":{"hits_empty":"找不到您查询的内容：${query}","hits_stats":"共找到 ${hits} 篇文章"}},
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":300},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '天',
  dateSuffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid@4.11.1/dist/infinitegrid.min.js',
    buttonText: '加载更多'
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: true,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: '卷积神经网络',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2026-01-31 12:00:30'
}</script><script>(win=>{
      win.saveToLocal = {
        set: (key, value, ttl) => {
          if (ttl === 0) return
          const now = Date.now()
          const expiry = now + ttl * 86400000
          const item = {
            value,
            expiry
          }
          localStorage.setItem(key, JSON.stringify(item))
        },
      
        get: key => {
          const itemStr = localStorage.getItem(key)
      
          if (!itemStr) {
            return undefined
          }
          const item = JSON.parse(itemStr)
          const now = Date.now()
      
          if (now > item.expiry) {
            localStorage.removeItem(key)
            return undefined
          }
          return item.value
        }
      }
    
      win.getScript = (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        script.onerror = reject
        script.onload = script.onreadystatechange = function() {
          const loadState = this.readyState
          if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
          script.onload = script.onreadystatechange = null
          resolve()
        }

        Object.keys(attr).forEach(key => {
          script.setAttribute(key, attr[key])
        })

        document.head.appendChild(script)
      })
    
      win.getCSS = (url, id = false) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onerror = reject
        link.onload = link.onreadystatechange = function() {
          const loadState = this.readyState
          if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
          link.onload = link.onreadystatechange = null
          resolve()
        }
        document.head.appendChild(link)
      })
    
      win.activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
        if (t === 'dark') activateDarkMode()
        else if (t === 'light') activateLightMode()
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
      const detectApple = () => {
        if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
          document.documentElement.classList.add('apple')
        }
      }
      detectApple()
    })(window)</script><link rel="stylesheet" href="//at.alicdn.com/t/font_3319458_ks437t3n4r.css"><link rel="stylesheet" href="/css/modify.css"><link rel="stylesheet" href="/css/custom.css"><meta name="generator" content="Hexo 7.3.0"></head><body><div id="web_bg"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="https://wuyaohui06022.oss-cn-chengdu.aliyuncs.com/blogwebp/b_2a1aef95f351a5f7ef72eb81e6838fd6.webp" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">81</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">15</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">1</div></a></div><hr class="custom-hr"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw iconfont icon-shouye"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw iconfont icon-rili"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw iconfont icon-biaoqian"></i><span> 标签</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="not-top-img" id="page-header"><nav id="nav"><span id="blog-info"><a href="/" title="がんばろう"><img class="site-icon" src="/img/favicon.png"><span class="site-name">がんばろう</span></a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search" href="javascript:void(0);"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw iconfont icon-shouye"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw iconfont icon-rili"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw iconfont icon-biaoqian"></i><span> 标签</span></a></div></div><div id="toggle-menu"><a class="site-page" href="javascript:void(0);"><i class="fas fa-bars fa-fw"></i></a></div></div></nav></header><main class="layout" id="content-inner"><div id="post"><div id="post-info"><h1 class="post-title">卷积神经网络</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="fa-fw post-meta-icon far fa-calendar-alt"></i><span class="post-meta-label">发表于</span><time datetime="2025-10-23T15:30:57.000Z" title="发表于 2025-10-23 15:30:57">2025-10-23</time></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">字数总计:</span><span class="word-count">23.4k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>90分钟</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="卷积神经网络"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div><article class="post-content" id="article-container"><p>图像数据的每个样本都由一个二维像素网格组成，每个像素可能是一个或者多个数值，取决于是黑白还是彩色图像</p>
<p>之前仅仅通过将图像数据展平成一维向量而忽略了每个图像的空间结构信息，再将数据送入一个全连接的多层感知机中。因为这些网络特征元素的顺序是不变的，因此最优的结果是利用先验知识，即利用相近像素之间的相互关联性，从图像数据中学习得到有效的模型</p>
<p>**卷积神经网络(convolutional neural network，CNN)**是一类强大的、为处理图像数据而设计的神经网络，基于卷积神经网络架构的模型在计算机视觉领域中已经占主导地位</p>
<p>卷积神经网络需要的参数少于全连接架构的网络，而且卷积也很容易用GPU并行计算</p>
<h2 id="从全连接层到卷积"><a href="#从全连接层到卷积" class="headerlink" title="从全连接层到卷积"></a>从全连接层到卷积</h2><p>MLP适合处理那些“每个特征相互独立且无结构”的任务</p>
<p>对于表格数据，特征之间的关系往往复杂且难以事先定义，模式可能来源于任意特征的非线性交互，此时多层感知机可能是最好的选择</p>
<p>然而对于高维感知数据，这种缺少结构的网络可能会变得不实用</p>
<h3 id="不变性"><a href="#不变性" class="headerlink" title="不变性"></a>不变性</h3><p>假设想从一张图片中找到某个物体，合理的假设是：无论哪种方法找到这个物体，都应该和物体的位置无关</p>
<p>卷积神经网络(CNN)正是把这种“空间不变性”的思想系统化的模型。它能在不同位置识别出相同的特征，通过共享参数与局部感知实现高效的特征学习，用更少的参数捕捉图像中的关键信息</p>
<p>特性总结：</p>
<ol>
<li><strong>平移不变性(translation invariance)</strong>：不管检测对象出现在图像中的哪个位置，神经网络的前面几层应该对相同的图像区域具有相似的反应，即为“平移不变性”</li>
<li><strong>局部性(locality)</strong>：神经网络的前面几层应该只探索输入图像中的局部区域，而不过度在意图像中相隔较远区域的关系，这就是“局部性”原则</li>
</ol>
<h3 id="多层感知机的限制"><a href="#多层感知机的限制" class="headerlink" title="多层感知机的限制"></a>多层感知机的限制</h3><p>存在两个核心问题：</p>
<ol>
<li><strong>参数太多</strong>，容易过拟合且计算开销大</li>
<li><strong>忽略空间结构</strong>，无法捕捉局部特征的空间关系(例如邻近像素常常相关)</li>
</ol>
<h3 id="卷积"><a href="#卷积" class="headerlink" title="卷积"></a>卷积</h3><p>为了使每个隐藏神经元都能接收到每个输入像素的信息，将参数从权重矩阵替换为四阶权重张量$\mathsf{W}$，假设$\mathbf{U}$包含偏置参数，可以将全连接层形式化地表示为<br>$$<br>\begin{split}\begin{aligned} \mathbf H_{i, j} &amp;= \mathbf U_{i, j} + \sum_k \sum_l\mathsf W_{i, j, k, l}  \mathbf X_{k, l}\\ &amp;=  \mathbf U_{i, j} + \sum_a \sum_b \mathsf V_{i, j, a, b}  \mathbf X_{i+a, j+b}.\end{aligned}\end{split}<br>$$<br>从$\mathsf{W}$到$\mathsf{V}$的转换只是形式上的转换，使$k = i+a, l = j+b$</p>
<p>把输入索引从绝对坐标$(k, l)$改写成相对输出位置的位移$(a,b)$<br>$$<br>\mathsf V_{i, j, a, b} = \mathsf W_{i, j, i+a, j+b}<br>$$<br>索引$a$和$b$通过在正偏移和负偏移之间移动覆盖了整个图像</p>
<h4 id="平移不变性"><a href="#平移不变性" class="headerlink" title="平移不变性"></a>平移不变性</h4><p>检测对象在输入$\mathbf{X}$中的平移，应该仅导致隐藏表示$\mathbf{H}$中的平移，$\mathsf{V,U}$实际上不依赖于$(i, j)$的值</p>
<p>可以简化$\mathbf{H}$为<br>$$<br>\mathbf H_{i, j} = u + \sum_a\sum_b \mathbf V_{a, b} \mathbf X_{i+a, j+b}.<br>$$<br>这就是<strong>卷积(convolution)</strong></p>
<p>使用系数$\mathbf V_{a, b}$对位置$(i, j)$附近的像素$(i+a, j+b)$进行加权得到$[\mathbf{H}]_{i, j}$</p>
<p>卷积核在图像上滑动(平移)，每个位置使用同一组参数，实现<strong>权重共享(weight sharing)</strong>，保证了平移不变性</p>
<h4 id="局部性"><a href="#局部性" class="headerlink" title="局部性"></a>局部性</h4><p>不应偏离到距$(i,j)$很远的地方，在$\mid a\mid  &gt; \Delta , \mid b\mid &gt;\Delta $的范围之外可以设置$[\mathbf{V}]_{a, b} = 0$</p>
<p>可以将$\mathbf H_{i, j}$重写为<br>$$<br>\mathbf H_{i, j} = u + \sum_{a = -\Delta}^{\Delta} \sum_{b = -\Delta}^{\Delta} \mathbf V_{a, b}  \mathbf X_{i+a, j+b}.<br>$$<br>这就是<strong>卷积层(convolutional layer)</strong></p>
<p>在深度学习研究社区中$\mathbf{V}$被称为<strong>卷积核(convolution kernel)<strong>或者</strong>滤波器(filter)</strong></p>
<p>亦或简单地称之为该卷积层的权重，通常该权重是可学习的参数</p>
<h3 id="思考题"><a href="#思考题" class="headerlink" title="思考题"></a>思考题</h3><p><font color="Violetred">为什么平移不变性可能也不是好主意呢？</font></p>
<p>平移不变性关注的是特征是否出现过，而不在意它在图像中的位置</p>
<p>在图像分类等任务中非常有效，但当任务依赖精确位置或结构时，这种假设反而会成为限制</p>
<p>理想的做法不是彻底放弃平移不变性，而是在保持共享的同时引入位置信息，让模型既高效又具空间感知</p>
<h2 id="图像卷积"><a href="#图像卷积" class="headerlink" title="图像卷积"></a>图像卷积</h2><h3 id="互相关"><a href="#互相关" class="headerlink" title="互相关"></a>互相关</h3><p>在数学中，两个离散二维张量之间的“卷积”被定义为<br>$$<br>(f * g)(i, j) = \sum_a\sum_b f(a, b) g(i-a, j-b).<br>$$<br>会发现其实数学定义是需要翻转的，但是刚刚写的并没有翻转，深度学习里所谓的“卷积”其实严格意义上是<strong>互相关(cross-correlation)</strong>，它没有翻转卷积核，只是把核在输入上滑动求和</p>
<p>但人们习惯仍称它为“卷积层”，因为计算形式和思想完全一致</p>
<p>因为卷积核的宽度和高度大于1，而卷积核只与图像中每个大小完全适合的位置进行互相关运算，设输入大小为$n_h \times n_w$，卷积核大小$k_h \times k_w$，则输出大小<br>$$<br>\color{purple} (n_h-k_h+1) \times (n_w-k_w+1).<br>$$<br>在<code>corr2d</code>函数中实现如上过程，该函数接受输入张量<code>X</code>和卷积核张量<code>K</code>，并返回输出张量<code>Y</code></p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">corr2d</span>(<span class="params">X, K</span>):  <span class="comment">#@save</span></span><br><span class="line">    <span class="string">"""计算二维互相关运算"""</span></span><br><span class="line">    h, w = K.shape</span><br><span class="line">    Y = torch.zeros((X.shape[<span class="number">0</span>] - h + <span class="number">1</span>, X.shape[<span class="number">1</span>] - w + <span class="number">1</span>))</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(Y.shape[<span class="number">0</span>]):</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(Y.shape[<span class="number">1</span>]):</span><br><span class="line">            Y[i, j] = (X[i:i + h, j:j + w] * K).<span class="built_in">sum</span>()</span><br><span class="line">    <span class="keyword">return</span> Y</span><br></pre></td></tr></tbody></table></figure>

<p>测试函数：</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">X = torch.tensor([[<span class="number">0.0</span>, <span class="number">1.0</span>, <span class="number">2.0</span>], [<span class="number">3.0</span>, <span class="number">4.0</span>, <span class="number">5.0</span>], [<span class="number">6.0</span>, <span class="number">7.0</span>, <span class="number">8.0</span>]])</span><br><span class="line">K = torch.tensor([[<span class="number">0.0</span>, <span class="number">1.0</span>], [<span class="number">2.0</span>, <span class="number">3.0</span>]])</span><br><span class="line"><span class="built_in">print</span>(corr2d(X, K))</span><br></pre></td></tr></tbody></table></figure>

<figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">tensor([[19., 25.],</span><br><span class="line">        [37., 43.]])</span><br></pre></td></tr></tbody></table></figure>

<p><img src="https://wuyaohui06022.oss-cn-chengdu.aliyuncs.com/YJS1/correlation.jpg" alt="correlation"></p>
<h3 id="卷积层"><a href="#卷积层" class="headerlink" title="卷积层"></a>卷积层</h3><p>卷积层对输入和卷积核权重进行互相关运算，并在添加标量偏置之后产生输出</p>
<p>卷积层中的两个被训练的参数是卷积核权重和标量偏置，也需要随机初始化</p>
<p>基于上面定义的<code>corr2d</code>函数实现二维卷积层，在<code>__init__</code>构造函数中，将<code>weight</code>和<code>bias</code>声明为两个模型参数，前向传播函数调用<code>corr2d</code>函数并添加偏置</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Conv2D</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, kernel_size</span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        <span class="variable language_">self</span>.weight = nn.Parameter(torch.rand(kernel_size))</span><br><span class="line">        <span class="variable language_">self</span>.bias = nn.Parameter(torch.zeros(<span class="number">1</span>))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, X</span>):</span><br><span class="line">        <span class="keyword">return</span> corr2d(X, <span class="variable language_">self</span>.weight) + <span class="variable language_">self</span>.bias</span><br></pre></td></tr></tbody></table></figure>

<h3 id="目标的边缘检测"><a href="#目标的边缘检测" class="headerlink" title="目标的边缘检测"></a>目标的边缘检测</h3><p>通过找到像素变化的位置，来检测图像中不同颜色的边缘</p>
<p>构造一个6×8像素的黑白图像，中间四列为黑色(0)，周围为白色(1)</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">X = torch.ones((<span class="number">6</span>, <span class="number">8</span>))</span><br><span class="line">X[:, <span class="number">2</span>:<span class="number">6</span>] = <span class="number">0</span></span><br></pre></td></tr></tbody></table></figure>

<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">tensor([[<span class="number">1.</span>, <span class="number">1.</span>, <span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>, <span class="number">1.</span>, <span class="number">1.</span>],</span><br><span class="line">        [<span class="number">1.</span>, <span class="number">1.</span>, <span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>, <span class="number">1.</span>, <span class="number">1.</span>],</span><br><span class="line">        [<span class="number">1.</span>, <span class="number">1.</span>, <span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>, <span class="number">1.</span>, <span class="number">1.</span>],</span><br><span class="line">        [<span class="number">1.</span>, <span class="number">1.</span>, <span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>, <span class="number">1.</span>, <span class="number">1.</span>],</span><br><span class="line">        [<span class="number">1.</span>, <span class="number">1.</span>, <span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>, <span class="number">1.</span>, <span class="number">1.</span>],</span><br><span class="line">        [<span class="number">1.</span>, <span class="number">1.</span>, <span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>, <span class="number">1.</span>, <span class="number">1.</span>]])</span><br></pre></td></tr></tbody></table></figure>

<p>构造一个高度为1、宽度为2的卷积核$K$，当进行互相关运算时，如果水平相邻的两元素相同，则输出为零，否则输出为非零</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">K = torch.tensor([[<span class="number">1.0</span>, -<span class="number">1.0</span>]])</span><br></pre></td></tr></tbody></table></figure>

<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Y = corr2d(X, K)</span><br></pre></td></tr></tbody></table></figure>

<figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">tensor([[ 0.,  1.,  0.,  0.,  0., -1.,  0.],</span><br><span class="line">        [ 0.,  1.,  0.,  0.,  0., -1.,  0.],</span><br><span class="line">        [ 0.,  1.,  0.,  0.,  0., -1.,  0.],</span><br><span class="line">        [ 0.,  1.,  0.,  0.,  0., -1.,  0.],</span><br><span class="line">        [ 0.,  1.,  0.,  0.,  0., -1.,  0.],</span><br><span class="line">        [ 0.,  1.,  0.,  0.,  0., -1.,  0.]])</span><br></pre></td></tr></tbody></table></figure>

<p>发现输出很明显的边缘信息</p>
<p>现在将输入的二维图像转置，再进行如上的互相关运算</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">corr2d(X.t(), K)</span><br></pre></td></tr></tbody></table></figure>

<figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">tensor([[0., 0., 0., 0., 0.],</span><br><span class="line">        [0., 0., 0., 0., 0.],</span><br><span class="line">        [0., 0., 0., 0., 0.],</span><br><span class="line">        [0., 0., 0., 0., 0.],</span><br><span class="line">        [0., 0., 0., 0., 0.],</span><br><span class="line">        [0., 0., 0., 0., 0.],</span><br><span class="line">        [0., 0., 0., 0., 0.],</span><br><span class="line">        [0., 0., 0., 0., 0.]])</span><br></pre></td></tr></tbody></table></figure>

<p>之前检测到的垂直边缘消失了，这个卷积核<code>K</code>只可以检测垂直边缘，无法检测水平边缘</p>
<h3 id="学习卷积核"><a href="#学习卷积核" class="headerlink" title="学习卷积核"></a>学习卷积核</h3><p>如果只需寻找黑白边缘，那么[-1,1]边缘检测器足以，当有了更复杂数值的卷积核，或者连续的卷积层时，不可能手动设计滤波器</p>
<p>所以就要进入迭代学习的部分</p>
<p>先讲一下<code>nn.Conv2d</code></p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">nn.Conv2d(</span><br><span class="line">    in_channels,  <span class="comment"># 输入通道数，灰度1，彩色3</span></span><br><span class="line">    out_channels, <span class="comment"># 输出通道数，也就是卷积核数</span></span><br><span class="line">    kernel_size,  <span class="comment"># 卷积核的大小，常用(3,3)</span></span><br><span class="line">    stride=<span class="number">1</span>,     <span class="comment"># 步幅，每次滑动的步长，默认1</span></span><br><span class="line">    padding=<span class="number">0</span>,    <span class="comment"># 默认0不填充</span></span><br><span class="line">    bias=<span class="literal">True</span>,    <span class="comment"># 是否使用偏置项，默认True</span></span><br><span class="line">    padding_mode=<span class="string">'zeros'</span>  <span class="comment"># 填充方式</span></span><br><span class="line">)</span><br></pre></td></tr></tbody></table></figure>

<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 构造一个二维卷积层，它具有1个输出通道和形状为(1，2)的卷积核</span></span><br><span class="line">conv2d = nn.Conv2d(<span class="number">1</span>,<span class="number">1</span>, kernel_size=(<span class="number">1</span>,<span class="number">2</span>),bias=<span class="literal">False</span>)</span><br><span class="line"><span class="comment"># 使用四维输入和输出格式(批量大小、通道、高度、宽度)</span></span><br><span class="line">X = X.reshape((<span class="number">1</span>, <span class="number">1</span>, <span class="number">6</span>, <span class="number">8</span>))</span><br><span class="line">Y = Y.reshape((<span class="number">1</span>, <span class="number">1</span>, <span class="number">6</span>, <span class="number">7</span>))</span><br><span class="line">lr = <span class="number">3e-2</span>  <span class="comment"># 学习率</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>):</span><br><span class="line">    Y_hat = conv2d(X)</span><br><span class="line">    l = (Y_hat - Y)**<span class="number">2</span></span><br><span class="line">    conv2d.zero_grad()</span><br><span class="line">    l.<span class="built_in">sum</span>().backward()</span><br><span class="line">    <span class="comment"># 迭代卷积核</span></span><br><span class="line">    conv2d.weight.data[:] -= lr * conv2d.weight.grad</span><br><span class="line">    <span class="keyword">if</span> (i+<span class="number">1</span>)%<span class="number">2</span> == <span class="number">0</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f"epoch <span class="subst">{i+<span class="number">1</span>}</span>, loss <span class="subst">{l.<span class="built_in">sum</span>():<span class="number">.3</span>f}</span>"</span>)</span><br></pre></td></tr></tbody></table></figure>

<figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">epoch 2, loss 7.668</span><br><span class="line">epoch 4, loss 1.313</span><br><span class="line">epoch 6, loss 0.231</span><br><span class="line">epoch 8, loss 0.043</span><br><span class="line">epoch 10, loss 0.009</span><br></pre></td></tr></tbody></table></figure>

<p>在10次迭代之后，误差已经降到足够低</p>
<p>查看学习获得的卷积核权重张量</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">conv2d.weight.data.reshape(<span class="number">1</span>,<span class="number">2</span>)</span><br></pre></td></tr></tbody></table></figure>

<figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tensor([[ 0.9800, -0.9914]])</span><br></pre></td></tr></tbody></table></figure>

<p>和之前定义的基本接近</p>
<h3 id="特征映射和感受野"><a href="#特征映射和感受野" class="headerlink" title="特征映射和感受野"></a>特征映射和感受野</h3><p>输出的卷积层有时被称为<strong>特征映射(feature map)</strong>，因为它可以被视为一个输入映射到下一层的空间维度的转换器</p>
<p>在卷积神经网络中，对于某一层的任意元素$x$，其**感受野(receptive field)**是指在前向传播期间可能影响$x$计算的所有元素(来自所有先前层)</p>
<p>感受野可能大于输入的实际大小，在多层卷积网络中，感受野会随着层数的增加逐渐变大</p>
<p><img src="https://wuyaohui06022.oss-cn-chengdu.aliyuncs.com/YJS1/correlation.jpg" alt="correlation"></p>
<p>若每一层卷积核大小为 2×2，第一层输出的每个元素受输入4个像素影响，再经过一层卷积后，感受野不仅是输入的4个元素，还有最初的9个输入</p>
<p>因此随着卷积层的叠加，感受野不断扩大，使网络能够捕捉更高层次、更全局的特征</p>
<h2 id="填充和步幅"><a href="#填充和步幅" class="headerlink" title="填充和步幅"></a>填充和步幅</h2><h3 id="填充"><a href="#填充" class="headerlink" title="填充"></a>填充</h3><p>在应用了连续的卷积之后，最终得到的输出远小于输入大小，如此一来原始图像的边界丢失了许多有用信息，**填充(padding)**是解决此问题最有效的方法</p>
<p>在输入图像的边界填充元素(通常填充元素是0)</p>
<p><img src="https://wuyaohui06022.oss-cn-chengdu.aliyuncs.com/YJS1/conv-pad.jpg" alt="conv-pad"></p>
<p>通常对称填充，填充大小为$p_h=k_h-1$和$p_w=k_w-1$，使得输入和输出具有相同高度和宽度</p>
<p>卷积神经网络中卷积核的高度和宽度通常为奇数，例如1、3、5或7，选择奇数的好处是，保持空间维度的同时，在对称方向上填充的行数相同</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 为了方便起见，定义了一个计算卷积层的函数</span></span><br><span class="line"><span class="comment"># 此函数初始化卷积层权重，并对输入和输出提高和缩减相应的维数</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">comp_conv2d</span>(<span class="params">conv2d, X</span>):</span><br><span class="line">    <span class="comment"># 这里的(1，1)表示批量大小和通道数都是1</span></span><br><span class="line">    X = X.reshape((<span class="number">1</span>,<span class="number">1</span>)+X.shape)</span><br><span class="line">    Y = conv2d(X)</span><br><span class="line">    <span class="comment"># 省略前两个维度：批量大小和通道</span></span><br><span class="line">    <span class="keyword">return</span> Y.reshape(Y.shape[<span class="number">2</span>:])</span><br></pre></td></tr></tbody></table></figure>

<p>当卷积核高度宽度相同时，填充大小相同；如果不同，需要填充不同的高度和宽度</p>
<p><code>padding</code>大小为<code>(kernel_size-1)/2</code></p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">X = torch.rand(size=(<span class="number">8</span>, <span class="number">8</span>))</span><br><span class="line">conv2d = nn.Conv2d(<span class="number">1</span>, <span class="number">1</span>, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>) </span><br><span class="line"><span class="comment"># conv2d = nn.Conv2d(1, 1, kernel_size=(5, 3), padding=(2, 1))</span></span><br><span class="line">comp_conv2d(conv2d, X).shape</span><br></pre></td></tr></tbody></table></figure>

<figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.Size([8, 8])</span><br></pre></td></tr></tbody></table></figure>

<h3 id="步幅"><a href="#步幅" class="headerlink" title="步幅"></a>步幅</h3><p>在计算互相关时，卷积窗口从输入张量的左上角开始，向下、向右滑动</p>
<p>默认每次滑动一个元素，但有时候为了高效计算或是缩减采样次数，卷积窗口可以跳过中间位置，每次滑动多个元素</p>
<p>将每次滑动元素的数量称为<strong>步幅(stride)</strong></p>
<p>垂直步幅为3，水平步幅为2的二维互相关运算</p>
<p><img src="https://wuyaohui06022.oss-cn-chengdu.aliyuncs.com/YJS1/conv-stride.jpg" alt="conv-stride"></p>
<p>当垂直步幅为$s_h$，水平步幅为$s_w$时，输出形状为<br>$$<br>\color{purple}H = \lfloor \frac{n_h-k_h+p_h}{s_h}+1\rfloor \qquad W=\lfloor\frac{n_w-k_w+p_w}{s_w}+1\rfloor.<br>$$</p>
<blockquote>
<p>公式通用的，计算池化后的尺寸也是用这个</p>
</blockquote>
<p>如果设置了填充大小为$p_h=k_h-1$和$p_w=k_w-1$，简化为<br>$$<br>H = \lfloor \frac{n_h-1}{s_h}+1\rfloor \qquad W=\lfloor\frac{n_w-1}{s_w}+1\rfloor.<br>$$<br>如果<font color="DarkViolet">输入的高度和宽度可以被垂直和水平步幅整除</font>，则输出形状将为$(n_h/s_h) \times (n_w/s_w)$</p>
<p>将高度和宽度的步幅设置为2，从而将输入的高度和宽度减半</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">conv2d = nn.Conv2d(<span class="number">1</span>, <span class="number">1</span>, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>, stride=<span class="number">2</span>)</span><br><span class="line">comp_conv2d(conv2d, X).shape</span><br></pre></td></tr></tbody></table></figure>

<figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.Size([4, 4])</span><br></pre></td></tr></tbody></table></figure>

<h2 id="多输入多输出"><a href="#多输入多输出" class="headerlink" title="多输入多输出"></a>多输入多输出</h2><h3 id="多输入通道"><a href="#多输入通道" class="headerlink" title="多输入通道"></a>多输入通道</h3><p>假设输入的通道数为$c_i$，那么卷积核的输入通道数也需要为$c_i$</p>
<p>$c_i=1$时可以把卷积核看作形状为$k_h\times k_w$的二维张量</p>
<p>$c_i&gt;1$时可以得到形状为$c_i\times k_h\times k_w$的卷积核，对每个通道输入的二维张量和卷积核的二维张量进行互相关运算，再对通道求和得到二维张量</p>
<p><img src="https://wuyaohui06022.oss-cn-chengdu.aliyuncs.com/YJS1/conv-multi-in.jpg" alt="conv-multi-in"></p>
<p>函数实现</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">corr2d_multi_in</span>(<span class="params">X, K</span>):</span><br><span class="line">    <span class="comment"># 遍历累加</span></span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">sum</span>(corr2d(x, k) <span class="keyword">for</span> x, k <span class="keyword">in</span> <span class="built_in">zip</span>(X, K))</span><br></pre></td></tr></tbody></table></figure>

<p>求和代表融合后的特征，综合了所有输入通道在同一空间位置的响应</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">X = torch.tensor([[[<span class="number">0.0</span>, <span class="number">1.0</span>, <span class="number">2.0</span>], [<span class="number">3.0</span>, <span class="number">4.0</span>, <span class="number">5.0</span>], [<span class="number">6.0</span>, <span class="number">7.0</span>, <span class="number">8.0</span>]],</span><br><span class="line">               [[<span class="number">1.0</span>, <span class="number">2.0</span>, <span class="number">3.0</span>], [<span class="number">4.0</span>, <span class="number">5.0</span>, <span class="number">6.0</span>], [<span class="number">7.0</span>, <span class="number">8.0</span>, <span class="number">9.0</span>]]])</span><br><span class="line">K = torch.tensor([[[<span class="number">0.0</span>, <span class="number">1.0</span>], [<span class="number">2.0</span>, <span class="number">3.0</span>]], [[<span class="number">1.0</span>, <span class="number">2.0</span>], [<span class="number">3.0</span>, <span class="number">4.0</span>]]])</span><br><span class="line"></span><br><span class="line">corr2d_multi_in(X, K)</span><br></pre></td></tr></tbody></table></figure>

<figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">tensor([[ 56.,  72.],</span><br><span class="line">        [104., 120.]])</span><br></pre></td></tr></tbody></table></figure>

<h3 id="多输出通道"><a href="#多输出通道" class="headerlink" title="多输出通道"></a>多输出通道</h3><p>随着神经网络层数的加深，常会增加输出通道的维数，通过减少空间分辨率以获得更大的通道深度</p>
<p>即可以将每个通道看作对不同特征的响应，每个通道并不是彼此独立而是协同优化的</p>
<p>为了获得多个通道的输出，可以为每个输出通道创建一个形状为$c_i\times k_h\times k_w$的卷积核张量，卷积核的形状是$\color{red}c_o\times c_i\times k_h\times k_w$，输出$c_o$个通道</p>
<p>实现一个计算多个通道的输出的互相关函数</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">corr2d_multi_in_out</span>(<span class="params">X, K</span>):</span><br><span class="line">    <span class="keyword">return</span> torch.stack([corr2d_multi_in(X,k) <span class="keyword">for</span> k <span class="keyword">in</span> K ], <span class="number">0</span>)</span><br></pre></td></tr></tbody></table></figure>

<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">K = torch.stack((K, K + <span class="number">1</span>, K + <span class="number">2</span>), <span class="number">0</span>)</span><br><span class="line">corr2d_multi_in_out(X, K)</span><br></pre></td></tr></tbody></table></figure>

<figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">tensor([[[ 56.,  72.],</span><br><span class="line">         [104., 120.]],</span><br><span class="line"></span><br><span class="line">        [[ 76., 100.],</span><br><span class="line">         [148., 172.]],</span><br><span class="line"></span><br><span class="line">        [[ 96., 128.],</span><br><span class="line">         [192., 224.]]])</span><br></pre></td></tr></tbody></table></figure>

<p>现在的输出包含3个通道，第一个通道的结果与先前结果一致</p>
<h4 id="1×1卷积层"><a href="#1×1卷积层" class="headerlink" title="1×1卷积层"></a>1×1卷积层</h4><p>看起来似乎没有多大意义，但是可以进行通道计算，输出中的每个元素都是从输入图像中同一位置的元素的线性组合</p>
<p>可以将1×1卷积层看作在每个像素位置应用的全连接层</p>
<p>以$c_i$个输入值转换为$c_o$个输出值</p>
<p><img src="https://wuyaohui06022.oss-cn-chengdu.aliyuncs.com/YJS1/conv-1x1.jpg" alt="conv-1x1"></p>
<p>使用全连接层实现1×1卷积，需要对输入和输出形状进行调整</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">corr2d_multi_in_out_1x1</span>(<span class="params">X, K</span>):</span><br><span class="line">    c_i ,h, w = X.shape</span><br><span class="line">    c_o = K.shape[<span class="number">0</span>]</span><br><span class="line">    X = X.reshape((c_i, h*w))</span><br><span class="line">    K = K.reshape((c_o, c_i))</span><br><span class="line">    <span class="comment"># 全连接层的矩阵乘法</span></span><br><span class="line">    Y = torch.matmul(K, X)</span><br><span class="line">    <span class="keyword">return</span> Y.reshape((c_o,h,w))</span><br></pre></td></tr></tbody></table></figure>

<p>1×1 卷积没有空间移动，只在通道维度上“融合信息”</p>
<h3 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h3><ul>
<li>多输入多输出通道可以用来扩展卷积层的模型</li>
<li>当以每像素为基础应用时，1×1卷积层相当于全连接层</li>
<li>1×1卷积层通常用于调整网络层的通道数量和控制模型复杂性</li>
</ul>
<h3 id="思考题-1"><a href="#思考题-1" class="headerlink" title="思考题"></a>思考题</h3><ol>
<li><p>假设有两个卷积核大小分别为$k_1$和$k_2$(中间没有非线性激活函数)</p>
<p>两次卷积等价于一次卷积，因为卷积运算有结合律</p>
<p>等效卷积核大小为$k_1+k_2-1$</p>
<p>但一个大卷积 ≠ 任意两次小卷积，除非满足特殊可分离条件</p>
</li>
<li><p>假设输入为$c_i\times h\times w$，卷积核大小为$c_o\times c_i\times k_h\times k_w$，填充为$(p_h, p_w)$，步幅为$(s_h, s_w)$</p>
<ol>
<li><p>前向传播的计算成本(乘法和加法)是多少？</p>
<p>输出空间尺寸<br>$$<br>H = \lfloor \frac{n_h-k_h+p_h}{s_h}+1\rfloor \qquad W=\lfloor\frac{n_w-k_w+p_w}{s_w}+1\rfloor.<br>$$<br>每个输出像素是一个长度为$c_i k_hk_w$的点积<br>$$<br>\mathrm{Multi_{fwd}} = c_oHW(c_ik_h k_w) \qquad \mathrm{Add_{fwd}}= c_oHW(c_i k_hk_w-1)<br>$$<br>若有偏置，再为每个输出像素加一次加法</p>
<p>总复杂度$O(c_oHWc_ik_hk_w)$</p>
</li>
<li><p>内存占用是多少?</p>
<p>必须同时驻留输入、权重、输出(以及可选偏置)<br>$$<br>Mem_{fwd}= c_ihw+ c_oc_ik_hk_w +c_oHW +(c_o)<br>$$<br>再乘以dtype大小，$c_o$为偏置大小</p>
</li>
</ol>
</li>
<li><p>如果将输入通道和输出通道的数量加倍，计算数量会增加多少？把填充数量翻一番会怎么样？</p>
<p>计算量增加4倍；</p>
<p>填充增大导致输出空间略变大，对计算量的影响相对较小、近似线性</p>
</li>
</ol>
<h2 id="汇聚-池化"><a href="#汇聚-池化" class="headerlink" title="汇聚/池化"></a>汇聚/池化</h2><p>当处理图像时，希望逐渐降低隐藏表示的空间分辨率、聚集信息，这样随着在神经网络中层叠的上升，每个神经元对其敏感的感受野(输入)就越大</p>
<p>机器学习任务通常会跟全局图像的问题有关，所以最后一层的神经元应该对整个输入全局敏感</p>
<p>通过逐渐聚合信息，生成越来越粗糙的映射，最终实现学习全局表示的目标，同时将卷积图层的所有优势保留在中间层</p>
<p><strong>汇聚(pooling)层</strong>的目的：</p>
<ul>
<li>降低卷积层对位置的敏感性</li>
<li>降低对空间降采样表示的敏感性</li>
</ul>
<p><font color="Violetred">汇聚层做的就是池化操作</font></p>
<h3 id="汇聚层"><a href="#汇聚层" class="headerlink" title="汇聚层"></a>汇聚层</h3><p>汇聚层与卷积层相似，都通过一个固定大小的窗口在输入上滑动，并根据步幅计算输出</p>
<p>但汇聚层执行的是确定性的运算，没有可学习的参数，通常取窗口内元素的最大值或平均值，即<strong>最大汇聚(max pooling)<strong>和</strong>平均汇聚(average pooling)</strong></p>
<p><img src="https://wuyaohui06022.oss-cn-chengdu.aliyuncs.com/YJS1/pooling.jpg" alt="pooling"></p>
<blockquote>
<p>几乎不会用到最小池化，因为最小池化往往保留噪声或背景，不太有助于学习</p>
<p>Softmax软最大在性能上并没有带来显著提升，难以抵消其计算代价，并不常用</p>
</blockquote>
<p>在下面的<code>pool2d</code>函数实现汇聚层的前向传播</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">pool2d</span>(<span class="params">X, pool_size, mode=<span class="string">'max'</span></span>):</span><br><span class="line">    p_h, p_w = pool_size</span><br><span class="line">    Y = torch.zeros((X.shape[<span class="number">0</span>]-p_h+<span class="number">1</span>, X.shape[<span class="number">1</span>]-p_w+<span class="number">1</span>))</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(Y.shape[<span class="number">0</span>]):</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(Y.shape[<span class="number">1</span>]):</span><br><span class="line">            <span class="keyword">if</span> mode == <span class="string">'max'</span>:</span><br><span class="line">                Y[i, j] = X[i:i+p_h, j:j+p_w].<span class="built_in">max</span>()</span><br><span class="line">            <span class="keyword">elif</span> mode == <span class="string">'avg'</span>:</span><br><span class="line">                Y[i, j] = X[i:i+p_h, j:j+p_w].mean()</span><br><span class="line">    <span class="keyword">return</span> Y</span><br></pre></td></tr></tbody></table></figure>

<p>其实和互相关很像，但是没用到卷积核</p>
<p>输入张量<code>X</code>，验证二维最大汇聚层的输出</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">X = torch.tensor([[<span class="number">0.0</span>, <span class="number">1.0</span>, <span class="number">2.0</span>], [<span class="number">3.0</span>, <span class="number">4.0</span>, <span class="number">5.0</span>], [<span class="number">6.0</span>, <span class="number">7.0</span>, <span class="number">8.0</span>]])</span><br><span class="line"><span class="built_in">print</span>(pool2d(X, (<span class="number">2</span>, <span class="number">2</span>)))</span><br><span class="line"><span class="built_in">print</span>(pool2d(X, (<span class="number">2</span>, <span class="number">2</span>), mode=<span class="string">'avg'</span>))</span><br></pre></td></tr></tbody></table></figure>

<figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">tensor([[4., 5.],</span><br><span class="line">        [7., 8.]])</span><br><span class="line">tensor([[2., 3.],</span><br><span class="line">        [5., 6.]])        </span><br></pre></td></tr></tbody></table></figure>

<h3 id="填充和步幅-1"><a href="#填充和步幅-1" class="headerlink" title="填充和步幅"></a>填充和步幅</h3><p>与卷积层一样，汇聚层也可以改变输出形状，仍然通过填充和步幅来实现</p>
<p>首先构造了一个输入张量<code>X</code>，它有四个维度，其中样本数和通道数都是1</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">X = torch.arange(<span class="number">16</span>, dtype=torch.float32).reshape((<span class="number">1</span>, <span class="number">1</span>, <span class="number">4</span>, <span class="number">4</span>))</span><br></pre></td></tr></tbody></table></figure>

<figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">tensor([[[[ 0.,  1.,  2.,  3.],</span><br><span class="line">          [ 4.,  5.,  6.,  7.],</span><br><span class="line">          [ 8.,  9., 10., 11.],</span><br><span class="line">          [12., 13., 14., 15.]]]])</span><br></pre></td></tr></tbody></table></figure>

<p>默认情况下，深度学习框架中的步幅与汇聚窗口的大小相同</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">torch.nn.MaxPool2d(</span><br><span class="line">    kernel_size,  <span class="comment"># 池化窗口大小</span></span><br><span class="line">    stride=<span class="literal">None</span>,  <span class="comment"># 步幅，默认与 kernel_size 相同</span></span><br><span class="line">    padding=<span class="number">0</span>,    <span class="comment"># 填充</span></span><br><span class="line">    return_indices=<span class="literal">False</span>,  <span class="comment"># 是否返回最大值所在的索引，用于反池化</span></span><br><span class="line">)</span><br><span class="line"></span><br></pre></td></tr></tbody></table></figure>

<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">pool2d = nn.MaxPool2d(<span class="number">3</span>)</span><br><span class="line">pool2d(X)</span><br></pre></td></tr></tbody></table></figure>

<figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tensor([[[[10.]]]])</span><br></pre></td></tr></tbody></table></figure>

<p>填充和步幅可以手动设定</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">pool2d = nn.MaxPool2d((<span class="number">2</span>, <span class="number">3</span>), stride=(<span class="number">2</span>, <span class="number">3</span>), padding=(<span class="number">0</span>, <span class="number">1</span>))</span><br><span class="line">pool2d(X)</span><br></pre></td></tr></tbody></table></figure>

<figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">tensor([[[[ 5.,  7.],</span><br><span class="line">          [13., 15.]]]])</span><br></pre></td></tr></tbody></table></figure>

<h3 id="多个通道"><a href="#多个通道" class="headerlink" title="多个通道"></a>多个通道</h3><p>在处理多通道输入数据时，汇聚层在每个输入通道上单独运算，而不是像卷积层一样在通道上对输入进行汇总，所以汇聚层的输出通道数与输入通道数相同</p>
<p>将在通道维度上连结张量<code>X</code>和<code>X + 1</code>，以构建具有2个通道的输入</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">X1 = torch.cat((X, X + <span class="number">1</span>), <span class="number">1</span>)</span><br><span class="line">pool2d = nn.MaxPool2d(kernel_size=<span class="number">3</span>, stride=<span class="number">2</span>, padding=<span class="number">1</span>)</span><br><span class="line">pool2d(X1)</span><br></pre></td></tr></tbody></table></figure>

<p>汇聚后输出通道的数量仍然是2</p>
<figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">tensor([[[[ 5.,  7.],</span><br><span class="line">          [13., 15.]],</span><br><span class="line"></span><br><span class="line">         [[ 6.,  8.],</span><br><span class="line">          [14., 16.]]]])</span><br></pre></td></tr></tbody></table></figure>

<h3 id="小结-1"><a href="#小结-1" class="headerlink" title="小结"></a>小结</h3><ul>
<li>对于给定输入元素，最大汇聚层会输出该窗口内的最大值，平均汇聚层会输出该窗口内的平均值</li>
<li>汇聚层的主要优点之一是减轻卷积层对位置的过度敏感</li>
<li>可以指定汇聚层的填充和步幅</li>
<li>使用最大汇聚层以及大于1的步幅，可减少空间维度(如高度和宽度)</li>
<li>汇聚层的输出通道数与输入通道数相同</li>
</ul>
<h2 id="卷积神经网络-LeNet"><a href="#卷积神经网络-LeNet" class="headerlink" title="卷积神经网络(LeNet)"></a>卷积神经网络(LeNet)</h2><p>LeNet，它是最早发布的卷积神经网络之一，发布时的目的是识别图像(LeCun <em>et al.</em>, 1998)中的手写数字</p>
<p>LeNet取得了与**支持向量机(support vector machines)**性能相媲美的成果，成为监督学习的主流方法，被广泛用于自动取款机(ATM)机中，帮助识别处理支票的数字</p>
<h3 id="网络结构"><a href="#网络结构" class="headerlink" title="网络结构"></a>网络结构</h3><p>总体来看，LeNet(LeNet-5)由两个部分组成：</p>
<ul>
<li>卷积编码器：由两个卷积层组成</li>
<li>全连接层稠密块：由三个全连接层组成</li>
</ul>
<blockquote>
<p>稠密块可以理解为一组顺序堆叠的<strong>全连接层 + 激活函数</strong></p>
<p>和后面的DenseNet没有关系</p>
</blockquote>
<p>该架构如图所示</p>
<p><img src="https://wuyaohui06022.oss-cn-chengdu.aliyuncs.com/YJS1/lenet.webp" alt="lenet"></p>
<p>每个卷积块由一个使用 5×5 卷积核的卷积层、一个 sigmoid 激活函数和一个平均汇聚层组成</p>
<p><font color="Violetred">虽然 ReLU 激活函数和最大汇聚层在性能上更高效，但它们当时尚未被提出</font></p>
<p>这些层将输入映射到多个二维特征输出，并在提取特征的同时逐步增加通道数</p>
<p>第一层卷积输出6个通道，第二层卷积输出16个通道</p>
<p>汇聚操作采用2×2窗口，通过空间下采样使特征图尺寸缩小4倍，减少计算量</p>
<p>在将卷积块的输出输入至稠密块前，必须在小批量中展平每个样本，将样本从四维张量(批量、通道、高、宽)转换为二维矩阵，第一维表示样本索引，第二维为该样本的平面向量表示</p>
<p>LeNet的稠密块有三个全连接层，分别有120、84和10个输出</p>
<p>由于任务是手写数字识别，最终的 10 维输出对应于 10 个数字类别</p>
<p>只需要实例化一个<code>Sequential</code>块并将需要的层连接在一起就能实现LeNet-5</p>
<blockquote>
<p>因为用的MNIST，所以不是原版32×32，所以在第一层卷积的时候加入padding让28-&gt;32</p>
</blockquote>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">net = nn.Sequential(</span><br><span class="line">    nn.Conv2d(<span class="number">1</span>, <span class="number">6</span>, kernel_size=<span class="number">5</span>, padding=<span class="number">2</span>), nn.Sigmoid(),</span><br><span class="line">    nn.AvgPool2d(kernel_size=<span class="number">2</span>, stride=<span class="number">2</span>),</span><br><span class="line">    nn.Conv2d(<span class="number">6</span>, <span class="number">16</span>, kernel_size=<span class="number">5</span>), nn.Sigmoid(),</span><br><span class="line">    nn.AvgPool2d(kernel_size=<span class="number">2</span>, stride=<span class="number">2</span>),</span><br><span class="line">    nn.Flatten(),</span><br><span class="line">    nn.Linear(<span class="number">16</span> * <span class="number">5</span> * <span class="number">5</span>, <span class="number">120</span>), nn.Sigmoid(),</span><br><span class="line">    nn.Linear(<span class="number">120</span>, <span class="number">84</span>), nn.Sigmoid(),</span><br><span class="line">    nn.Linear(<span class="number">84</span>, <span class="number">10</span>)</span><br><span class="line">)</span><br></pre></td></tr></tbody></table></figure>

<p>对原始模型做了一点小改动，去掉了最后一层的高斯激活</p>
<p>将一个大小为28×28的单通道(黑白)图像通过LeNet，并在每一层打印输出的形状</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">X = torch.rand(size=(<span class="number">1</span>, <span class="number">1</span>, <span class="number">28</span>, <span class="number">28</span>), dtype=torch.float32)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f"<span class="subst">{<span class="string">'Layer'</span>:&lt;<span class="number">15</span>}</span><span class="subst">{<span class="string">'Output shape'</span>}</span>"</span>)  <span class="comment"># 学习利用格式化字符串"&lt;"对齐</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">'-'</span> * <span class="number">30</span>)</span><br><span class="line"><span class="keyword">for</span> layer <span class="keyword">in</span> net:</span><br><span class="line">    X = layer(X)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f"<span class="subst">{layer.__class__.__name__:&lt;<span class="number">15</span>}</span><span class="subst">{<span class="built_in">str</span>(<span class="built_in">tuple</span>(X.shape))}</span>"</span>)</span><br></pre></td></tr></tbody></table></figure>

<figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">Layer          Output shape</span><br><span class="line">------------------------------</span><br><span class="line">Conv2d         (1, 6, 28, 28)</span><br><span class="line">Sigmoid        (1, 6, 28, 28)</span><br><span class="line">AvgPool2d      (1, 6, 14, 14)</span><br><span class="line">Conv2d         (1, 16, 10, 10)</span><br><span class="line">Sigmoid        (1, 16, 10, 10)</span><br><span class="line">AvgPool2d      (1, 16, 5, 5)</span><br><span class="line">Flatten        (1, 400)</span><br><span class="line">Linear         (1, 120)</span><br><span class="line">Sigmoid        (1, 120)</span><br><span class="line">Linear         (1, 84)</span><br><span class="line">Sigmoid        (1, 84)</span><br></pre></td></tr></tbody></table></figure>

<h3 id="模型训练"><a href="#模型训练" class="headerlink" title="模型训练"></a>模型训练</h3><p>看看LeNet在Fashion-MNIST数据集上的表现</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">batch_size = <span class="number">256</span></span><br><span class="line">train_iter, test_iter = load_data_fashion_mnist(batch_size=batch_size)</span><br></pre></td></tr></tbody></table></figure>

<p>虽然卷积神经网络的参数较少，但与深度的多层感知机相比，它们的计算成本仍然很高，因为每个参数都参与更多的乘法，通过使用GPU，可以用它加快训练</p>
<p>由于完整的数据集位于内存中，因此在模型使用GPU计算数据集之前，需要将其复制到显存中</p>
<p>对之前<code>evaluate_accuracy</code>函数进行轻微的修改</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">evaluate_accuracy_gpu</span>(<span class="params">net, data_iter, device=<span class="literal">None</span></span>): <span class="comment">#@save</span></span><br><span class="line">    <span class="string">"""使用GPU计算模型在数据集上的精度"""</span></span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">isinstance</span>(net, nn.Module):</span><br><span class="line">        net.<span class="built_in">eval</span>()  <span class="comment"># 设置为评估模式</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> device:</span><br><span class="line">            device = <span class="built_in">next</span>(<span class="built_in">iter</span>(net.parameters())).device</span><br><span class="line">    <span class="comment"># 正确预测的数量，总预测的数量</span></span><br><span class="line">    metric = Accumulator(<span class="number">2</span>)</span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        <span class="keyword">for</span> X, y <span class="keyword">in</span> data_iter:</span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">isinstance</span>(X, <span class="built_in">list</span>):</span><br><span class="line">                <span class="comment"># BERT微调所需的(之后将介绍)</span></span><br><span class="line">                X = [x.to(device) <span class="keyword">for</span> x <span class="keyword">in</span> X]</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                X = X.to(device)</span><br><span class="line">            y = y.to(device)</span><br><span class="line">            metric.add(accuracy(net(X), y), y.numel())</span><br><span class="line">    <span class="keyword">return</span> metric[<span class="number">0</span>] / metric[<span class="number">1</span>]</span><br></pre></td></tr></tbody></table></figure>

<p>训练函数也有所变化，进行正向和反向传播之前，需要将每一小批量数据移动到指定的设备(例如GPU)上</p>
<p>训练函数<code>train_ch6</code>也类似于之前定义的<code>train_ch3</code>，这里用到sigmoid激活所以使用<code>Xavier</code>初始化模型参数，使用交叉熵损失函数和小批量随机梯度下降</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#@save</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">train_ch6</span>(<span class="params">net, train_iter, test_iter, num_epochs, lr, device</span>):</span><br><span class="line">    <span class="string">"""用GPU训练模型(在第六章定义)"""</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">init_weights</span>(<span class="params">m</span>):</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">isinstance</span>(m, (nn.Conv2d, nn.Linear)):</span><br><span class="line">            nn.init.xavier_uniform_(m.weight)</span><br><span class="line">    net.apply(init_weights)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">'training on'</span>, device)</span><br><span class="line">    net.to(device)</span><br><span class="line">    optimizer = torch.optim.SGD(net.parameters(), lr=lr)</span><br><span class="line">    loss = nn.CrossEntropyLoss()</span><br><span class="line">    animator = Animator(xlabel=<span class="string">'epoch'</span>, xlim=[<span class="number">1</span>, num_epochs],</span><br><span class="line">                            legend=[<span class="string">'train loss'</span>, <span class="string">'train acc'</span>, <span class="string">'test acc'</span>])</span><br><span class="line">    timer, num_batches = Timer(), <span class="built_in">len</span>(train_iter)</span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(num_epochs):</span><br><span class="line">        <span class="comment"># 训练损失之和，训练准确率之和，样本数</span></span><br><span class="line">        metric = Accumulator(<span class="number">3</span>)</span><br><span class="line">        net.train()</span><br><span class="line">        <span class="keyword">for</span> i, (X, y) <span class="keyword">in</span> <span class="built_in">enumerate</span>(train_iter):</span><br><span class="line">            timer.start()</span><br><span class="line">            optimizer.zero_grad()</span><br><span class="line">            X, y = X.to(device), y.to(device)</span><br><span class="line">            y_hat = net(X)</span><br><span class="line">            l = loss(y_hat, y)</span><br><span class="line">            l.backward()</span><br><span class="line">            optimizer.step()</span><br><span class="line">            <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">                metric.add(l * X.shape[<span class="number">0</span>], accuracy(y_hat, y), X.shape[<span class="number">0</span>])</span><br><span class="line">            timer.stop()</span><br><span class="line">            train_l = metric[<span class="number">0</span>] / metric[<span class="number">2</span>]</span><br><span class="line">            train_acc = metric[<span class="number">1</span>] / metric[<span class="number">2</span>]</span><br><span class="line">            <span class="keyword">if</span> (i + <span class="number">1</span>) % (num_batches // <span class="number">5</span>) == <span class="number">0</span> <span class="keyword">or</span> i == num_batches - <span class="number">1</span>:</span><br><span class="line">                animator.add(epoch + (i + <span class="number">1</span>) / num_batches,</span><br><span class="line">                             (train_l, train_acc, <span class="literal">None</span>))</span><br><span class="line">        test_acc = evaluate_accuracy_gpu(net, test_iter)</span><br><span class="line">        animator.add(epoch + <span class="number">1</span>, (<span class="literal">None</span>, <span class="literal">None</span>, test_acc))</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f"epoch <span class="subst">{epoch+<span class="number">1</span>}</span>, loss <span class="subst">{train_l:<span class="number">.3</span>f}</span>, acc <span class="subst">{train_acc:<span class="number">.3</span>f}</span>"</span>)</span><br><span class="line">    animator.show()</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f'loss <span class="subst">{train_l:<span class="number">.3</span>f}</span>, train acc <span class="subst">{train_acc:<span class="number">.3</span>f}</span>, '</span></span><br><span class="line">          <span class="string">f'test acc <span class="subst">{test_acc:<span class="number">.3</span>f}</span>'</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f'<span class="subst">{metric[<span class="number">2</span>] * num_epochs / timer.<span class="built_in">sum</span>():<span class="number">.1</span>f}</span> examples/sec '</span></span><br><span class="line">          <span class="string">f'on <span class="subst">{<span class="built_in">str</span>(device)}</span>'</span>)</span><br></pre></td></tr></tbody></table></figure>

<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">lr, num_epochs = <span class="number">0.9</span>, <span class="number">10</span></span><br><span class="line">train_ch6(net, train_iter, test_iter, num_epochs, lr, try_gpu())</span><br></pre></td></tr></tbody></table></figure>

<figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">training on cpu</span><br><span class="line">epoch 1, loss 2.321, acc 0.102</span><br><span class="line">epoch 2, loss 2.165, acc 0.168</span><br><span class="line">epoch 3, loss 1.031, acc 0.586</span><br><span class="line">epoch 4, loss 0.805, acc 0.686</span><br><span class="line">epoch 5, loss 0.679, acc 0.734</span><br><span class="line">epoch 6, loss 0.622, acc 0.758</span><br><span class="line">epoch 7, loss 0.575, acc 0.777</span><br><span class="line">epoch 8, loss 0.535, acc 0.793</span><br><span class="line">epoch 9, loss 0.500, acc 0.811</span><br><span class="line">epoch 10, loss 0.478, acc 0.819</span><br></pre></td></tr></tbody></table></figure>

<img src="https://wuyaohui06022.oss-cn-chengdu.aliyuncs.com/YJS1/202510232252.webp" alt="202510232252" style="zoom:80%;">

<figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">loss 0.478, train acc 0.819, test acc 0.821</span><br><span class="line">34923.8 examples/sec on cpu</span><br></pre></td></tr></tbody></table></figure>

<h3 id="模型升级"><a href="#模型升级" class="headerlink" title="模型升级"></a>模型升级</h3><p>如果想将ReLU和最大汇聚层加入其中优化，需要对结构进行一些修改</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">net = nn.Sequential(</span><br><span class="line">    nn.Conv2d(<span class="number">1</span>, <span class="number">6</span>, kernel_size=<span class="number">5</span>, padding=<span class="number">2</span>),</span><br><span class="line">    nn.ReLU(),</span><br><span class="line">    nn.MaxPool2d(<span class="number">2</span>, <span class="number">2</span>),</span><br><span class="line">    nn.Conv2d(<span class="number">6</span>, <span class="number">16</span>, kernel_size=<span class="number">5</span>),</span><br><span class="line">    nn.ReLU(),</span><br><span class="line">    nn.MaxPool2d(<span class="number">2</span>, <span class="number">2</span>),</span><br><span class="line">    nn.Flatten(),</span><br><span class="line">    nn.Linear(<span class="number">16</span> * <span class="number">5</span> * <span class="number">5</span>, <span class="number">120</span>),</span><br><span class="line">    nn.ReLU(),</span><br><span class="line">    nn.Linear(<span class="number">120</span>, <span class="number">84</span>),</span><br><span class="line">    nn.ReLU(),</span><br><span class="line">    nn.Linear(<span class="number">84</span>, <span class="number">10</span>)</span><br><span class="line">)</span><br></pre></td></tr></tbody></table></figure>

<p>同时初始化函数要修改为<code>Kaiming</code>初始化</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">init_weights</span>(<span class="params">m</span>):</span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">isinstance</span>(m, (nn.Conv2d, nn.Linear)):</span><br><span class="line">        nn.init.kaiming_uniform_(m.weight, nonlinearity=<span class="string">'relu'</span>)</span><br></pre></td></tr></tbody></table></figure>

<p>因为ReLU的梯度比较大，所以学习率不能那么大，设为0.15</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">lr, num_epochs = <span class="number">0.15</span>, <span class="number">10</span></span><br><span class="line">train_ch6(net, train_iter, test_iter, num_epochs, lr, try_gpu())</span><br></pre></td></tr></tbody></table></figure>

<figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">training on cpu</span><br><span class="line">epoch 1, loss 0.764, acc 0.724</span><br><span class="line">epoch 2, loss 0.450, acc 0.834</span><br><span class="line">epoch 3, loss 0.379, acc 0.861</span><br><span class="line">epoch 4, loss 0.343, acc 0.873</span><br><span class="line">epoch 5, loss 0.319, acc 0.881</span><br><span class="line">epoch 6, loss 0.299, acc 0.888</span><br><span class="line">epoch 7, loss 0.287, acc 0.892</span><br><span class="line">epoch 8, loss 0.277, acc 0.897</span><br><span class="line">epoch 9, loss 0.261, acc 0.902</span><br><span class="line">epoch 10, loss 0.252, acc 0.906</span><br></pre></td></tr></tbody></table></figure>

<img src="https://wuyaohui06022.oss-cn-chengdu.aliyuncs.com/YJS1/202510232335.webp" alt="202510232335" style="zoom:80%;">

<figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">loss 0.252, train acc 0.906, test acc 0.885</span><br><span class="line">33082.3 examples/sec on cpu</span><br></pre></td></tr></tbody></table></figure>

<p>可以看到准确率得到了大幅提升</p>
<h3 id="思考题-2"><a href="#思考题-2" class="headerlink" title="思考题"></a>思考题</h3><ol>
<li><p>将平均汇聚层替换为最大汇聚层，会发生什么？</p>
<p>平均汇聚会把特征“柔化”，而最大汇聚让模型更关注最突出的区域，所以输出特征图会更稀疏、更“尖锐”</p>
<p>只有最大值那一个像素会收到梯度更新，对于 LeNet 这种浅层网络来说，可能导致部分通道几乎不更新，梯度传播变稀疏</p>
<p>收敛速度可能更快，但不稳定</p>
<p>需要对应更换激活函数为ReLU才能发货最大汇聚层的优势</p>
</li>
<li><p>改进LeNet</p>
<table>
<thead>
<tr>
<th>方面</th>
<th>原始设计</th>
<th>改进方向</th>
</tr>
</thead>
<tbody><tr>
<td>激活函数</td>
<td>Sigmoid</td>
<td>改为 ReLU</td>
</tr>
<tr>
<td>池化方式</td>
<td>AvgPool</td>
<td>改为 MaxPool</td>
</tr>
<tr>
<td>卷积核大小</td>
<td>5×5</td>
<td>改为 3×3(更细特征)</td>
</tr>
<tr>
<td>输出通道数</td>
<td>6, 16</td>
<td>增大为 16, 32</td>
</tr>
<tr>
<td>卷积层数量</td>
<td>2 层</td>
<td>增加到 3 层</td>
</tr>
<tr>
<td>全连接层数量</td>
<td>3 层</td>
<td>减少到 2 层或用 Dropout 防过拟合</td>
</tr>
<tr>
<td>初始化</td>
<td>Xavier</td>
<td>改为 Kaiming</td>
</tr>
<tr>
<td>优化器</td>
<td>SGD(lr=0.9)</td>
<td>改为 Adam(lr=1e-3)</td>
</tr>
<tr>
<td>训练轮数</td>
<td>10</td>
<td>增加到 15~20</td>
</tr>
</tbody></table>
<p>基本就能实现91–93%的准确率</p>
</li>
</ol>
<h2 id="深度卷积神经网络-AlexNet"><a href="#深度卷积神经网络-AlexNet" class="headerlink" title="深度卷积神经网络(AlexNet)"></a>深度卷积神经网络(AlexNet)</h2><p>在LeNet提出后，卷积神经网络在计算机视觉和机器学习领域中很有名气，但卷积神经网络并没有主导这些领域</p>
<p>因为虽然LeNet在小数据集上取得了很好的效果，但是在更大、更真实的数据集上训练卷积神经网络的性能和可行性还有待研究</p>
<h3 id="学习表征"><a href="#学习表征" class="headerlink" title="学习表征"></a>学习表征</h3><p>在2012年前，图像特征都是机械地计算出来的，SIFT(Lowe, 2004)、SURF(Bay <em>et al.</em>, 2006)、HOG(定向梯度直方图)(Dalal and Triggs, 2005)、bags of visual words等特征提取方法占据了主导地位</p>
<p>另一组研究人员提出<strong>特征应由模型自动学习</strong>，并通过多层神经网络在不同层次提取抽象特征，在视觉任务中，底层可学习边缘、颜色和纹理等基本特征</p>
<p>这一思想在AlexNet(Krizhevsky <em>et al.</em>, 2012) 中得到突破性验证</p>
<p>AlexNet 的底层卷积核学到的模式与传统图像滤波器极为相似</p>
<p><img src="https://wuyaohui06022.oss-cn-chengdu.aliyuncs.com/YJS1/filters.webp" alt="filters"></p>
<p>AlexNet的更高层建立在这些底层表示的基础上，以表示更大的特征</p>
<p>深度卷积神经网络的突破出现在2012年，突破可归因于两个关键因素</p>
<ul>
<li>数据：10年以后数据集的规模快速扩大(ImageNet)</li>
<li>硬件：GPU并行计算实现</li>
</ul>
<h3 id="网络结构-1"><a href="#网络结构-1" class="headerlink" title="网络结构"></a>网络结构</h3><p>AlexNet和LeNet的架构非常相似，左图为LeNet结构，右图为AlexNet结构</p>
<p>图中AlexNet结构去除了原文需要两个小型GPU同时运算的设计特点</p>
<img src="https://wuyaohui06022.oss-cn-chengdu.aliyuncs.com/YJS1/alexnet.webp" alt="alexnet" style="zoom:80%;">

<p>AlexNet和LeNet的设计理念非常相似，但也存在显著差异</p>
<ol>
<li><p>AlexNet比相对LeNet要深得多，由八层组成：五个卷积层、两个全连接隐藏层和一个全连接输出层</p>
</li>
<li><p>AlexNet使用ReLU而不是sigmoid作为其激活函数</p>
<p>计算更简单，不需要幂次计算，并且避免出现初始化异常导致梯度消失的情况</p>
</li>
</ol>
<p>第一层卷积窗口的形状是11×11，这是因为ImageNet的图片是要比MNIST长宽大10倍以上，需要一个更大的卷积窗口来捕获目标；第二层的形状为5×5，其余卷积层为3×3</p>
<p>在第一层、第二层和第五层卷积层之后，加入窗口形状为3×3，步幅为2的最大汇聚层，并且卷积通道数是LeNet的10倍</p>
<p>在最后一个卷积层后有两个全连接层，分别有4096个输出，这两个巨大的全连接层拥有将近1GB的模型参数</p>
<blockquote>
<p>早期GPU内存有限，原版AlexNet采用了双数据流设计，使得每个GPU负责存储和计算模型的一半参数，现在很少需要跨GPU分解模型了</p>
</blockquote>
<p>AlexNet通过暂退法控制全连接层的模型复杂度，而LeNet只使用了权重衰减</p>
<p>为了进一步扩充数据，AlexNet在训练时增加了大量的图像增强数据，如翻转、裁切和变色，这使得模型更健壮，更大的样本量有效地减少了过拟合(以下代码中没有体现)</p>
<p>实例化一个<code>Sequential</code>块并将需要的层连接在一起实现AlexNet</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">net = nn.Sequential(</span><br><span class="line">    nn.Conv2d(<span class="number">1</span>, <span class="number">96</span>, kernel_size=<span class="number">11</span>, stride=<span class="number">4</span>, padding=<span class="number">1</span>), nn.ReLU(),</span><br><span class="line">    nn.MaxPool2d(kernel_size=<span class="number">3</span>, stride=<span class="number">2</span>),</span><br><span class="line">    <span class="comment"># 减小卷积窗口且增大输出通道数, padding保持输入输出大小一致</span></span><br><span class="line">    nn.Conv2d(<span class="number">96</span>, <span class="number">256</span>, kernel_size=<span class="number">5</span>, padding=<span class="number">2</span>), nn.ReLU(),</span><br><span class="line">    nn.MaxPool2d(kernel_size=<span class="number">3</span>, stride=<span class="number">2</span>),</span><br><span class="line">    <span class="comment"># 使用三个连续的卷积层和较小的卷积窗口</span></span><br><span class="line">    nn.Conv2d(<span class="number">256</span>, <span class="number">384</span>, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>), nn.ReLU(),</span><br><span class="line">    nn.Conv2d(<span class="number">384</span>, <span class="number">384</span>, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>), nn.ReLU(),</span><br><span class="line">    nn.Conv2d(<span class="number">384</span>, <span class="number">256</span>, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>), nn.ReLU(),</span><br><span class="line">    nn.MaxPool2d(kernel_size=<span class="number">3</span>, stride=<span class="number">2</span>),</span><br><span class="line">    nn.Flatten(),</span><br><span class="line">    <span class="comment"># 全连接层的输出数量是LeNet中的好几倍。使用dropout层来减轻过拟合</span></span><br><span class="line">    nn.Linear(<span class="number">256</span> * <span class="number">5</span> * <span class="number">5</span>, <span class="number">4096</span>), nn.ReLU(),</span><br><span class="line">    nn.Dropout(p = <span class="number">0.5</span>),</span><br><span class="line">    nn.Linear(<span class="number">4096</span>, <span class="number">4096</span>), nn.ReLU(),</span><br><span class="line">    nn.Dropout(p = <span class="number">0.5</span>),</span><br><span class="line">    <span class="comment"># 输出层，由于使用Fashion-MNIST，所以用类别数为10，而非论文中的1000</span></span><br><span class="line">    nn.Linear(<span class="number">4096</span>, <span class="number">10</span>)</span><br><span class="line">)</span><br></pre></td></tr></tbody></table></figure>

<p>构造一个高度和宽度都为224的单通道数据，来观察每一层输出的形状</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">X = torch.randn(<span class="number">1</span>, <span class="number">1</span>, <span class="number">224</span>, <span class="number">224</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f"<span class="subst">{<span class="string">'Layer'</span>:&lt;<span class="number">15</span>}</span><span class="subst">{<span class="string">'Output Shape'</span>}</span>"</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">'-'</span>*<span class="number">30</span>)</span><br><span class="line"><span class="keyword">for</span> layer <span class="keyword">in</span> net:</span><br><span class="line">    X = layer(X)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f"<span class="subst">{layer.__class__.__name__:&lt;<span class="number">15</span>}</span><span class="subst">{<span class="built_in">str</span>(<span class="built_in">tuple</span>(X.shape))}</span>"</span>)</span><br></pre></td></tr></tbody></table></figure>

<figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">Layer          Output Shape</span><br><span class="line">------------------------------</span><br><span class="line">Conv2d         (1, 96, 54, 54)</span><br><span class="line">ReLU           (1, 96, 54, 54)</span><br><span class="line">MaxPool2d      (1, 96, 26, 26)</span><br><span class="line">Conv2d         (1, 256, 26, 26)</span><br><span class="line">ReLU           (1, 256, 26, 26)</span><br><span class="line">MaxPool2d      (1, 256, 12, 12)</span><br><span class="line">Conv2d         (1, 384, 12, 12)</span><br><span class="line">ReLU           (1, 384, 12, 12)</span><br><span class="line">Conv2d         (1, 384, 12, 12)</span><br><span class="line">ReLU           (1, 384, 12, 12)</span><br><span class="line">Conv2d         (1, 256, 12, 12)</span><br><span class="line">ReLU           (1, 256, 12, 12)</span><br><span class="line">MaxPool2d      (1, 256, 5, 5)</span><br><span class="line">Flatten        (1, 6400)</span><br><span class="line">Linear         (1, 4096)</span><br><span class="line">ReLU           (1, 4096)</span><br><span class="line">Dropout        (1, 4096)</span><br><span class="line">Linear         (1, 4096)</span><br><span class="line">ReLU           (1, 4096)</span><br><span class="line">Dropout        (1, 4096)</span><br><span class="line">Linear         (1, 10)</span><br></pre></td></tr></tbody></table></figure>

<h3 id="模型训练-1"><a href="#模型训练-1" class="headerlink" title="模型训练"></a>模型训练</h3><p>原文中AlexNet是在ImageNet上进行训练的，但在这里使用的是Fashion-MNIST数据集</p>
<p>因为即使在现代GPU上，训练ImageNet模型，同时使其收敛可能需要数小时或数天的时间</p>
<p>将AlexNet直接应用于Fashion-MNIST会出现一个问题，Fashion-MNIST图像的分辨率低于ImageNet图像，在这里为了方便使用直接将MNIST图像<code>resize</code>到224×224(通常这不是一个明智的做法)</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">batch_size = <span class="number">128</span></span><br><span class="line">train_iter, test_iter = load_data_fashion_mnist(batch_size, resize=<span class="number">224</span>)</span><br></pre></td></tr></tbody></table></figure>

<p>现在AlexNet可以开始被训练了，这里的主要变化是使用更小的学习速率训练，这是因为网络更深更广、图像分辨率更高，训练卷积神经网络就更昂贵</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">lr, num_epochs = <span class="number">0.01</span>, <span class="number">10</span></span><br><span class="line">train_ch6(net, train_iter, test_iter, num_epochs, lr, try_gpu())</span><br></pre></td></tr></tbody></table></figure>

<p>到这里cpu烤不动了，得换到有GPU的电脑来跑了</p>
<figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">training on cuda:0</span><br><span class="line">epoch 1, loss 0.795, acc 0.716</span><br><span class="line">epoch 2, loss 0.483, acc 0.825</span><br><span class="line">epoch 3, loss 0.414, acc 0.851</span><br><span class="line">epoch 4, loss 0.375, acc 0.865</span><br><span class="line">epoch 5, loss 0.347, acc 0.873</span><br><span class="line">epoch 6, loss 0.328, acc 0.880</span><br><span class="line">epoch 7, loss 0.312, acc 0.885</span><br><span class="line">epoch 8, loss 0.299, acc 0.891</span><br><span class="line">epoch 9, loss 0.287, acc 0.896</span><br><span class="line">epoch 10, loss 0.275, acc 0.900</span><br></pre></td></tr></tbody></table></figure>

<img src="https://wuyaohui06022.oss-cn-chengdu.aliyuncs.com/YJS1/2025-10-24_152814_212.png" alt="2025-10-24_152814_212" style="zoom:80%;">

<figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">loss 0.275, train acc 0.900, test acc 0.899</span><br><span class="line">1432.2 examples/sec on cuda:0</span><br></pre></td></tr></tbody></table></figure>

<h3 id="小结-2"><a href="#小结-2" class="headerlink" title="小结"></a>小结</h3><ul>
<li>AlexNet的架构与LeNet相似，但使用了更多的卷积层和更多的参数来拟合大规模的ImageNet数据集</li>
<li>AlexNet已经被更有效的架构所超越，但它是从浅层网络到深层网络的关键一步</li>
<li><font color="DarkViolet">Dropout、ReLU和预处理是提升计算机视觉任务性能的其他关键步骤</font></li>
</ul>
<h3 id="思考题-3"><a href="#思考题-3" class="headerlink" title="思考题"></a>思考题</h3><p>分析了AlexNet的计算性能</p>
<ul>
<li><p>在AlexNet中主要是哪部分占用显存？</p>
<p><strong>特征图(feature maps)</strong> 和 <strong>模型参数(parameters)</strong></p>
<p>模型参数：</p>
<table>
<thead>
<tr>
<th>类型</th>
<th>层定义参数</th>
<th>输出尺寸</th>
<th>模型参数</th>
</tr>
</thead>
<tbody><tr>
<td>Conv1</td>
<td>11×11, stride=4, padding=2, out_channels=96</td>
<td>55×55×96</td>
<td>34,944</td>
</tr>
<tr>
<td>MaxPool</td>
<td>3×3, stride=2</td>
<td>27×27×96</td>
<td></td>
</tr>
<tr>
<td>Conv2</td>
<td>5×5, padding=2, out_channels=256</td>
<td>27×27×256</td>
<td>614,656</td>
</tr>
<tr>
<td>MaxPool</td>
<td>3×3, stride=2</td>
<td>13×13×256</td>
<td></td>
</tr>
<tr>
<td>Conv3</td>
<td>3×3, out_channels=384</td>
<td>13×13×384</td>
<td>885,120</td>
</tr>
<tr>
<td>Conv4</td>
<td>3×3, out_channels=384</td>
<td>13×13×384</td>
<td>1,327,488</td>
</tr>
<tr>
<td>Conv5</td>
<td>3×3, out_channels=256</td>
<td>13×13×256</td>
<td>884,992</td>
</tr>
<tr>
<td>MaxPool</td>
<td>3×3, stride=2</td>
<td>6×6×256</td>
<td></td>
</tr>
<tr>
<td>FC1</td>
<td>4096 neurons</td>
<td>-</td>
<td>37,752,832</td>
</tr>
<tr>
<td>FC2</td>
<td>4096 neurons</td>
<td>-</td>
<td>16,781,312</td>
</tr>
<tr>
<td>FC3</td>
<td>1000 neurons (ImageNet classes)</td>
<td>-</td>
<td>4,097,000</td>
</tr>
</tbody></table>
<p>卷积层的参数计算公式<br>$$<br>\mathrm{Params} = (k_h\times k_w\times C_{in})\times C_{out}+C_{out}<br>$$</p>
<table>
<thead>
<tr>
<th>模块</th>
<th>参数数量</th>
</tr>
</thead>
<tbody><tr>
<td>卷积层</td>
<td>≈ 3.75 M</td>
</tr>
<tr>
<td>全连接层</td>
<td>≈ 58.6 M</td>
</tr>
<tr>
<td>总计</td>
<td>≈ 62.3 M</td>
</tr>
</tbody></table>
</li>
<li><p>在AlexNet中主要是哪部分需要更多的计算？</p>
<p>中间到后期的卷积层</p>
<p>对于一个卷积层，乘加次数为<br>$$<br>\mathrm{MAC_s} = K_h\times K_w\times C_{in}\times H_{out}\times W_{out}\times C_{out}<br>$$</p>
<table>
<thead>
<tr>
<th>层</th>
<th>输入尺寸</th>
<th>卷积核</th>
<th>输出通道</th>
<th>输出尺寸</th>
<th>乘加次数</th>
</tr>
</thead>
<tbody><tr>
<td>Conv1</td>
<td>3×224×224</td>
<td>11×11</td>
<td>96</td>
<td>54×54</td>
<td>105M</td>
</tr>
<tr>
<td>Conv2</td>
<td>96×54×54</td>
<td>5×5</td>
<td>256</td>
<td>26×26</td>
<td>448M</td>
</tr>
<tr>
<td>Conv3</td>
<td>256×26×26</td>
<td>3×3</td>
<td>384</td>
<td>26×26</td>
<td>298M</td>
</tr>
<tr>
<td>Conv4</td>
<td>384×26×26</td>
<td>3×3</td>
<td>384</td>
<td>26×26</td>
<td>447M</td>
</tr>
<tr>
<td>Conv5</td>
<td>384×26×26</td>
<td>3×3</td>
<td>256</td>
<td>26×26</td>
<td>298M</td>
</tr>
</tbody></table>
<p>全连接层虽然参数多(占了 90% 的参数量)，但计算量反而较小</p>
<p>业内有两种说法：</p>
<ul>
<li>FLOPs 把一次乘加算 2 次运算</li>
<li>MACs 把一次乘加算 1 次运算</li>
</ul>
</li>
</ul>
<h2 id="使用块的网络-VGG"><a href="#使用块的网络-VGG" class="headerlink" title="使用块的网络(VGG)"></a>使用块的网络(VGG)</h2><p>虽然AlexNet证明深层神经网络卓有成效，但它没有提供一个通用的模板</p>
<p>与芯片设计中工程师从放置晶体管到逻辑元件再到逻辑块的过程类似，神经网络架构的设计也逐渐变得更加抽象，开始从单个神经元的角度思考问题，发展到整个层，现在又转向块，重复层的模式</p>
<p>使用块的想法首先出现在牛津大学的视觉几何组的VGG网络中</p>
<h3 id="VGG块"><a href="#VGG块" class="headerlink" title="VGG块"></a>VGG块</h3><p>经典卷积神经网络的基本组成部分是下面的这个序列：</p>
<ol>
<li>带填充以保持分辨率的卷积层</li>
<li>非线性激活函数，如ReLU</li>
<li>汇聚层，如最大汇聚层</li>
</ol>
<p>而一个VGG块与之类似，由一系列卷积层组成，后面再加上用于空间下采样的最大汇聚层</p>
<p>在最初的VGG论文中(Simonyan and Zisserman, 2014)使用了带有3×3卷积核，填充为1(保持高度和宽度)的卷积层和2×2汇聚窗口、步幅为2(每个块后分辨率减半)的最大汇聚层</p>
<p>定义一个名为<code>vgg_block</code>的函数来实现一个VGG块</p>
<p>该函数有三个参数，分别对应于卷积层的数量<code>num_convs</code>、输入通道的数量<code>in_channels</code> 和输出通道的数量<code>out_channels</code></p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">vgg_block</span>(<span class="params">num_convs, in_channels, out_channels</span>):</span><br><span class="line">    layers = []</span><br><span class="line">    <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(num_convs):</span><br><span class="line">        layers.append(nn.Conv2d(in_channels, out_channels, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>))</span><br><span class="line">        layers.append(nn.ReLU())</span><br><span class="line">        in_channels = out_channels <span class="comment"># 更新后继续输入</span></span><br><span class="line">    layers.append(nn.MaxPool2d(kernel_size=<span class="number">2</span>, stride=<span class="number">2</span>))</span><br><span class="line">    <span class="keyword">return</span> nn.Sequential(*layers) <span class="comment"># 解包列表，逐个放入</span></span><br></pre></td></tr></tbody></table></figure>

<h3 id="网络结构-2"><a href="#网络结构-2" class="headerlink" title="网络结构"></a>网络结构</h3><p>与AlexNet、LeNet一样，VGG网络可以分为两部分：第一部分主要由卷积层和汇聚层组成，第二部分由全连接层组成</p>
<img src="https://wuyaohui06022.oss-cn-chengdu.aliyuncs.com/YJS1/vgg.webp" alt="vgg" style="zoom:80%;">

<p>VGG神经网络连接几个VGG块(在<code>vgg_block</code>函数中定义)，其中有超参数变量<code>conv_arch</code></p>
<p>该变量指定了每个VGG块里卷积层个数和输出通道数，全连接模块则与AlexNet中的相同</p>
<p>原始VGG网络有5个卷积块，其中前两个块各有一个卷积层，后三个块各包含两个卷积层</p>
<p>第一个模块有64个输出通道，每个后续模块将输出通道数量翻倍，直到该数字达到512。由于该网络使用8个卷积层和3个全连接层，因此它通常被称为VGG-11</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># conv_arch 的内容为(num_convs, out_channels)，输入通道由程序逻辑推导</span></span><br><span class="line">conv_arch = ((<span class="number">1</span>, <span class="number">64</span>), (<span class="number">1</span>, <span class="number">128</span>), (<span class="number">2</span>, <span class="number">256</span>), (<span class="number">2</span>, <span class="number">512</span>), (<span class="number">2</span>, <span class="number">512</span>)) </span><br></pre></td></tr></tbody></table></figure>

<p>下面的代码实现了VGG-11，可以通过在<code>conv_arch</code>上执行for循环来简单实现</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">vgg</span>(<span class="params">conv_arch</span>):</span><br><span class="line">    conv_blks = []</span><br><span class="line">    in_channels = <span class="number">1</span></span><br><span class="line">    <span class="comment"># 卷积层部分</span></span><br><span class="line">    <span class="keyword">for</span> (num_convs, out_channels) <span class="keyword">in</span> conv_arch:</span><br><span class="line">        conv_blks.append(vgg_block(num_convs, in_channels, out_channels))</span><br><span class="line">        in_channels = out_channels</span><br><span class="line">    conv_part = nn.Sequential(*conv_blks)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 模拟前向传播计算flatten大小</span></span><br><span class="line">    X = torch.randn(<span class="number">1</span>, <span class="number">1</span>, <span class="number">224</span>, <span class="number">224</span>)</span><br><span class="line">    <span class="keyword">for</span> layer <span class="keyword">in</span> conv_part:</span><br><span class="line">        X = layer(X)</span><br><span class="line">    flatten_dim = X.numel() <span class="comment"># 计算展开维度</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> nn.Sequential(</span><br><span class="line">        conv_part, nn.Flatten(),</span><br><span class="line">        nn.Linear(flatten_dim, <span class="number">4096</span>), nn.ReLU(), nn.Dropout(<span class="number">0.5</span>),</span><br><span class="line">        nn.Linear(<span class="number">4096</span>, <span class="number">4096</span>), nn.ReLU(), nn.Dropout(<span class="number">0.5</span>),</span><br><span class="line">        nn.Linear(<span class="number">4096</span>, <span class="number">10</span>)</span><br><span class="line">    )</span><br></pre></td></tr></tbody></table></figure>

<p>构建一个高度和宽度为224的单通道数据样本，以观察每个层输出的形状</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">net = vgg(conv_arch)</span><br><span class="line">X = torch.randn(<span class="number">1</span>, <span class="number">1</span>, <span class="number">224</span>, <span class="number">224</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f"<span class="subst">{<span class="string">'Layer'</span>:&lt;<span class="number">15</span>}</span><span class="subst">{<span class="string">'Output Shape'</span>}</span>"</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">'-'</span>*<span class="number">30</span>)</span><br><span class="line"><span class="keyword">for</span> layer <span class="keyword">in</span> net:</span><br><span class="line">    <span class="comment"># 如果是卷积部分(Sequential)，继续深入打印</span></span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">isinstance</span>(layer, nn.Sequential):</span><br><span class="line">        <span class="keyword">for</span> sub_layer <span class="keyword">in</span> layer:</span><br><span class="line">            X = sub_layer(X)</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f"<span class="subst">{sub_layer.__class__.__name__:&lt;<span class="number">15</span>}</span><span class="subst">{<span class="built_in">str</span>(<span class="built_in">tuple</span>(X.shape))}</span>"</span>)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        X = layer(X)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f"<span class="subst">{layer.__class__.__name__:&lt;<span class="number">15</span>}</span><span class="subst">{<span class="built_in">str</span>(<span class="built_in">tuple</span>(X.shape))}</span>"</span>)</span><br></pre></td></tr></tbody></table></figure>

<figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">Layer          Output Shape</span><br><span class="line">------------------------------</span><br><span class="line">Sequential     (1, 64, 112, 112)</span><br><span class="line">Sequential     (1, 128, 56, 56)</span><br><span class="line">Sequential     (1, 256, 28, 28)</span><br><span class="line">Sequential     (1, 512, 14, 14)</span><br><span class="line">Sequential     (1, 512, 7, 7)</span><br><span class="line">Flatten        (1, 25088)</span><br><span class="line">Linear         (1, 4096)</span><br><span class="line">ReLU           (1, 4096)</span><br><span class="line">Dropout        (1, 4096)</span><br><span class="line">Linear         (1, 4096)</span><br><span class="line">ReLU           (1, 4096)</span><br></pre></td></tr></tbody></table></figure>

<p>正如从代码中所看到的，在每个块输出的高度和宽度减半，最终高度和宽度都为7，最后再展平表示，送入全连接层处理</p>
<p>为了方便打印，把打印封装为函数</p>
<p>如果没有遍历sub_layer会将多个卷积视为一个块，只会输出一个</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">print_net_shapes</span>(<span class="params">net, X</span>):</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f"<span class="subst">{<span class="string">'Layer'</span>:&lt;<span class="number">15</span>}</span><span class="subst">{<span class="string">'Output Shape'</span>}</span>"</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">'-'</span>*<span class="number">30</span>)</span><br><span class="line">    <span class="keyword">for</span> layer <span class="keyword">in</span> net:</span><br><span class="line">        <span class="comment"># 如果是块Sequential，继续深入再打印</span></span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">isinstance</span>(layer, nn.Sequential):</span><br><span class="line">            <span class="keyword">for</span> sub_layer <span class="keyword">in</span> layer:</span><br><span class="line">                X = sub_layer(X)</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">f"<span class="subst">{sub_layer.__class__.__name__:&lt;<span class="number">15</span>}</span><span class="subst">{<span class="built_in">str</span>(<span class="built_in">tuple</span>(X.shape))}</span>"</span>)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            X = layer(X)</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f"<span class="subst">{layer.__class__.__name__:&lt;<span class="number">15</span>}</span><span class="subst">{<span class="built_in">str</span>(<span class="built_in">tuple</span>(X.shape))}</span>"</span>)</span><br></pre></td></tr></tbody></table></figure>

<h3 id="模型训练-2"><a href="#模型训练-2" class="headerlink" title="模型训练"></a>模型训练</h3><p>由于VGG-11比AlexNet计算量更大，因此构建了一个通道数较少的网络，足够用于训练Fashion-MNIST数据集</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">ratio = <span class="number">4</span>  <span class="comment"># 减少输出通道数倍率</span></span><br><span class="line">small_conv_arch = [(pair[<span class="number">0</span>], pair[<span class="number">1</span>] // ratio) <span class="keyword">for</span> pair <span class="keyword">in</span> conv_arch]</span><br><span class="line">net = vgg(small_conv_arch)</span><br></pre></td></tr></tbody></table></figure>

<p>除了使用略高的学习率外，模型训练过程与AlexNet类似</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">lr, num_epochs, batch_size = <span class="number">0.05</span>, <span class="number">10</span>, <span class="number">128</span></span><br><span class="line">train_iter, test_iter = load_data_fashion_mnist(batch_size, resize=<span class="number">224</span>)</span><br><span class="line">train_ch6(net, train_iter, test_iter, num_epochs, lr, try_gpu())</span><br></pre></td></tr></tbody></table></figure>

<figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">epoch 1, loss 0.675, acc 0.755</span><br><span class="line">epoch 2, loss 0.353, acc 0.871</span><br><span class="line">epoch 3, loss 0.301, acc 0.890</span><br><span class="line">epoch 4, loss 0.267, acc 0.902</span><br><span class="line">epoch 5, loss 0.241, acc 0.910</span><br><span class="line">epoch 6, loss 0.221, acc 0.918</span><br><span class="line">epoch 7, loss 0.204, acc 0.925</span><br><span class="line">epoch 8, loss 0.189, acc 0.930</span><br><span class="line">epoch 9, loss 0.175, acc 0.937</span><br><span class="line">epoch 10, loss 0.163, acc 0.940</span><br></pre></td></tr></tbody></table></figure>

<img src="https://wuyaohui06022.oss-cn-chengdu.aliyuncs.com/YJS1/2025-10-24_171101_367.png" alt="2025-10-24_171101_367" style="zoom:80%;">

<figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">loss 0.163, train acc 0.940, test acc 0.928</span><br><span class="line">1030.3 examples/sec on cuda:0</span><br></pre></td></tr></tbody></table></figure>

<h3 id="小结-3"><a href="#小结-3" class="headerlink" title="小结"></a>小结</h3><ul>
<li>VGG-11使用可复用的卷积块构造网络，不同的VGG模型可通过每个块中卷积层数量和输出通道数量的差异来定义</li>
<li>块的使用导致网络定义的非常简洁，使用块可以有效地设计复杂的网络</li>
<li>在VGG论文中，他们发现<strong>深层且窄的卷积(3×3)<strong>比</strong>浅层且宽的卷积</strong>更有效</li>
</ul>
<h3 id="思考题-4"><a href="#思考题-4" class="headerlink" title="思考题"></a>思考题</h3><ol>
<li><p>与AlexNet相比，VGG的计算要慢得多，而且它还需要更多的显存。分析出现这种情况的原因</p>
<table>
<thead>
<tr>
<th>模型</th>
<th>卷积层数</th>
<th>卷积核大小</th>
<th>通道增长</th>
<th>参数量</th>
</tr>
</thead>
<tbody><tr>
<td>AlexNet</td>
<td>5 层</td>
<td>11×11, 5×5, 3×3</td>
<td>96→256→384→384→256</td>
<td>~61M</td>
</tr>
<tr>
<td>VGG-11</td>
<td>8 层</td>
<td>3×3</td>
<td>64→128→256→512→512</td>
<td>~132M</td>
</tr>
</tbody></table>
<p>VGG 的卷积层数量更多，通道数更多，参数几乎翻倍，中间特征图分辨率保持更高</p>
</li>
<li><p>尝试将Fashion-MNIST数据集图像的高度和宽度从224改为96，这对实验有什么影响</p>
<p>卷积层的输出特征图变小，全连接层输入维度随之改变，计算效率会得到提高</p>
</li>
</ol>
<h3 id="不同的VGG"><a href="#不同的VGG" class="headerlink" title="不同的VGG"></a>不同的VGG</h3><table>
<thead>
<tr>
<th>模型</th>
<th>卷积层数</th>
<th>全连接层</th>
<th>总层数(卷积+全连接)</th>
</tr>
</thead>
<tbody><tr>
<td>VGG-11 (A型)</td>
<td>8</td>
<td>3</td>
<td>11</td>
</tr>
<tr>
<td>VGG-16 (D型)</td>
<td>13</td>
<td>3</td>
<td>16</td>
</tr>
<tr>
<td>VGG-19 (E型)</td>
<td>16</td>
<td>3</td>
<td>19</td>
</tr>
</tbody></table>
<p>卷积块设计：</p>
<table>
<thead>
<tr>
<th>Block</th>
<th>输出通道</th>
<th>池化后尺寸</th>
<th>VGG-11</th>
<th>VGG-16</th>
<th>VGG-19</th>
</tr>
</thead>
<tbody><tr>
<td>1</td>
<td>64</td>
<td>112×112</td>
<td>Conv×1</td>
<td>Conv×2</td>
<td>Conv×2</td>
</tr>
<tr>
<td>2</td>
<td>128</td>
<td>56×56</td>
<td>Conv×1</td>
<td>Conv×2</td>
<td>Conv×2</td>
</tr>
<tr>
<td>3</td>
<td>256</td>
<td>28×28</td>
<td>Conv×2</td>
<td>Conv×3</td>
<td>Conv×4</td>
</tr>
<tr>
<td>4</td>
<td>512</td>
<td>14×14</td>
<td>Conv×2</td>
<td>Conv×3</td>
<td>Conv×4</td>
</tr>
<tr>
<td>5</td>
<td>512</td>
<td>7×7</td>
<td>Conv×2</td>
<td>Conv×3</td>
<td>Conv×4</td>
</tr>
</tbody></table>
<p>性能对比：</p>
<table>
<thead>
<tr>
<th>模型</th>
<th>参数量</th>
<th>GFLOPs</th>
<th>Top-5 准确率</th>
<th>特征</th>
</tr>
</thead>
<tbody><tr>
<td>VGG-11</td>
<td>≈ 133M</td>
<td>≈ 7.6</td>
<td>~89.5%</td>
<td>最浅、最快、参数最少</td>
</tr>
<tr>
<td>VGG-16</td>
<td>≈ 138M</td>
<td>≈ 15.3</td>
<td>~92.7%</td>
<td>标准版，最常用</td>
</tr>
<tr>
<td>VGG-19</td>
<td>≈ 144M</td>
<td>≈ 19.6</td>
<td>~93.0%</td>
<td>最深、最慢、参数略多</td>
</tr>
</tbody></table>
<p>VGG-16是性能与代价的最佳平衡点，从VGG-16到VGG-19精度几乎不变，但计算量大幅增加</p>
<p><font color="Violetred">所以工业界和研究中最常用的是 VGG-16</font></p>
<p>如果想要修改VGG模型，只需要修改conv_arch，以下为VGG-16结构</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">conv_arch = ((<span class="number">2</span>, <span class="number">64</span>), (<span class="number">2</span>, <span class="number">128</span>), (<span class="number">3</span>, <span class="number">256</span>), (<span class="number">3</span>, <span class="number">512</span>), (<span class="number">3</span>, <span class="number">512</span>))</span><br></pre></td></tr></tbody></table></figure>

<h2 id="网络中的网络-NiN"><a href="#网络中的网络-NiN" class="headerlink" title="网络中的网络(NiN)"></a>网络中的网络(NiN)</h2><p>LeNet、AlexNet和VGG都有一个共同的设计模式：通过一系列的卷积层与汇聚层来提取空间结构特征，然后通过全连接层对特征的表征进行处理</p>
<p>AlexNet和VGG对LeNet的改进主要在于如何扩大和加深这两个模块</p>
<p>如果在这个过程的早期使用了全连接层，可能会完全放弃表征的空间结构，NiN提供了一个非常简单的解决方案：在每个像素的通道上分别使用多层感知机(Lin <em>et al.</em>, 2013)</p>
<h3 id="NiN块"><a href="#NiN块" class="headerlink" title="NiN块"></a>NiN块</h3><p>NiN的核心思想是：在每个像素位置上应用一个1×1卷积(可视为局部全连接层)，把空间维度的每个像素当作独立样本，通道维度作为其特征进行学习</p>
<p>VGG和NiN及它们的块之间主要架构差异：</p>
<img src="https://wuyaohui06022.oss-cn-chengdu.aliyuncs.com/YJS1/nin~1.webp" alt="nin~1" style="zoom:80%;">

<p>NiN块以一个普通卷积层开始，输入输出通道数通常由用户设置，后面是两个1×1的卷积层，这两个卷积层充当带有ReLU激活函数的逐像素全连接层</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">nin_block</span>(<span class="params">in_channels, out_channels, kernel_size, stride, padding</span>):</span><br><span class="line">    <span class="keyword">return</span> nn.Sequential(</span><br><span class="line">        nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding),</span><br><span class="line">        nn.ReLU(),</span><br><span class="line">        nn.Conv2d(out_channels, out_channels, kernel_size=<span class="number">1</span>), nn.ReLU(),</span><br><span class="line">        nn.Conv2d(out_channels, out_channels, kernel_size=<span class="number">1</span>), nn.ReLU())</span><br></pre></td></tr></tbody></table></figure>

<h3 id="网络结构-3"><a href="#网络结构-3" class="headerlink" title="网络结构"></a>网络结构</h3><p>最初的NiN在AlexNet后不久提出，结构类似，仍用11×11、5×5、3×3卷积和步幅为2的3×3最大池化，输出通道数相同，主要区别在于用NiN块替代全连接层，并通过**全局平均汇聚层(global average pooling layer)**输出类别</p>
<p>NiN设计显著减少参数量，但在实际中可能会增加训练模型的时间</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">net = nn.Sequential(</span><br><span class="line">    nin_block(<span class="number">1</span>, <span class="number">96</span>, kernel_size=<span class="number">11</span>, stride=<span class="number">4</span>, padding=<span class="number">0</span>),</span><br><span class="line">    nn.MaxPool2d(<span class="number">3</span>, stride=<span class="number">2</span>),</span><br><span class="line">    nin_block(<span class="number">96</span>, <span class="number">256</span>, kernel_size=<span class="number">5</span>, stride=<span class="number">1</span>, padding=<span class="number">2</span>),</span><br><span class="line">    nn.MaxPool2d(<span class="number">3</span>, stride=<span class="number">2</span>),</span><br><span class="line">    nin_block(<span class="number">256</span>, <span class="number">384</span>, kernel_size=<span class="number">3</span>, stride=<span class="number">1</span>, padding=<span class="number">1</span>),</span><br><span class="line">    nn.MaxPool2d(<span class="number">3</span>, stride=<span class="number">2</span>),</span><br><span class="line">    nn.Dropout(<span class="number">0.5</span>),</span><br><span class="line">    <span class="comment"># 标签类别为10</span></span><br><span class="line">    nin_block(<span class="number">384</span>, <span class="number">10</span>, kernel_size=<span class="number">3</span>, stride=<span class="number">1</span>, padding=<span class="number">1</span>),</span><br><span class="line">    nn.AdaptiveAvgPool2d((<span class="number">1</span>, <span class="number">1</span>)), <span class="comment"># 对每个类别通道取平均，固定输出尺寸</span></span><br><span class="line">    <span class="comment"># 输出 [batch_size, channels, 1, 1]</span></span><br><span class="line">    nn.Flatten() <span class="comment"># 展平为[batch_size, channels]</span></span><br><span class="line">)</span><br></pre></td></tr></tbody></table></figure>

<p>创建一个数据样本来查看每个块的输出形状</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">X = torch.rand(size=(<span class="number">1</span>, <span class="number">1</span>, <span class="number">224</span>, <span class="number">224</span>))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f"<span class="subst">{<span class="string">'Layer'</span>:&lt;<span class="number">20</span>}</span><span class="subst">{<span class="string">'Output Shape'</span>}</span>"</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">'-'</span>*<span class="number">40</span>)</span><br><span class="line"><span class="keyword">for</span> layer <span class="keyword">in</span> net:</span><br><span class="line">    X = layer(X)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f"<span class="subst">{layer.__class__.__name__:&lt;<span class="number">20</span>}</span><span class="subst">{<span class="built_in">str</span>(<span class="built_in">tuple</span>(X.shape))}</span>"</span>)</span><br></pre></td></tr></tbody></table></figure>

<figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">Layer               Output Shape</span><br><span class="line">----------------------------------------</span><br><span class="line">Sequential          (1, 96, 54, 54)</span><br><span class="line">MaxPool2d           (1, 96, 26, 26)</span><br><span class="line">Sequential          (1, 256, 26, 26)</span><br><span class="line">MaxPool2d           (1, 256, 12, 12)</span><br><span class="line">Sequential          (1, 384, 12, 12)</span><br><span class="line">MaxPool2d           (1, 384, 5, 5)</span><br><span class="line">Dropout             (1, 384, 5, 5)</span><br><span class="line">Sequential          (1, 10, 5, 5)</span><br><span class="line">AdaptiveAvgPool2d   (1, 10, 1, 1)</span><br><span class="line">Flatten             (1, 10)</span><br></pre></td></tr></tbody></table></figure>

<h3 id="训练模型"><a href="#训练模型" class="headerlink" title="训练模型"></a>训练模型</h3><p>使用Fashion-MNIST来训练模型</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">lr, num_epochs, batch_size = <span class="number">0.1</span>, <span class="number">10</span>, <span class="number">128</span></span><br><span class="line">train_iter, test_iter = load_data_fashion_mnist(batch_size, resize=<span class="number">224</span>)</span><br><span class="line">train_ch6(net, train_iter, test_iter, num_epochs, lr, try_gpu())</span><br></pre></td></tr></tbody></table></figure>

<figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">epoch 1, loss 2.084, acc 0.224, time 61.468</span><br><span class="line">epoch 2, loss 1.739, acc 0.381, time 64.322</span><br><span class="line">epoch 3, loss 1.147, acc 0.614, time 71.435</span><br><span class="line">epoch 4, loss 0.797, acc 0.712, time 72.637</span><br><span class="line">epoch 5, loss 0.715, acc 0.744, time 72.469</span><br><span class="line">epoch 6, loss 0.663, acc 0.772, time 65.857</span><br><span class="line">epoch 7, loss 0.632, acc 0.788, time 65.089</span><br><span class="line">epoch 8, loss 0.626, acc 0.792, time 64.080</span><br><span class="line">epoch 9, loss 0.576, acc 0.807, time 65.202</span><br><span class="line">epoch 10, loss 0.554, acc 0.814, time 65.073</span><br></pre></td></tr></tbody></table></figure>

<img src="https://wuyaohui06022.oss-cn-chengdu.aliyuncs.com/YJS1/2025-10-24_223841_316.png" alt="2025-10-24_223841_316" style="zoom:80%;">

<figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">loss 0.554, train acc 0.814, test acc 0.787</span><br><span class="line">1250.5 examples/sec on cuda:0</span><br></pre></td></tr></tbody></table></figure>

<h3 id="小结-4"><a href="#小结-4" class="headerlink" title="小结"></a>小结</h3><ul>
<li>NiN使用由一个卷积层和多个1×1卷积层组成的块，该块可以在卷积神经网络中使用，以允许更多的每像素非线性</li>
<li>NiN去除了容易造成过拟合的全连接层，将它们替换为全局平均汇聚层(即在所有位置上进行求和)，该汇聚层通道数量为所需的输出数量</li>
<li>移除全连接层可减少过拟合，同时显著减少NiN的参数</li>
<li>虽然NiN的性能不比VGG，但它取消全连接层的思想很重要，为后来的 GoogLeNet、ResNet 等模型奠定了基础</li>
</ul>
<h3 id="思考题-5"><a href="#思考题-5" class="headerlink" title="思考题"></a>思考题</h3><ol>
<li><p>为什么NiN块中有两个1×1卷积层？</p>
<table>
<thead>
<tr>
<th>层次</th>
<th>功能</th>
<th>类比</th>
</tr>
</thead>
<tbody><tr>
<td>普通卷积</td>
<td>提取局部空间特征</td>
<td>“卷积滤波器”</td>
</tr>
<tr>
<td>第一个 1×1 卷积</td>
<td>对通道特征进行第一次变换</td>
<td>“小型全连接层”</td>
</tr>
<tr>
<td>第二个 1×1 卷积</td>
<td>进一步学习通道间非线性关系</td>
<td>“堆叠的多层感知机”</td>
</tr>
</tbody></table>
<p>第一个用于提取和压缩通道特征，第二个用于再次组合与非线性变换，增强表示能力</p>
<p>如果删除一个1×1卷积，模型仍然可以训练，但准确率通常下降，收敛更慢，并且表达能力变弱，尤其在复杂数据集上</p>
</li>
<li><p>一次性直接将384×5×5的表示缩减为10×5×5的表示会出现什么问题</p>
<p>如果直接用1×1卷积将通道数压缩到10，这会让非线性减弱，学不到高阶的通道交互，而且梯度通道太窄，容易欠拟合，将优化压力给到前面层</p>
<p>通常会导致泛化变差，准确率降低</p>
</li>
<li><p>计算NiN的资源使用情况</p>
<ul>
<li><p>参数数量</p>
<p>第一层(11×11, 1→96)参数约 11×11×1×96 = 11,616</p>
<p>第二层(5×5, 96→256)参数约 5×5×96×256 = 614,400</p>
<p>第三层(3×3, 256→384)参数约 3×3×256×384 = 884,736</p>
<p>整网加起来约 8M，比AlexNet少得多，因为少了全连接层</p>
</li>
<li><p>计算量<br>$$<br>\mathrm{MAC_s} = K_h\times K_w\times C_{in}\times H_{out}\times W_{out}\times C_{out}<br>$$<br>虽然1×1卷积核简单，但是输出通道多，计算量也不小，FLOPs约为1~1.5GFLOPs，小于VGG</p>
</li>
</ul>
</li>
</ol>
<h2 id="含并行连结的网络-GoogleNet"><a href="#含并行连结的网络-GoogleNet" class="headerlink" title="含并行连结的网络(GoogleNet)"></a>含并行连结的网络(GoogleNet)</h2><p>GoogLeNet(Szegedy <em>et al.</em>, 2015)借鉴NiN的串联结构，并在此基础上做了改进，通过组合不同大小的卷积核来解决卷积核尺寸选择问题</p>
<p>接下来实现的GoogLeNet稍微简化，省略了一些为稳定训练而添加的特殊特性，因为现在有了更好的训练方法，这些特性不是必要的</p>
<h3 id="Inception块"><a href="#Inception块" class="headerlink" title="Inception块"></a>Inception块</h3><p>在GoogLeNet中，基本的卷积块被称为<strong>Inception块(Inception block)</strong></p>
<p>这很可能得名于电影《盗梦空间》(Inception)，因为电影中的一句话“We need to go deeper”</p>
<img src="https://wuyaohui06022.oss-cn-chengdu.aliyuncs.com/YJS1/inception.jpg" alt="inception" style="zoom:80%;">

<p>Inception块由四条并行路径组成。前三条路径使用窗口大小为1×1,3×3,5×5的卷积层，从不同空间大小中提取信息；中间的两条路径在输入上执行1×1卷积，以减少通道数从而降低模型的复杂性；第四条路径使用3×3最大汇聚层，然后使用1×1卷积层来改变通道数</p>
<p><font color="DarkViolet">核心思想是同时用多尺度卷积去提取不同层次的特征，再把它们拼在一起</font></p>
<p>这四条路径都使用合适的填充来使输入与输出的高和宽一致，最后将每条线路的输出在通道维度上连结，并构成Inception块的输出</p>
<p>在Inception块中，通常调整的超参数是每层输出通道数</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Inception</span>(nn.Module):</span><br><span class="line">    <span class="comment"># c1--c4是每条路径的输出通道</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, in_channels, c1, c2, c3, c4, **kwargs</span>):</span><br><span class="line">        <span class="comment"># **kwargs接收任意额外参数，方便子类继承时继续传参</span></span><br><span class="line">        <span class="built_in">super</span>(Inception, <span class="variable language_">self</span>).__init__(**kwargs)</span><br><span class="line">        <span class="comment"># 线路1，单1×1卷积层</span></span><br><span class="line">        <span class="variable language_">self</span>.p1_1 = nn.Conv2d(in_channels, c1, kernel_size=<span class="number">1</span>)</span><br><span class="line">        <span class="comment"># 线路2，1x1卷积层后接3x3卷积层</span></span><br><span class="line">        <span class="variable language_">self</span>.p2_1 = nn.Conv2d(in_channels, c2[<span class="number">0</span>], kernel_size=<span class="number">1</span>)</span><br><span class="line">        <span class="variable language_">self</span>.p2_2 = nn.Conv2d(c2[<span class="number">0</span>], c2[<span class="number">1</span>], kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>)</span><br><span class="line">        <span class="comment"># 线路3，1x1卷积层后接5x5卷积层</span></span><br><span class="line">        <span class="variable language_">self</span>.p3_1 = nn.Conv2d(in_channels, c3[<span class="number">0</span>], kernel_size=<span class="number">1</span>)</span><br><span class="line">        <span class="variable language_">self</span>.p3_2 = nn.Conv2d(c3[<span class="number">0</span>], c3[<span class="number">1</span>], kernel_size=<span class="number">5</span>, padding=<span class="number">2</span>)</span><br><span class="line">        <span class="comment"># 线路4，3x3最大汇聚层后接1x1卷积层</span></span><br><span class="line">        <span class="variable language_">self</span>.p4_1 = nn.MaxPool2d(kernel_size=<span class="number">3</span>, stride=<span class="number">1</span>, padding=<span class="number">1</span>)</span><br><span class="line">        <span class="variable language_">self</span>.p4_2 = nn.Conv2d(in_channels, c4, kernel_size=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        p1 = F.relu(<span class="variable language_">self</span>.p1_1(x))</span><br><span class="line">        p2 = F.relu(<span class="variable language_">self</span>.p2_2(F.relu(<span class="variable language_">self</span>.p2_1(x))))</span><br><span class="line">        p3 = F.relu(<span class="variable language_">self</span>.p3_2(F.relu(<span class="variable language_">self</span>.p3_1(x))))</span><br><span class="line">        p4 = F.relu(<span class="variable language_">self</span>.p4_2(F.relu(<span class="variable language_">self</span>.p4_1(x))))</span><br><span class="line">        <span class="comment"># 在通道维度上连接输出</span></span><br><span class="line">        <span class="keyword">return</span> torch.cat((p1, p2, p3, p4), dim=<span class="number">1</span>)</span><br></pre></td></tr></tbody></table></figure>

<p>为什么GoogLeNet这个网络如此有效呢？</p>
<p>不同尺寸的卷积滤波器能捕捉图像中不同尺度的特征，小核捕捉局部细节，大核关注全局结构，从而同时学习细节与整体特征，增强了模型的表达能力</p>
<h3 id="网络结构-4"><a href="#网络结构-4" class="headerlink" title="网络结构"></a>网络结构</h3><p>GoogLeNet一共使用9个Inception块和全局平均汇聚层的堆叠来生成其估计值，Inception块之间的最大汇聚层可降低维度</p>
<p>第一个模块类似于AlexNet和LeNet，Inception块的组合从VGG继承，全局平均汇聚层从NiN继承，避免了在最后使用全连接层</p>
<img src="https://wuyaohui06022.oss-cn-chengdu.aliyuncs.com/YJS1/inception-full.jpg" alt="inception-full" style="zoom:80%;">

<p>逐一实现GoogLeNet的每个模块</p>
<p>第一模块和之前的网络相同，使用一个7×7卷积层，输出64个通道，步幅为2，填充为3</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">b1 = nn.Sequential(</span><br><span class="line">    nn.Conv2d(<span class="number">1</span>, <span class="number">64</span>, kernel_size=<span class="number">7</span>, stride=<span class="number">2</span>, padding=<span class="number">3</span>),</span><br><span class="line">    nn.ReLU(),</span><br><span class="line">    nn.MaxPool2d(kernel_size=<span class="number">3</span>, stride=<span class="number">2</span>, padding=<span class="number">1</span>)</span><br><span class="line">)</span><br></pre></td></tr></tbody></table></figure>

<p>第二模块使用两个卷积层，第一个卷积层输出64通道，第二个卷积层输出192通道</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">b2 = nn.Sequential(</span><br><span class="line">    nn.Conv2d(<span class="number">64</span>, <span class="number">64</span>, kernel_size=<span class="number">1</span>),</span><br><span class="line">    nn.ReLU(),</span><br><span class="line">    nn.Conv2d(<span class="number">64</span>, <span class="number">192</span>, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>),</span><br><span class="line">    nn.ReLU(),</span><br><span class="line">    nn.MaxPool2d(kernel_size=<span class="number">3</span>, stride=<span class="number">2</span>, padding=<span class="number">1</span>)</span><br><span class="line">)</span><br></pre></td></tr></tbody></table></figure>

<p><font color="DarkViolet">从第三模块开始有Inception块</font></p>
<p>第三模块串联两个完整的Inception块，输入通道数为192</p>
<p>第一个Inception块的输出通道数为64+128+32+32=256，四个路径的输出通道比为2:4:1:1</p>
<p>第二条和第三条路径首先将输入通道的数量分别减少为1/2(96)和1/12(16)，然后连接第二个卷积层</p>
<p>第二个Inception块将输出通道数增加到128+192+96+64=480，四个路径之间的输出通道数量比为4:6:3:2，第二条和第三条路径首先将输入通道的数量分别减少为1/2(128)和1/8(32)</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">b3 = nn.Sequential(</span><br><span class="line">    Inception(<span class="number">192</span>, <span class="number">64</span>, (<span class="number">96</span>, <span class="number">128</span>), (<span class="number">16</span>, <span class="number">32</span>), <span class="number">32</span>),</span><br><span class="line">    Inception(<span class="number">256</span>, <span class="number">128</span>, (<span class="number">128</span>, <span class="number">192</span>), (<span class="number">32</span>, <span class="number">96</span>), <span class="number">64</span>),</span><br><span class="line">    nn.MaxPool2d(kernel_size=<span class="number">3</span>, stride=<span class="number">2</span>, padding=<span class="number">1</span>)</span><br><span class="line">)</span><br></pre></td></tr></tbody></table></figure>

<p>第四模块更加复杂，它串联了5个Inception块，其输出通道数分别是192+208+48+64=512，160+224+64+64=512，128+256+64+64=512，112+288+64+64=528和256+320+128+128=832</p>
<p>路径的通道分配和第三模块类似，<font color="Violetred">含3×3卷积层的第二条路径输出最多通道，其次是仅含1×1卷积层的第一条路径，之后是含5×5卷积层的第三条路径和含3×3最大汇聚层的第四条路径</font></p>
<p>第二、第三条路径都会先按比例减小通道数，这个比例在各个Inception块中都略有不同</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">b4 = nn.Sequential(</span><br><span class="line">    Inception(<span class="number">480</span>, <span class="number">192</span>, (<span class="number">96</span>, <span class="number">208</span>), (<span class="number">16</span>, <span class="number">48</span>), <span class="number">64</span>),</span><br><span class="line">    Inception(<span class="number">512</span>, <span class="number">160</span>, (<span class="number">112</span>, <span class="number">224</span>), (<span class="number">24</span>, <span class="number">64</span>), <span class="number">64</span>),</span><br><span class="line">    Inception(<span class="number">512</span>, <span class="number">128</span>, (<span class="number">128</span>, <span class="number">256</span>), (<span class="number">24</span>, <span class="number">64</span>), <span class="number">64</span>),</span><br><span class="line">    Inception(<span class="number">512</span>, <span class="number">112</span>, (<span class="number">144</span>, <span class="number">288</span>), (<span class="number">32</span>, <span class="number">64</span>), <span class="number">64</span>),</span><br><span class="line">    Inception(<span class="number">528</span>, <span class="number">256</span>, (<span class="number">160</span>, <span class="number">320</span>), (<span class="number">32</span>, <span class="number">128</span>), <span class="number">128</span>),</span><br><span class="line">    nn.MaxPool2d(kernel_size=<span class="number">3</span>, stride=<span class="number">2</span>, padding=<span class="number">1</span>)</span><br><span class="line">)</span><br></pre></td></tr></tbody></table></figure>

<p>第五模块包含两个Inception块，输出通道数为256+320+128+128=832和384+384+128+128=1024，其中每条路径通道数的分配思路和第三、第四模块中的一致，只是在具体数值上有所不同</p>
<p>需要注意的是，第五模块的后面紧跟输出层，<font color="DarkViolet">该模块同NiN一样使用全局平均汇聚层</font>，将每个通道的高和宽变成1，最后将输出变成二维数组，再接上一个输出个数为标签类别数的全连接层</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">b5 = nn.Sequential(</span><br><span class="line">    Inception(<span class="number">832</span>, <span class="number">256</span>, (<span class="number">160</span>, <span class="number">320</span>), (<span class="number">32</span>, <span class="number">128</span>), <span class="number">128</span>),</span><br><span class="line">    Inception(<span class="number">832</span>, <span class="number">384</span>, (<span class="number">192</span>, <span class="number">384</span>), (<span class="number">48</span>, <span class="number">128</span>), <span class="number">128</span>),</span><br><span class="line">    nn.AdaptiveAvgPool2d((<span class="number">1</span>,<span class="number">1</span>)),</span><br><span class="line">    nn.Flatten()</span><br><span class="line">)</span><br><span class="line">net = nn.Sequential(b1, b2, b3, b4, b5, nn.Linear(<span class="number">1024</span>, <span class="number">10</span>))</span><br></pre></td></tr></tbody></table></figure>

<p>GoogLeNet模型的计算复杂，而且不如VGG那样便于修改通道数</p>
<p>为了使Fashion-MNIST上的训练短小精悍，将输入的高和宽从224降到96，这简化了计算</p>
<p>下面演示各个模块输出的形状变化</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">X = torch.rand(size=(<span class="number">1</span>, <span class="number">1</span>, <span class="number">96</span>, <span class="number">96</span>))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f"<span class="subst">{<span class="string">'Layer'</span>:&lt;<span class="number">20</span>}</span><span class="subst">{<span class="string">'Output Shape'</span>}</span>"</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">'-'</span>*<span class="number">40</span>)</span><br><span class="line"><span class="keyword">for</span> layer <span class="keyword">in</span> net:</span><br><span class="line">    X = layer(X)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f"<span class="subst">{layer.__class__.__name__:&lt;<span class="number">20</span>}</span><span class="subst">{<span class="built_in">str</span>(<span class="built_in">tuple</span>(X.shape))}</span>"</span>)</span><br></pre></td></tr></tbody></table></figure>

<figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">Layer               Output Shape</span><br><span class="line">----------------------------------------</span><br><span class="line">Sequential          (1, 64, 24, 24)</span><br><span class="line">Sequential          (1, 192, 12, 12)</span><br><span class="line">Sequential          (1, 480, 6, 6)</span><br><span class="line">Sequential          (1, 832, 3, 3)</span><br><span class="line">Sequential          (1, 1024)</span><br><span class="line">Linear              (1, 10)</span><br></pre></td></tr></tbody></table></figure>

<h3 id="训练模型-1"><a href="#训练模型-1" class="headerlink" title="训练模型"></a>训练模型</h3><p>在训练之前，将图片转换为96×96分辨率</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">lr, num_epochs, batch_size = <span class="number">0.01</span>, <span class="number">10</span>, <span class="number">128</span></span><br><span class="line">train_iter, test_iter = load_data_fashion_mnist(batch_size, resize=<span class="number">96</span>)</span><br><span class="line">train_ch6(net, train_iter, test_iter, num_epochs, lr, try_gpu())</span><br></pre></td></tr></tbody></table></figure>

<figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">epoch 1, loss 0.957, acc 0.650, time 42.424</span><br><span class="line">epoch 2, loss 0.507, acc 0.812, time 41.946</span><br><span class="line">epoch 3, loss 0.423, acc 0.844, time 42.178</span><br><span class="line">epoch 4, loss 0.370, acc 0.864, time 41.612</span><br><span class="line">epoch 5, loss 0.342, acc 0.875, time 44.255</span><br><span class="line">epoch 6, loss 0.317, acc 0.883, time 43.916</span><br><span class="line">epoch 7, loss 0.300, acc 0.889, time 44.202</span><br><span class="line">epoch 8, loss 0.285, acc 0.896, time 44.064</span><br><span class="line">epoch 9, loss 0.270, acc 0.900, time 43.925</span><br><span class="line">epoch 10, loss 0.260, acc 0.903, time 44.153</span><br></pre></td></tr></tbody></table></figure>

<img src="https://wuyaohui06022.oss-cn-chengdu.aliyuncs.com/YJS1/image-20251024230401380.png" alt="image-20251024230401380" style="zoom:80%;">

<figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">loss 0.260, train acc 0.903, test acc 0.878</span><br><span class="line">2036.9 examples/sec on cuda:0</span><br></pre></td></tr></tbody></table></figure>

<h3 id="小结-5"><a href="#小结-5" class="headerlink" title="小结"></a>小结</h3><ul>
<li>Inception块相当于一个有4条路径的子网络，它通过不同窗口形状的卷积层和最大汇聚层来并行抽取信息，并使用1×1卷积层减少每像素级别上的通道维数从而降低模型复杂度</li>
<li>GoogLeNet将多个设计精细的Inception块与其他层(卷积层、全连接层)串联起来，其中Inception块的通道数分配之比是在ImageNet数据集上通过大量的实验得来的</li>
<li>GoogLeNet和它的后继者们一度是ImageNet上最有效的模型之一：它以较低的计算复杂度提供了类似的测试精度</li>
</ul>
<h3 id="思考题-6"><a href="#思考题-6" class="headerlink" title="思考题"></a>思考题</h3><ol>
<li><p>使用GoogLeNet的最小图像大小是多少？</p>
<table>
<thead>
<tr>
<th>层</th>
<th>操作</th>
<th>尺寸变化</th>
<th>输出尺寸(H×W)</th>
</tr>
</thead>
<tbody><tr>
<td>输入</td>
<td>-</td>
<td>-</td>
<td>224×224</td>
</tr>
<tr>
<td>Conv1</td>
<td>7×7, stride=2, padding=3</td>
<td>↓ 一半</td>
<td>112×112</td>
</tr>
<tr>
<td>MaxPool1</td>
<td>3×3, stride=2</td>
<td>↓ 一半</td>
<td>56×56</td>
</tr>
<tr>
<td>Conv2</td>
<td>3×3, stride=1</td>
<td>保持</td>
<td>56×56</td>
</tr>
<tr>
<td>MaxPool2</td>
<td>3×3, stride=2</td>
<td>↓ 一半</td>
<td>28×28</td>
</tr>
<tr>
<td>Inception 3a+3b</td>
<td>stride=1</td>
<td>保持</td>
<td>28×28</td>
</tr>
<tr>
<td>MaxPool3</td>
<td>3×3, stride=2</td>
<td>↓ 一半</td>
<td>14×14</td>
</tr>
<tr>
<td>Inception 4a+4b</td>
<td>stride=1</td>
<td>保持</td>
<td>14×14</td>
</tr>
<tr>
<td>MaxPool4</td>
<td>3×3, stride=2</td>
<td>↓ 一半</td>
<td>7×7</td>
</tr>
<tr>
<td>Inception 5a+5b</td>
<td>stride=1</td>
<td>保持</td>
<td>7×7</td>
</tr>
<tr>
<td>Global AvgPool</td>
<td>通道合并</td>
<td></td>
<td></td>
</tr>
</tbody></table>
<p>所以在进入Global AvgPool前尺寸减少了$2^5$次，所以理论最小是32</p>
</li>
<li><p>将AlexNet、VGG和NiN的模型参数大小与GoogLeNet进行比较。后两个网络架构是如何显著减少模型参数大小的？</p>
<table>
<thead>
<tr>
<th>模型</th>
<th>参数量</th>
<th>主要节省策略</th>
<th>关键创新</th>
</tr>
</thead>
<tbody><tr>
<td>AlexNet(2012)</td>
<td>60M</td>
<td>无优化</td>
<td>首次大规模 CNN</td>
</tr>
<tr>
<td>VGG-16(2014)</td>
<td>138M</td>
<td>深层结构但全连接太大</td>
<td>多层小卷积</td>
</tr>
<tr>
<td>NiN(2013)</td>
<td>8M</td>
<td>1×1 Conv + GAP，去除FC</td>
<td>Network in Network</td>
</tr>
<tr>
<td>GoogLeNet (2014)</td>
<td>6.8M</td>
<td>Inception + 通道压缩 + GAP</td>
<td>模块化多尺度设计</td>
</tr>
</tbody></table>
<p>VGG和AlexNet的参数主要来源于三个巨大的全连接层</p>
<p>NiN 通过 1×1 卷积和全局平均池化消除了冗余的全连接层</p>
<p>GoogLeNet 在此基础上进一步通过 多分支 + 通道压缩 把参数量进一步压缩</p>
</li>
</ol>
<h2 id="批量规范化"><a href="#批量规范化" class="headerlink" title="批量规范化"></a>批量规范化</h2><p>训练深层神经网络是十分困难的，特别是在较短的时间内使他们收敛更加棘手</p>
<p><strong>批量规范化(batch normalization,BN)</strong>(Ioffe and Szegedy, 2015)是一种流行且有效的技术，可持续加速深层网络的收敛速度</p>
<h3 id="实际挑战"><a href="#实际挑战" class="headerlink" title="实际挑战"></a>实际挑战</h3><p>数据预处理的方式通常会对最终结果产生巨大影响</p>
<p>批量规范化是为了解决训练神经网络时输入分布不稳定、梯度难以收敛等问题。在训练时对每一层的小批量输入计算均值与方差，将其规范化为均值为0、方差为1的分布，再通过可学习的<strong>拉伸参数(scale)</strong>$\gamma$以及<strong>偏移参数(shift)</strong>$\beta$恢复模型的表达能力</p>
<p>这样做可以：</p>
<ul>
<li>减少不同层之间分布的剧烈变化，加快收敛；</li>
<li>使训练对学习率不那么敏感；</li>
<li>起到一定正则化作用，减轻过拟合</li>
</ul>
<p>需要注意的是，BN 依赖于小批量的统计特性，因此批量太小会导致不稳定或无效</p>
<p>从形式上来说$\mathbf{x} \in \mathcal{B}$表示一个来自小批量的输入，批量规范化根据以下表达式转换$\mathbf{x}$<br>$$<br>BN(x) = \gamma \cdot \frac{x - \hat \mu_B}{\hat \sigma_B} + \beta<br>$$<br>批量均值与方差分别为<br>$$<br>\begin{aligned}<br>\hat\mu_\mathcal B &amp;= \frac{1}{| B|} \sum_{x \in  B} x \\<br>\hat\sigma^2_B &amp;= \frac{1}{| B|} \sum_{x \in  B} (x - \hat\mu_B)^2 + \epsilon<br>\end{aligned}<br>$$<br>在方差估计值中添加一个小的常量以确保永远不会尝试除以零，训练中的随机性与噪声可视为一种正则化，有助于泛化</p>
<p>(Teye <em>et al.</em>, 2018)和(Luo <em>et al.</em>, 2018)分别将批量规范化的性质与贝叶斯先验相关联，这些理论揭示了为什么批量规范化最适应50~100范围中等批量大小的难题</p>
<p>批量规范化在训练和预测阶段的行为不同：</p>
<ul>
<li>训练模式：使用当前小批量的均值和方差进行规范化，因为此时无法获得全数据统计</li>
<li>预测模式：使用在训练过程中累计得到的全局均值和方差，对输入进行稳定规范化</li>
</ul>
<h3 id="批量规范化层"><a href="#批量规范化层" class="headerlink" title="批量规范化层"></a>批量规范化层</h3><p>批量规范化和其他层之间的一个关键区别是，由于批量规范化在完整的小批量上运行，因此不能像以前在引入其他层时那样忽略批量大小</p>
<p><font color="DarkViolet">批量规范化层置于全连接层/卷积层后，激活函数之前</font></p>
<h4 id="全连接层"><a href="#全连接层" class="headerlink" title="全连接层"></a>全连接层</h4><p>设全连接层的输入为$\mathbf{x}$，激活函数为$\phi$，批量规范化的运算符为$\mathrm{BN}$，使用批量规范化的全连接层的输出的计算详情如下<br>$$<br>\mathbf{h} = \phi(\mathrm{BN}(\mathbf{W}\mathbf{x} + \mathbf{b}) ).<br>$$<br>均值和方差是在应用变换的“相同”小批量上计算的</p>
<h4 id="卷积层-1"><a href="#卷积层-1" class="headerlink" title="卷积层"></a>卷积层</h4><p>当卷积有多个输出通道时，需要对这些通道的每个输出执行批量规范化，<font color="Violetred">每个通道都有自己的拉伸和偏移参数</font>，这两个参数都是标量</p>
<p>设一个小批量中有$m$个样本，每个通道输出的特征图尺寸为$p×q$，那么需要对每个输出通道的$m \cdot p \cdot q$个元素上同时执行批量规范化</p>
<h4 id="预测过程"><a href="#预测过程" class="headerlink" title="预测过程"></a>预测过程</h4><p>批量规范化在训练与预测阶段的行为不同，训练时依赖当前小批量数据的均值和方差进行规范化，因此包含随机噪声和批次间波动，而预测阶段则需要稳定、确定的输出，不再使用小批量统计量，而是采用在训练过程中通过移动平均得到的全局均值和方差</p>
<p><font color="Violetred">BN层与暂退法类似，在训练和推理阶段的计算方式并不相同</font></p>
<h3 id="底层实现"><a href="#底层实现" class="headerlink" title="底层实现"></a>底层实现</h3><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">batch_norm</span>(<span class="params">X, gamma, beta, moving_mean, moving_var, eps, momentum</span>):</span><br><span class="line">    <span class="comment"># momentum动量参数，用于更新移动平均的平滑程度</span></span><br><span class="line">    <span class="comment"># 通过is_grad_enabled来判断当前模式是训练模式还是预测模式</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> torch.is_grad_enabled():</span><br><span class="line">        <span class="comment"># 如果预测模式，直接使用传入的移动平均获得的均值和方差</span></span><br><span class="line">        X_hat = (X-moving_mean) / torch.sqrt(moving_var + eps)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">assert</span> <span class="built_in">len</span>(X.shape) <span class="keyword">in</span> (<span class="number">2</span>,<span class="number">4</span>)</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(X.shape) == <span class="number">2</span>:</span><br><span class="line">            <span class="comment"># 使用全连接层的情况，计算特征维上的均值和方差</span></span><br><span class="line">            mean = X.mean(dim=<span class="number">0</span>)</span><br><span class="line">            var = ((X-mean)**<span class="number">2</span>).mean(dim=<span class="number">0</span>)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="comment"># 使用二维卷积层的情况，计算通道维上(axis=1)的均值和方差</span></span><br><span class="line">            mean = X.mean(dim=(<span class="number">0</span>,<span class="number">2</span>,<span class="number">3</span>), keepdim=<span class="literal">True</span>)</span><br><span class="line">            var = ((X-mean)**<span class="number">2</span>).mean(dim=(<span class="number">0</span>,<span class="number">2</span>,<span class="number">3</span>), keepdim=<span class="literal">True</span>)</span><br><span class="line">        <span class="comment"># 训练模式下，用当前的均值和方差做标准化</span></span><br><span class="line">        X_hat = (X - mean) / torch.sqrt(var + eps)</span><br><span class="line">        <span class="comment"># 更新移动平均的均值和方差</span></span><br><span class="line">        <span class="comment"># 越大的 momentum 越依赖过去的统计值</span></span><br><span class="line">        moving_mean = momentum * moving_mean + (<span class="number">1.0</span> - momentum) * mean</span><br><span class="line">        moving_var = momentum * moving_var + (<span class="number">1.0</span> - momentum) * var</span><br><span class="line">    Y = gamma * X_hat + beta <span class="comment"># 缩放和移位</span></span><br><span class="line">    <span class="keyword">return</span> Y, moving_mean.data, moving_var.data</span><br></pre></td></tr></tbody></table></figure>

<p>在可以创建一个正确的<code>BatchNorm</code>层，这个层将保持适当的参数：拉伸<code>gamma</code>和偏移<code>beta</code>，这两个参数将在训练过程中更新，将保存均值和方差的移动平均值，以便在模型预测期间随后使用</p>
<p>将此功能集成到一个自定义层中，其代码主要处理数据移动到训练设备(如GPU)、分配和初始化任何必需的变量、跟踪移动平均线(此处为均值和方差)等问题，这里代码需要指定整个特征的数量，但在深度学习框架中的API不需要考虑这个问题</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">BatchNorm</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, num_features, num_dims</span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        <span class="keyword">if</span> num_dims == <span class="number">2</span>:</span><br><span class="line">            shape = (<span class="number">1</span>, num_features)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            shape = (<span class="number">1</span>, num_features, <span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">        <span class="comment"># 参与求梯度和迭代的拉伸和偏移参数，分别初始化成1和0</span></span><br><span class="line">        <span class="variable language_">self</span>.gamma = nn.Parameter(torch.ones(shape))</span><br><span class="line">        <span class="variable language_">self</span>.beta = nn.Parameter(torch.zeros(shape))</span><br><span class="line">        <span class="comment"># 非模型参数的变量初始化为0和1</span></span><br><span class="line">        <span class="variable language_">self</span>.moving_mean = torch.zeros(shape)</span><br><span class="line">        <span class="variable language_">self</span>.moving_var = torch.ones(shape)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, X</span>):</span><br><span class="line">        <span class="comment"># 如果X不在内存上，将moving_mean和moving_var复制到X所在显存</span></span><br><span class="line">        <span class="keyword">if</span> <span class="variable language_">self</span>.moving_mean.device != X.device:</span><br><span class="line">            <span class="variable language_">self</span>.moving_mean = <span class="variable language_">self</span>.moving_mean.to(X.device)</span><br><span class="line">            <span class="variable language_">self</span>.moving_var = <span class="variable language_">self</span>.moving_var.to(X.device)</span><br><span class="line">        Y, <span class="variable language_">self</span>.moving_mean, <span class="variable language_">self</span>.moving_var = batch_norm(</span><br><span class="line">            X, <span class="variable language_">self</span>.gamma, <span class="variable language_">self</span>.beta, <span class="variable language_">self</span>.moving_mean, <span class="variable language_">self</span>.moving_var,</span><br><span class="line">            eps = <span class="number">1e-5</span>, momentum = <span class="number">0.9</span></span><br><span class="line">        )</span><br><span class="line">        <span class="keyword">return</span> Y</span><br></pre></td></tr></tbody></table></figure>

<h3 id="带入LeNet"><a href="#带入LeNet" class="headerlink" title="带入LeNet"></a>带入LeNet</h3><p>批量规范化是在卷积层或全连接层之后、相应的激活函数之前应用的</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">net = nn.Sequential(</span><br><span class="line">    <span class="comment"># 这里第一层没加padding，所以最后输出的是4*4</span></span><br><span class="line">    nn.Conv2d(<span class="number">1</span>, <span class="number">6</span>, kernel_size=<span class="number">5</span>), BatchNorm(<span class="number">6</span>, num_dims=<span class="number">4</span>), nn.Sigmoid(),</span><br><span class="line">    nn.AvgPool2d(kernel_size=<span class="number">2</span>, stride=<span class="number">2</span>),</span><br><span class="line">    nn.Conv2d(<span class="number">6</span>, <span class="number">16</span>, kernel_size=<span class="number">5</span>), BatchNorm(<span class="number">16</span>, num_dims=<span class="number">4</span>), nn.Sigmoid(),</span><br><span class="line">    nn.AvgPool2d(kernel_size=<span class="number">2</span>, stride=<span class="number">2</span>), nn.Flatten(),</span><br><span class="line">    nn.Linear(<span class="number">16</span> * <span class="number">4</span> * <span class="number">4</span>, <span class="number">120</span>), BatchNorm(<span class="number">120</span>, num_dims=<span class="number">2</span>), nn.Sigmoid(),</span><br><span class="line">    nn.Linear(<span class="number">120</span>, <span class="number">84</span>), BatchNorm(<span class="number">84</span>, num_dims=<span class="number">2</span>), nn.Sigmoid(),</span><br><span class="line">    nn.Linear(<span class="number">84</span>, <span class="number">10</span>))</span><br></pre></td></tr></tbody></table></figure>

<p>和以前一样，将在Fashion-MNIST数据集上训练网络，但区别是学习率大得多</p>
<p>批量规范化通过控制中间层输入的分布，让网络在数值上对学习率更加鲁棒，因此可以安全使用更大的学习率，以加快收敛并提升泛化</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">lr, num_epochs, batch_size = <span class="number">1.0</span>, <span class="number">10</span>, <span class="number">256</span></span><br><span class="line">train_iter, test_iter = load_data_fashion_mnist(batch_size)</span><br><span class="line">train_ch6(net, train_iter, test_iter, num_epochs, lr, try_gpu())</span><br></pre></td></tr></tbody></table></figure>

<figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">epoch 1, loss 0.759, acc 0.727, time 9.976</span><br><span class="line">epoch 2, loss 0.478, acc 0.825, time 9.793</span><br><span class="line">epoch 3, loss 0.406, acc 0.851, time 9.434</span><br><span class="line">epoch 4, loss 0.362, acc 0.868, time 9.730</span><br><span class="line">epoch 5, loss 0.331, acc 0.881, time 9.272</span><br><span class="line">epoch 6, loss 0.313, acc 0.885, time 10.261</span><br><span class="line">epoch 7, loss 0.300, acc 0.890, time 9.568</span><br><span class="line">epoch 8, loss 0.287, acc 0.894, time 9.825</span><br><span class="line">epoch 9, loss 0.279, acc 0.897, time 9.699</span><br><span class="line">epoch 10, loss 0.270, acc 0.902, time 9.667</span><br></pre></td></tr></tbody></table></figure>

<img src="https://wuyaohui06022.oss-cn-chengdu.aliyuncs.com/YJS1/image-20251025153222380.png" alt="image-20251025153222380" style="zoom:80%;">

<figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">loss 0.270, train acc 0.902, test acc 0.871</span><br><span class="line">24791.2 examples/sec on cpu</span><br></pre></td></tr></tbody></table></figure>

<p>来看看从第一个批量规范化层中学到的拉伸参数<code>gamma</code>和偏移参数<code>beta</code></p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">net[<span class="number">1</span>].gamma.reshape((-<span class="number">1</span>,)), net[<span class="number">1</span>].beta.reshape((-<span class="number">1</span>,))</span><br></pre></td></tr></tbody></table></figure>

<figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">(tensor([0.5371, 2.9680, 4.2053, 3.2385, 0.3399, 3.5118],</span><br><span class="line">        grad_fn=&lt;ViewBackward0&gt;),</span><br><span class="line"> tensor([-0.5215,  1.7145, -2.4500,  0.6433, -0.5788,  3.7196],</span><br><span class="line">        grad_fn=&lt;ViewBackward0&gt;))</span><br></pre></td></tr></tbody></table></figure>

<h3 id="简洁实现"><a href="#简洁实现" class="headerlink" title="简洁实现"></a>简洁实现</h3><p>可以直接使用深度学习框架中定义的<code>BatchNorm</code>，net中修改一下即可，只需要输入输出通道数作为参数</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">net = nn.Sequential(</span><br><span class="line">    nn.Conv2d(<span class="number">1</span>, <span class="number">6</span>, kernel_size=<span class="number">5</span>), nn.BatchNorm2d(<span class="number">6</span>), nn.Sigmoid(),</span><br><span class="line">    nn.AvgPool2d(kernel_size=<span class="number">2</span>, stride=<span class="number">2</span>),</span><br><span class="line">    nn.Conv2d(<span class="number">6</span>, <span class="number">16</span>, kernel_size=<span class="number">5</span>), nn.BatchNorm2d(<span class="number">16</span>), nn.Sigmoid(),</span><br><span class="line">    nn.AvgPool2d(kernel_size=<span class="number">2</span>, stride=<span class="number">2</span>), nn.Flatten(),</span><br><span class="line">    nn.Linear(<span class="number">16</span> * <span class="number">4</span> * <span class="number">4</span>, <span class="number">120</span>), nn.BatchNorm1d(<span class="number">120</span>), nn.Sigmoid(),</span><br><span class="line">    nn.Linear(<span class="number">120</span>, <span class="number">84</span>), nn.BatchNorm1d(<span class="number">84</span>), nn.Sigmoid(),</span><br><span class="line">    nn.Linear(<span class="number">84</span>, <span class="number">10</span>)</span><br><span class="line">)</span><br></pre></td></tr></tbody></table></figure>

<p>通常高级API变体运行速度快得多，因为它的代码已编译为C++或CUDA，而自定义代码由Python实现</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">train_ch6(net, train_iter, test_iter, num_epochs, lr, try_gpu())</span><br></pre></td></tr></tbody></table></figure>

<figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">epoch 1, loss 0.647, acc 0.760, time 9.311</span><br><span class="line">epoch 2, loss 0.418, acc 0.847, time 9.212</span><br><span class="line">epoch 3, loss 0.360, acc 0.868, time 9.311</span><br><span class="line">epoch 4, loss 0.330, acc 0.878, time 9.302</span><br><span class="line">epoch 5, loss 0.313, acc 0.884, time 9.373</span><br><span class="line">epoch 6, loss 0.295, acc 0.891, time 8.978</span><br><span class="line">epoch 7, loss 0.278, acc 0.898, time 9.393</span><br><span class="line">epoch 8, loss 0.270, acc 0.901, time 9.384</span><br><span class="line">epoch 9, loss 0.257, acc 0.905, time 8.945</span><br><span class="line">epoch 10, loss 0.251, acc 0.908, time 9.630</span><br></pre></td></tr></tbody></table></figure>

<img src="https://wuyaohui06022.oss-cn-chengdu.aliyuncs.com/YJS1/image-20251025154825344.png" alt="image-20251025154825344" style="zoom:80%;">

<figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">loss 0.251, train acc 0.908, test acc 0.885</span><br><span class="line">34264.4 examples/sec on cpu</span><br></pre></td></tr></tbody></table></figure>

<h3 id="争议"><a href="#争议" class="headerlink" title="争议"></a>争议</h3><p>批量规范化常被直观地认为能让优化过程更平滑、更稳定，然而这种“直觉解释”并不等同于科学原理，事实上至今仍未完全理解即使是简单神经网络(如多层感知机、传统CNN)为何能如此有效泛化</p>
<p>BN的提出者在论文中将其效果归因于减少<strong>内部协变量偏移(internal covariate shift)</strong>，即训练过程中各层输入分布的变化，但这种解释存在两点问题：</p>
<ol>
<li>内部协变量偏移与严格意义上的**协变量偏移(covariate shift)**不同，命名并不严谨</li>
<li>该解释仅是一种模糊的直觉，并未真正揭示 BN 成功的机制</li>
</ol>
<p>其他研究者提出了新的观点：BN 的作用机制可能与原论文的解释相反(Santurkar et al., 2018)，其真正效果更接近于改善优化几何性质，使损失函数更光滑</p>
<p>无论解释如何分歧，批量规范化几乎成为现代神经网络训练的标准组成部分，尤其在图像分类任务中表现突出，并在学术界获得了数万次引用</p>
<h3 id="小结-6"><a href="#小结-6" class="headerlink" title="小结"></a>小结</h3><ul>
<li>在模型训练过程中，批量规范化利用小批量的均值和标准差，不断调整神经网络的中间输出，使整个神经网络各层的中间输出值更加稳定</li>
<li>批量规范化在全连接层和卷积层的使用略有不同</li>
<li>批量规范化层和暂退层一样，在训练模式和预测模式下计算不同</li>
<li>批量规范化有许多有益的副作用，主要是正则化</li>
</ul>
<h3 id="思考题-7"><a href="#思考题-7" class="headerlink" title="思考题"></a>思考题</h3><ol>
<li><p>在使用批量规范化之前，是否可以从全连接层或卷积层中删除偏置参数？为什么？</p>
<p>可以删除偏置参数，因为BN的$\beta$拥有“平移能力”，原本线性层的偏置就变得多余</p>
<p>大多数现代实现(包括 ResNet、VGG-BN、DenseNet等)都是在有 BN 的情况下，关闭前一层的 bias，这不仅简化了参数，还能略微提高训练效率，避免无意义的梯度更新</p>
</li>
<li><p>比较使用和不使用批量规范化情况下的学习率</p>
<p>BN会扩大稳定学习率范围，所以用BN可以把学习率开得更大</p>
</li>
<li><p>是否需要在每个层中进行批量规范化？</p>
<p>删除全连接层后面的批量规范化对结果影响不大，所以不是非要每个层</p>
<ul>
<li><strong>卷积层</strong>：在每个卷积层后(激活函数前)加 BN 通常是有益的，因为早期特征分布变化大</li>
<li><strong>全连接层</strong>：加 BN 的收益远小于卷积层，常见做法是只在第一个或前几个全连接层上使用</li>
</ul>
<p>在浅层网络(如LeNet)中，只需在卷积层后加 BN 即可，在更深网络(如ResNet、DenseNet)，BN才几乎每层使用</p>
</li>
<li><p>对比批量规范化和暂退法</p>
<table>
<thead>
<tr>
<th>特征</th>
<th>批量规范化</th>
<th>暂退法</th>
</tr>
</thead>
<tbody><tr>
<td>引入的噪声</td>
<td>来自小批量统计(均值、方差的随机性)</td>
<td>来自神经元随机屏蔽</td>
</tr>
<tr>
<td>噪声作用层面</td>
<td>连续扰动——数值被平滑缩放</td>
<td>离散扰动——神经元直接置零</td>
</tr>
<tr>
<td>对梯度的影响</td>
<td>稳定梯度流</td>
<td>阻断部分梯度路径，增加训练噪声</td>
</tr>
<tr>
<td>对模型行为</td>
<td>加速收敛、提高数值稳定性</td>
<td>提高泛化、减轻过拟合</td>
</tr>
<tr>
<td>推理阶段</td>
<td>去噪(使用滑动均值/方差)</td>
<td>去噪(缩放激活值)</td>
</tr>
</tbody></table>
<ul>
<li><p>BN的噪声可以视作一种隐式贝叶斯正则，但强度有限</p>
</li>
<li><p>Dropout 的噪声是显式的、较强的随机化机制</p>
</li>
</ul>
<p>根据网络类型进行选择，BN对卷积层效果更好，Dropout对全连接层效果更好</p>
<table>
<thead>
<tr>
<th>场景</th>
<th>常见做法</th>
</tr>
</thead>
<tbody><tr>
<td>卷积网络(如LeNet、ResNet)</td>
<td>通常用 BN，不用 Dropout</td>
</tr>
<tr>
<td>全连接层较多(如传统 MLP)</td>
<td>通常用 Dropout，BN 作用有限</td>
</tr>
<tr>
<td>小数据集或易过拟合任务</td>
<td>同时使用 BN + Dropout<br>但 Dropout 需放在 BN 之后(否则统计不稳定)</td>
</tr>
<tr>
<td>大模型 + 大数据</td>
<td>通常使用 BN，不再需要 Dropout</td>
</tr>
</tbody></table>
</li>
</ol>
<h2 id="残差网络-ResNet"><a href="#残差网络-ResNet" class="headerlink" title="残差网络(ResNet)"></a>残差网络(ResNet)</h2><p>随着设计越来越深的网络，深刻理解“新添加的层如何提升神经网络的性能”变得至关重要</p>
<h3 id="函数类"><a href="#函数类" class="headerlink" title="函数类"></a>函数类</h3><p>假设有一类特定的神经网络架构$\mathcal{F}$，它包括学习速率和其他超参数设置，对于所有$f \in \mathcal{F}$存在一些参数集(例如权重和偏置)，这些参数可以通过在合适的数据集上进行训练而获得</p>
<p>假设$f^\ast$是真正想要找到的函数，如果$f^\ast \in \mathcal{F}$那可以轻而易举的训练得到它，但通常不会那么幸运，因此将尝试找到一个函数$f^\ast_\mathcal{F}$，这是在$\mathcal{F}$中的最佳选择</p>
<p>给定一个具有$\mathbf{X}$特性和$\mathbf y$标签的数据集，可以尝试通过解决以下优化问题来找到它<br>$$<br>f^\ast_\mathcal{F} := \mathop{\mathrm{argmin}}_f L(\mathbf{X}, \mathbf{y}, f) \text{ subject to } f \in \mathcal{F}.<br>$$<br>想要近似，唯一合理的可能性是设计一个更强大的架构$\mathcal{F}’$，但是如果$\mathcal{F} \not\subseteq \mathcal{F}’$则无法保证新的体系“更近似”</p>
<p>对于**非嵌套函数(non-nested function)**类，较复杂的函数类并不总是向真函数$f^\ast$靠拢(复杂度由1到6递增)，在左图中虽然$\mathcal{F}_3$比$\mathcal{F}_1$更接近$f^\ast$，但$\mathcal{F}_6$更远了</p>
<p>对于右侧的**嵌套函数(nested function)**类可以避免这个问题</p>
<img src="https://wuyaohui06022.oss-cn-chengdu.aliyuncs.com/YJS1/functionclasses.jpg" alt="functionclasses" style="zoom:80%;">

<p>只有当较复杂的函数类包含较简单的函数类时，模型性能才有可能提升</p>
<p>在深度神经网络，如果新增层能学到<strong>恒等映射(identity function)</strong>，则新旧模型表现相同，更深的模型具备更强表示能力，能够找到更优解，从而更容易降低训练误差</p>
<p>针对这一问题，何恺明等人提出了<strong>残差网络(ResNet)</strong>(He <em>et al.</em>, 2016)</p>
<p><font color="DarkViolet">残差网络的核心思想是：每一层在学习新特征的同时，都能够轻松地保留原始输入，从而让网络更容易表示目标函数</font></p>
<p>**残差块(residual blocks)**便诞生了，这个设计对如何建立深层神经网络产生了深远的影响</p>
<h3 id="残差块"><a href="#残差块" class="headerlink" title="残差块"></a>残差块</h3><p>在神经网络中，假设输入为$x$，理想映射为$f(\mathbf{x})$(作为激活函数的输入)，左图的虚线框直接拟合$f(\mathbf{x})$，右图的虚线框则学习残差$f(\mathbf{x}) - \mathbf{x}$，实践表明，残差映射往往更容易优化</p>
<img src="https://wuyaohui06022.oss-cn-chengdu.aliyuncs.com/YJS1/residual-block.jpg" alt="residual-block" style="zoom:80%;">

<p>左图为正常块，右图展示了ResNet的基本单元——残差块，其中输入可通过跨层连接直接向前传播，从而加速训练并缓解梯度消失问题</p>
<p>若将右图中加权层的权重与偏置设为0，即得到恒等映射</p>
<p>当理想映射接近恒等映射时，残差结构能轻松捕捉这种细微偏差</p>
<p>ResNet沿用了VGG完整的3×3卷积层设计，残差块里首先有2个有相同输出通道数的3×3卷积层，每个卷积层后接一个批量规范化层和ReLU激活函数，通过跨层数据通路，跳过这2个卷积运算，将输入直接加在最后的ReLU激活函数前</p>
<p>这样的设计要求2个卷积层的输出与输入形状一样从而使它们可以相加，如果想要改变通道数，就需要引入一个额外的1×1卷积层来将输入变换成需要的形状后再做相加运算</p>
<p>残差块的实现</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Residual</span>(nn.Module):  <span class="comment">#@save</span></span><br><span class="line">    <span class="comment"># 输入通道数，输出通道数</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, input_channels, num_channels,</span></span><br><span class="line"><span class="params">                 use_1x1conv=<span class="literal">False</span>, strides=<span class="number">1</span></span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        <span class="comment"># 两个连续的3×3卷积层</span></span><br><span class="line">        <span class="comment"># 第一个卷积可选择步幅，控制下采样</span></span><br><span class="line">        <span class="variable language_">self</span>.conv1 = nn.Conv2d(input_channels, num_channels,</span><br><span class="line">                               kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>, stride=strides)</span><br><span class="line">        <span class="variable language_">self</span>.conv2 = nn.Conv2d(num_channels, num_channels,</span><br><span class="line">                               kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>)</span><br><span class="line">        <span class="comment"># 实现捷径，调整X与的通道与大小</span></span><br><span class="line">        <span class="keyword">if</span> use_1x1conv:</span><br><span class="line">            <span class="variable language_">self</span>.conv3 = nn.Conv2d(input_channels, num_channels,</span><br><span class="line">                                   kernel_size=<span class="number">1</span>, stride=strides)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="variable language_">self</span>.conv3 = <span class="literal">None</span></span><br><span class="line">        <span class="variable language_">self</span>.bn1 = nn.BatchNorm2d(num_channels)</span><br><span class="line">        <span class="variable language_">self</span>.bn2 = nn.BatchNorm2d(num_channels)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, X</span>):</span><br><span class="line">        <span class="comment"># 第一层：Conv → BN → ReLU</span></span><br><span class="line">        Y = F.relu(<span class="variable language_">self</span>.bn1(<span class="variable language_">self</span>.conv1(X)))</span><br><span class="line">        <span class="comment"># 第二层：Conv → BN</span></span><br><span class="line">        Y = <span class="variable language_">self</span>.bn2(<span class="variable language_">self</span>.conv2(Y))</span><br><span class="line">        <span class="keyword">if</span> <span class="variable language_">self</span>.conv3:</span><br><span class="line">            X = <span class="variable language_">self</span>.conv3(X)</span><br><span class="line">        Y += X</span><br><span class="line">        <span class="comment"># ReLU留到残差加和后激活</span></span><br><span class="line">        <span class="keyword">return</span> F.relu(Y)</span><br></pre></td></tr></tbody></table></figure>

<p>此代码生成两种类型的网络，当<code>use_1x1conv=False</code>时应用ReLU非线性函数之前，将输入添加到输出；当<code>use_1x1conv=True</code>时，添加通过1×1卷积调整通道和分辨率</p>
<img src="https://wuyaohui06022.oss-cn-chengdu.aliyuncs.com/YJS1/resnet-block.webp" alt="resnet-block" style="zoom:80%;">

<p>来查看输入和输出形状一致的情况</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">block = Residual(<span class="number">3</span>,<span class="number">3</span>)</span><br><span class="line">X = torch.rand(<span class="number">4</span>,<span class="number">3</span>,<span class="number">6</span>,<span class="number">6</span>)</span><br><span class="line">Y = block(X)</span><br><span class="line">Y.shape</span><br><span class="line"><span class="comment"># torch.Size([4, 3, 6, 6])</span></span><br></pre></td></tr></tbody></table></figure>

<p>增加输出通道数的同时，减半输出的高和宽</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">blk = Residual(<span class="number">3</span>, <span class="number">6</span>, use_1x1conv=<span class="literal">True</span>, strides=<span class="number">2</span>)</span><br><span class="line">blk(X).shape</span><br><span class="line"><span class="comment"># torch.Size([4, 6, 3, 3])</span></span><br></pre></td></tr></tbody></table></figure>

<h3 id="网络结构-5"><a href="#网络结构-5" class="headerlink" title="网络结构"></a>网络结构</h3><p>ResNet的第一层跟GoogLeNet一样：在输出通道数为64、步幅为2的7×7卷积层后，接步幅为2的3×3的最大汇聚层，不同之处在于ResNet每个卷积层后增加了批量规范化层</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">b1 = nn.Sequential(nn.Conv2d(<span class="number">1</span>, <span class="number">64</span>, kernel_size=<span class="number">7</span>, stride=<span class="number">2</span>, padding=<span class="number">3</span>),</span><br><span class="line">                   nn.BatchNorm2d(<span class="number">64</span>), nn.ReLU(),</span><br><span class="line">                   nn.MaxPool2d(kernel_size=<span class="number">3</span>, stride=<span class="number">2</span>, padding=<span class="number">1</span>))</span><br></pre></td></tr></tbody></table></figure>

<p>GoogLeNet在后面接了4个由Inception块组成的模块，而ResNet则使用4个由残差块组成的模块构成，每个模块内的残差块输出通道数相同</p>
<p>因为在b1中最大池化已经下采样了，所以第一个模块步幅为1，不再下采样</p>
<table>
<thead>
<tr>
<th>场景</th>
<th>是否使用 1×1 卷积</th>
<th>步幅</th>
<th>作用</th>
</tr>
</thead>
<tbody><tr>
<td>第一个模块</td>
<td>否</td>
<td>1</td>
<td>保持通道数与尺寸</td>
</tr>
<tr>
<td>其他模块的第一个残差块</td>
<td>是</td>
<td>2</td>
<td>通道数翻倍、尺寸减半</td>
</tr>
<tr>
<td>其他模块中的后续块</td>
<td>否</td>
<td>1</td>
<td>保持不变</td>
</tr>
</tbody></table>
<p>来实现这个模块，对第一个模块做了特别处理</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">resnet_block</span>(<span class="params">input_channels, num_channels, num_residuals,</span></span><br><span class="line"><span class="params">                 first_block=<span class="literal">False</span></span>):</span><br><span class="line">    blk = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(num_residuals):</span><br><span class="line">        <span class="keyword">if</span> i == <span class="number">0</span> <span class="keyword">and</span> <span class="keyword">not</span> first_block: <span class="comment"># 判断是不是第一个块</span></span><br><span class="line">            <span class="comment"># 后续模块的首个残差块负责通道翻倍和空间下采样</span></span><br><span class="line">            blk.append(Residual(input_channels, num_channels,</span><br><span class="line">                                use_1x1conv=<span class="literal">True</span>, strides=<span class="number">2</span>))</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            blk.append(Residual(num_channels, num_channels))</span><br><span class="line">    <span class="keyword">return</span> blk</span><br></pre></td></tr></tbody></table></figure>

<p>在ResNet加入所有残差块，这里每个模块使用2个残差块</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">b2 = nn.Sequential(*resnet_block(<span class="number">64</span>, <span class="number">64</span>, <span class="number">2</span>, first_block=<span class="literal">True</span>))</span><br><span class="line">b3 = nn.Sequential(*resnet_block(<span class="number">64</span>, <span class="number">128</span>, <span class="number">2</span>))</span><br><span class="line">b4 = nn.Sequential(*resnet_block(<span class="number">128</span>, <span class="number">256</span>, <span class="number">2</span>))</span><br><span class="line">b5 = nn.Sequential(*resnet_block(<span class="number">256</span>, <span class="number">512</span>, <span class="number">2</span>))</span><br></pre></td></tr></tbody></table></figure>

<p>最后，与GoogLeNet一样，在ResNet中加入全局平均汇聚层，以及全连接层输出</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">net = nn.Sequential(b1, b2, b3, b4, b5,</span><br><span class="line">                    nn.AdaptiveAvgPool2d((<span class="number">1</span>,<span class="number">1</span>)),</span><br><span class="line">                    nn.Flatten(), nn.Linear(<span class="number">512</span>, <span class="number">10</span>))</span><br></pre></td></tr></tbody></table></figure>

<p>每个模块有4个卷积层(不包括恒等映射的1×1卷积层)，加上第一个7×7卷积层和最后一个全连接层，共有18层，这种模型通常被称为ResNet-18</p>
<p>通过配置不同的通道数和模块里的残差块数可以得到不同的ResNet模型，例如更深的含152层的ResNet-152</p>
<p>虽然ResNet的主体架构跟GoogLeNet类似，但ResNet架构更简单，修改也更方便</p>
<p>下图为完整的ResNet-18架构</p>
<img src="https://wuyaohui06022.oss-cn-chengdu.aliyuncs.com/YJS1/resnet18.webp" alt="resnet18" style="zoom:80%;">

<p>在训练ResNet之前，观察一下ResNet中不同模块的输入形状是如何变化的</p>
<p>在之前所有架构中，分辨率降低，通道数量增加，直到全局平均汇聚层聚集所有特征</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">X = torch.rand(size=(<span class="number">1</span>, <span class="number">1</span>, <span class="number">224</span>, <span class="number">224</span>))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f"<span class="subst">{<span class="string">'Layer'</span>:&lt;<span class="number">20</span>}</span><span class="subst">{<span class="string">'Output Shape'</span>}</span>"</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">'-'</span>*<span class="number">40</span>)</span><br><span class="line"><span class="keyword">for</span> layer <span class="keyword">in</span> net:</span><br><span class="line">    X = layer(X)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f"<span class="subst">{layer.__class__.__name__:&lt;<span class="number">20</span>}</span><span class="subst">{<span class="built_in">str</span>(<span class="built_in">tuple</span>(X.shape))}</span>"</span>)</span><br></pre></td></tr></tbody></table></figure>

<figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">Layer               Output Shape</span><br><span class="line">----------------------------------------</span><br><span class="line">Sequential          (1, 64, 56, 56)  # 两次下采样</span><br><span class="line">Sequential          (1, 64, 56, 56)  # 第一个模块步幅为1，通道数不变</span><br><span class="line">Sequential          (1, 128, 28, 28) # 通道数加倍，步幅为2下采样</span><br><span class="line">Sequential          (1, 256, 14, 14) # 通道数加倍，步幅为2下采样</span><br><span class="line">Sequential          (1, 512, 7, 7)   # 通道数加倍，步幅为2下采样</span><br><span class="line">AdaptiveAvgPool2d   (1, 512, 1, 1)   </span><br><span class="line">Flatten             (1, 512)</span><br><span class="line">Linear              (1, 10)</span><br></pre></td></tr></tbody></table></figure>

<h3 id="训练模型-2"><a href="#训练模型-2" class="headerlink" title="训练模型"></a>训练模型</h3><p>在Fashion-MNIST数据集上训练ResNet</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">lr, num_epochs, batch_size = <span class="number">0.05</span>, <span class="number">10</span>, <span class="number">256</span></span><br><span class="line">train_iter, test_iter = load_data_fashion_mnist(batch_size, resize=<span class="number">96</span>)</span><br><span class="line">train_ch6(net, train_iter, test_iter, num_epochs, lr, try_gpu())</span><br></pre></td></tr></tbody></table></figure>

<figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">epoch 1, loss 0.649, acc 0.820</span><br><span class="line">epoch 2, loss 0.268, acc 0.903</span><br><span class="line">epoch 3, loss 0.206, acc 0.926</span><br><span class="line">epoch 4, loss 0.160, acc 0.943</span><br><span class="line">epoch 5, loss 0.124, acc 0.957</span><br><span class="line">epoch 6, loss 0.091, acc 0.970</span><br><span class="line">epoch 7, loss 0.067, acc 0.979</span><br><span class="line">epoch 8, loss 0.041, acc 0.989</span><br><span class="line">epoch 9, loss 0.024, acc 0.994</span><br><span class="line">epoch 10, loss 0.018, acc 0.996</span><br></pre></td></tr></tbody></table></figure>

<img src="https://wuyaohui06022.oss-cn-chengdu.aliyuncs.com/YJS1/202510251949.png" alt="202510251949" style="zoom:80%;">

<figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">loss 0.018, train acc 0.996, test acc 0.913</span><br></pre></td></tr></tbody></table></figure>

<p>非常夸张的训练集精确度啊</p>
<h3 id="小结-7"><a href="#小结-7" class="headerlink" title="小结"></a>小结</h3><ul>
<li>学习嵌套函数是训练神经网络的理想情况，在深层神经网络中，学习另一层作为恒等映射较容易(尽管这是一个极端情况)</li>
<li>残差映射可以更容易地学习同一函数，例如将权重层中的参数近似为零</li>
<li>利用残差块可以训练出一个有效的深层神经网络：输入可以通过层间的残余连接更快地向前传播</li>
<li>ResNet对随后的深层神经网络设计产生了深远影响</li>
</ul>
<h3 id="思考题-8"><a href="#思考题-8" class="headerlink" title="思考题"></a>思考题</h3><ol>
<li><p>Inception块与残差块之间的主要区别是什么？在删除了Inception块中的一些路径之后，它们是如何相互关联的？</p>
<p>对比二者：</p>
<table>
<thead>
<tr>
<th>特征</th>
<th>Inception块</th>
<th>残差块(Residual Block)</th>
</tr>
</thead>
<tbody><tr>
<td>主要动机</td>
<td>增加网络的宽度(多尺度特征提取)</td>
<td>增加网络的深度(更容易优化的深层结构)</td>
</tr>
<tr>
<td>核心结构</td>
<td>多条卷积路径并行(1×1、3×3、5×5 等)再拼接</td>
<td>一条主路径 + 一条恒等捷径，进行相加</td>
</tr>
<tr>
<td>特征融合方式</td>
<td>把各路径输出在通道维度上堆叠</td>
<td>把输入与变换后的特征直接相加</td>
</tr>
<tr>
<td>设计目的</td>
<td>让网络在同一层中感受不同尺度的特征</td>
<td>让网络学习残差，稳定训练</td>
</tr>
<tr>
<td>对梯度传播的影响</td>
<td>并行路径增加特征表达能力，但深度增加后仍易梯度衰减</td>
<td>恒等连接保证梯度能直接后传，不易消失</td>
</tr>
</tbody></table>
<p>两者的关联：</p>
<p>把Inception块中的多分支路径删掉，只保留一条主要的卷积路径，这个结构就很接近一个普通的卷积层，如果再加上一条跨层的恒等连接，就演化为了残差块</p>
</li>
</ol>
<h3 id="ResNet变体"><a href="#ResNet变体" class="headerlink" title="ResNet变体"></a>ResNet变体</h3><p>参考ResNet论文(He <em>et al.</em>, 2016)中的表1，学习多种变体</p>
<img src="https://wuyaohui06022.oss-cn-chengdu.aliyuncs.com/YJS1/Snipaste_2025-10-25_20-08-15.webp" alt="Snipaste_2025-10-25_20-08-15" style="zoom: 67%;">

<table>
<thead>
<tr>
<th>模型</th>
<th>Block 类型</th>
<th>[conv2_x, conv3_x, conv4_x, conv5_x]</th>
<th>总层数</th>
</tr>
</thead>
<tbody><tr>
<td>ResNet-18</td>
<td>BasicBlock</td>
<td>[2, 2, 2, 2]</td>
<td>18</td>
</tr>
<tr>
<td>ResNet-34</td>
<td>BasicBlock</td>
<td>[3, 4, 6, 3]</td>
<td>34</td>
</tr>
<tr>
<td>ResNet-50</td>
<td>Bottleneck</td>
<td>[3, 4, 6, 3]</td>
<td>50</td>
</tr>
<tr>
<td>ResNet-101</td>
<td>Bottleneck</td>
<td>[3, 4, 23, 3]</td>
<td>101</td>
</tr>
<tr>
<td>ResNet-152</td>
<td>Bottleneck</td>
<td>[3, 8, 36, 3]</td>
<td>152</td>
</tr>
</tbody></table>
<p>在ResNet-50/101/152 都用到了<strong>Bottleneck</strong>，每个残差块由三个卷积核组成，其中1×1卷积的主要作用是降维+升维</p>
<p>以50-layers conv2_x为例：</p>
<table>
<thead>
<tr>
<th>卷积层</th>
<th>核大小</th>
<th>通道变化</th>
<th>作用</th>
</tr>
</thead>
<tbody><tr>
<td>第一层</td>
<td>1×1</td>
<td>256 → 64</td>
<td>降维，减少计算量</td>
</tr>
<tr>
<td>第二层</td>
<td>3×3</td>
<td>64 → 64</td>
<td>提取特征</td>
</tr>
<tr>
<td>第三层</td>
<td>1×1</td>
<td>64 → 256</td>
<td>升维，恢复通道数以便残差相加</td>
</tr>
</tbody></table>
<p>这样使得3×3卷积不会在高通道上操作，降低计算量</p>
<p>1×1卷积几乎不增加计算负担，却能控制通道数</p>
<hr>
<p>在ResNet v2中，作者将“卷积层、批量规范化层和激活层”架构更改为“批量规范化层、激活层和卷积层”架构</p>
<img src="https://wuyaohui06022.oss-cn-chengdu.aliyuncs.com/YJS1/Snipaste_2025-10-25_20-24-58.webp" alt="Snipaste_2025-10-25_20-24-58" style="zoom:67%;">

<table>
<thead>
<tr>
<th>类型</th>
<th>顺序</th>
<th>关键特性</th>
</tr>
</thead>
<tbody><tr>
<td>ResNet v1</td>
<td>Conv → BN → ReLU → Conv → BN → Add → ReLU</td>
<td>加法后再激活(post-activation)</td>
</tr>
<tr>
<td>ResNet v2</td>
<td>BN → ReLU → Conv → BN → ReLU → Conv → Add</td>
<td>加法前激活(pre-activation)</td>
</tr>
</tbody></table>
<p><code>post-activation</code>在浅层时没问题，但在非常深的网络中，梯度在跨层传播时容易衰减，因为 BN 和 ReLU 在加法之后才起作用</p>
<p><code>pre-activation</code>将BN和ReLU放在卷积层之前，残差相加不再经过激活函数，使残差连接成为真正的恒等映射，更利于梯度直接传播</p>
<h2 id="稠密连接网络-DenseNet"><a href="#稠密连接网络-DenseNet" class="headerlink" title="稠密连接网络(DenseNet)"></a>稠密连接网络(DenseNet)</h2><p>ResNet极大地改变了如何参数化深层网络中函数的观点，稠密连接网络(DenseNet)(Huang <em>et al.</em>, 2017)在某种程度上是ResNet的逻辑扩展</p>
<h3 id="从ResNet到DenseNet"><a href="#从ResNet到DenseNet" class="headerlink" title="从ResNet到DenseNet"></a>从ResNet到DenseNet</h3><p>任意函数的泰勒展开式它把这个函数分解成越来越高阶的项，在$x$接近0时<br>$$<br>f(x) = f(0) + f’(0) x + \frac{f’’(0)}{2!}  x^2 + \frac{f’’’(0)}{3!}  x^3 + \ldots.<br>$$<br>同样ResNet将函数展开为<br>$$<br>f(\mathbf{x}) = \mathbf{x} + g(\mathbf{x})<br>$$<br>就是说，ResNet将$f$分解为两部分：一个简单的线性项和一个复杂的非线性项</p>
<p>再向前拓展一步，想将$f$拓展成超过两部分的信息呢，一种方案便是DenseNet</p>
<img src="https://wuyaohui06022.oss-cn-chengdu.aliyuncs.com/YJS1/densenet-block.jpg" alt="densenet-block" style="zoom:80%;">

<p>ResNet(左)和DenseNet(右)的关键区别在于，DenseNet输出是连接而不是如ResNet的简单相加</p>
<p>因此，在应用越来越复杂的函数序列后，执行从$\mathbf {x}$到其展开式的映射<br>$$<br>\mathbf{x} \to \left[<br>\mathbf{x},<br>f_1(\mathbf{x}),<br>f_2([\mathbf{x}, f_1(\mathbf{x})]), f_3([\mathbf{x}, f_1(\mathbf{x}), f_2([\mathbf{x}, f_1(\mathbf{x})])]), \ldots\right].<br>$$<br>最后，将这些展开式结合连接到多层感知机中，再次减少特征的数量</p>
<p>DenseNet这个名字由变量之间的“稠密连接”而得来，最后一层与之前的所有层紧密相连</p>
<img src="https://wuyaohui06022.oss-cn-chengdu.aliyuncs.com/YJS1/densenet.jpg" alt="densenet" style="zoom:80%;">

<p>稠密网络主要由2部分构成：<strong>稠密块(dense block)<strong>和</strong>过渡层(transition layer)</strong></p>
<p>前者定义如何连接输入和输出，而后者则控制通道数量，使其不会太复杂</p>
<h3 id="稠密块体"><a href="#稠密块体" class="headerlink" title="稠密块体"></a>稠密块体</h3><p>DenseNet使用了ResNet改良版的“批量规范化、激活和卷积”架构，首先实现一下这个架构</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">conv_block</span>(<span class="params">input_channels, num_channels</span>):</span><br><span class="line">    <span class="comment"># 固定三个步骤，BN-&gt;ReLU-&gt;Conv</span></span><br><span class="line">    <span class="keyword">return</span> nn.Sequential(</span><br><span class="line">        nn.BatchNorm2d(input_channels), nn.ReLU(),</span><br><span class="line">        nn.Conv2d(input_channels, num_channels, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>))</span><br></pre></td></tr></tbody></table></figure>

<p>一个稠密块由多个卷积块组成，每个卷积块使用相同数量的输出通道</p>
<p>在前向传播中，将每个卷积块的输入和输出在通道维上连结</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">DenseBlock</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, num_convs, input_channels, num_channels</span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        layer = []</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(num_convs):</span><br><span class="line">            layer.append(conv_block(</span><br><span class="line">                num_channels * i + input_channels, num_channels))</span><br><span class="line">        <span class="variable language_">self</span>.net = nn.Sequential(*layer)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, X</span>):</span><br><span class="line">        <span class="keyword">for</span> blk <span class="keyword">in</span> <span class="variable language_">self</span>.net:</span><br><span class="line">            Y = blk(X)</span><br><span class="line">            <span class="comment"># 连接通道维度上每个块的输入和输出</span></span><br><span class="line">            X = torch.cat((X, Y), dim=<span class="number">1</span>)</span><br><span class="line">        <span class="keyword">return</span> X</span><br></pre></td></tr></tbody></table></figure>

<table>
<thead>
<tr>
<th>第几层</th>
<th>输入通道数</th>
<th>输出通道数</th>
<th>输入来自</th>
</tr>
</thead>
<tbody><tr>
<td>第 1 层</td>
<td>64</td>
<td>32</td>
<td>原始输入</td>
</tr>
<tr>
<td>第 2 层</td>
<td>64 + 32 = 96</td>
<td>32</td>
<td>输入 + 第 1 层输出</td>
</tr>
<tr>
<td>第 3 层</td>
<td>64 + 32×2 = 128</td>
<td>32</td>
<td>输入 + 第 1、2 层输出</td>
</tr>
</tbody></table>
<p>每一层不仅接收上一层的输出，还接收前面所有层的特征图，这种模式被称为<strong>特征重用(feature reuse)</strong></p>
<p>定义一个有2个卷积块，输出通道数为10的<code>DenseBlock</code>，使用通道数为3的输入时，会得到通道数为3+2×10=23的输出</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">blk = DenseBlock(<span class="number">2</span>, <span class="number">3</span>, <span class="number">10</span>)</span><br><span class="line">X = torch.randn(<span class="number">4</span>, <span class="number">3</span>, <span class="number">8</span>, <span class="number">8</span>)</span><br><span class="line">Y = blk(X)</span><br><span class="line">Y.shape</span><br><span class="line"><span class="comment"># torch.Size([4, 23, 8, 8])</span></span><br></pre></td></tr></tbody></table></figure>

<p>卷积块的通道数控制了输出通道数相对于输入通道数的增长，因此也被称为<strong>增长率(growth rate)</strong></p>
<h3 id="过渡层"><a href="#过渡层" class="headerlink" title="过渡层"></a>过渡层</h3><p>由于每个稠密块都会带来通道数的增加，使用过多则会过于复杂化模型，过渡层可以用来控制模型复杂度，通过1×1卷积层来减少通道数，并使用步幅为2的平均汇聚层减半高和宽，从而进一步降低模型复杂度</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">transition_block</span>(<span class="params">input_channels, num_channels</span>):</span><br><span class="line">    <span class="keyword">return</span> nn.Sequential(</span><br><span class="line">        nn.BatchNorm2d(input_channels), nn.ReLU(),</span><br><span class="line">        nn.Conv2d(input_channels, num_channels, kernel_size=<span class="number">1</span>),</span><br><span class="line">        nn.AvgPool2d(kernel_size=<span class="number">2</span>, stride=<span class="number">2</span>))</span><br></pre></td></tr></tbody></table></figure>

<p>对刚刚的输出使用通道数为10的过渡层，此时输出的通道数减为10，高和宽均减半</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">blk = transition_block(<span class="number">23</span>, <span class="number">10</span>)</span><br><span class="line">blk(Y).shape</span><br><span class="line"><span class="comment"># torch.Size([4, 10, 4, 4])</span></span><br></pre></td></tr></tbody></table></figure>

<h3 id="网络结构-6"><a href="#网络结构-6" class="headerlink" title="网络结构"></a>网络结构</h3><p>DenseNet首先使用同ResNet一样的单卷积层和最大汇聚层</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">b1 = nn.Sequential(</span><br><span class="line">    nn.Conv2d(<span class="number">1</span>, <span class="number">64</span>, kernel_size=<span class="number">7</span>, stride=<span class="number">2</span>, padding=<span class="number">3</span>),</span><br><span class="line">    nn.BatchNorm2d(<span class="number">64</span>), nn.ReLU(),</span><br><span class="line">    nn.MaxPool2d(kernel_size=<span class="number">3</span>, stride=<span class="number">2</span>, padding=<span class="number">1</span>))</span><br></pre></td></tr></tbody></table></figure>

<p>类似于ResNet使用的4个残差块，DenseNet使用的是4个稠密块</p>
<p>与ResNet类似，可以设置每个稠密块使用多少个卷积层，这里设成4使得与刚刚的ResNet-18保持一致</p>
<p>稠密块里的卷积层通道数(即增长率)设为32，所以每个稠密块将增加128个通道</p>
<p>在每个模块之间，ResNet通过步幅为2的残差块减小高和宽，DenseNet则使用过渡层来减半高和宽，并减半通道数</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># num_channels为当前的通道数</span></span><br><span class="line">num_channels, growth_rate = <span class="number">64</span>, <span class="number">32</span></span><br><span class="line">num_convs_in_dense_blocks = [<span class="number">4</span>, <span class="number">4</span>, <span class="number">4</span>, <span class="number">4</span>]</span><br><span class="line">blks = []</span><br><span class="line"><span class="keyword">for</span> i, num_convs <span class="keyword">in</span> <span class="built_in">enumerate</span>(num_convs_in_dense_blocks):</span><br><span class="line">    blks.append(DenseBlock(num_convs, num_channels, growth_rate))</span><br><span class="line">    <span class="comment"># 上一个稠密块的输出通道数</span></span><br><span class="line">    num_channels += num_convs * growth_rate</span><br><span class="line">    <span class="comment"># 在稠密块之间添加一个转换层，使通道数量减半</span></span><br><span class="line">    <span class="keyword">if</span> i != <span class="built_in">len</span>(num_convs_in_dense_blocks) - <span class="number">1</span>:</span><br><span class="line">        blks.append(transition_block(num_channels, num_channels // <span class="number">2</span>))</span><br><span class="line">        num_channels = num_channels // <span class="number">2</span></span><br></pre></td></tr></tbody></table></figure>

<p>与ResNet类似，最后接上全局汇聚层和全连接层来输出结果</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">net = nn.Sequential(</span><br><span class="line">    b1, *blks,</span><br><span class="line">    nn.BatchNorm2d(num_channels), nn.ReLU(),</span><br><span class="line">    nn.AdaptiveAvgPool2d((<span class="number">1</span>, <span class="number">1</span>)),</span><br><span class="line">    nn.Flatten(),</span><br><span class="line">    nn.Linear(num_channels, <span class="number">10</span>))</span><br></pre></td></tr></tbody></table></figure>

<p>测试一下模型</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">X = torch.rand(size=(<span class="number">1</span>, <span class="number">1</span>, <span class="number">224</span>, <span class="number">224</span>))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f"<span class="subst">{<span class="string">'Layer'</span>:&lt;<span class="number">20</span>}</span><span class="subst">{<span class="string">'Output Shape'</span>}</span>"</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">'-'</span>*<span class="number">40</span>)</span><br><span class="line"><span class="keyword">for</span> layer <span class="keyword">in</span> net:</span><br><span class="line">    X = layer(X)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f"<span class="subst">{layer.__class__.__name__:&lt;<span class="number">20</span>}</span><span class="subst">{<span class="built_in">str</span>(<span class="built_in">tuple</span>(X.shape))}</span>"</span>)</span><br></pre></td></tr></tbody></table></figure>

<figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">Layer               Output Shape</span><br><span class="line">----------------------------------------</span><br><span class="line">Sequential          (1, 64, 56, 56)</span><br><span class="line">DenseBlock          (1, 192, 56, 56)   # 固定+128</span><br><span class="line">Sequential          (1, 96, 28, 28)    # 减半</span><br><span class="line">DenseBlock          (1, 224, 28, 28)</span><br><span class="line">Sequential          (1, 112, 14, 14)</span><br><span class="line">DenseBlock          (1, 240, 14, 14)</span><br><span class="line">Sequential          (1, 120, 7, 7)</span><br><span class="line">DenseBlock          (1, 248, 7, 7)</span><br><span class="line">BatchNorm2d         (1, 248, 7, 7)</span><br><span class="line">ReLU                (1, 248, 7, 7)</span><br><span class="line">AdaptiveAvgPool2d   (1, 248, 1, 1)</span><br></pre></td></tr></tbody></table></figure>

<h3 id="训练模型-3"><a href="#训练模型-3" class="headerlink" title="训练模型"></a>训练模型</h3><p>由于这里使用了比较深的网络，将输入高和宽从224降到96来简化计算</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">lr, num_epochs, batch_size = <span class="number">0.1</span>, <span class="number">10</span>, <span class="number">256</span></span><br><span class="line">train_iter, test_iter = load_data_fashion_mnist(batch_size, resize=<span class="number">96</span>)</span><br><span class="line">train_ch6(net, train_iter, test_iter, num_epochs, lr, try_gpu())</span><br></pre></td></tr></tbody></table></figure>

<figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">epoch 1, loss 0.500, acc 0.827, time 35.426</span><br><span class="line">epoch 2, loss 0.295, acc 0.892, time 35.322</span><br><span class="line">epoch 3, loss 0.248, acc 0.912, time 35.535</span><br><span class="line">epoch 4, loss 0.221, acc 0.919, time 35.744</span><br><span class="line">epoch 5, loss 0.199, acc 0.928, time 37.568</span><br><span class="line">epoch 6, loss 0.179, acc 0.936, time 35.875</span><br><span class="line">epoch 7, loss 0.169, acc 0.939, time 36.142</span><br><span class="line">epoch 8, loss 0.153, acc 0.944, time 35.817</span><br><span class="line">epoch 9, loss 0.143, acc 0.948, time 35.799</span><br><span class="line">epoch 10, loss 0.129, acc 0.954, time 35.932</span><br></pre></td></tr></tbody></table></figure>

<img src="https://wuyaohui06022.oss-cn-chengdu.aliyuncs.com/YJS1/202510252138.png" alt="202510252138" style="zoom:80%;">

<figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">loss 0.129, train acc 0.954, test acc 0.882</span><br><span class="line">1915.5 examples/sec on cuda:0</span><br></pre></td></tr></tbody></table></figure>

<h3 id="小结-8"><a href="#小结-8" class="headerlink" title="小结"></a>小结</h3><ul>
<li>在跨层连接上，不同于ResNet中将输入与输出相加，稠密连接网络(DenseNet)在通道维上连结输入与输出</li>
<li>DenseNet的主要构建模块是稠密块和过渡层</li>
<li>在构建DenseNet时，需要通过添加过渡层来控制网络的维数，从而再次减少通道的数量</li>
</ul>
<h3 id="思考题-9"><a href="#思考题-9" class="headerlink" title="思考题"></a>思考题</h3><ol>
<li><p>为什么DenseNet在过渡层使用平均汇聚层而不是最大汇聚层？ </p>
<p>DenseNet 与 ResNet 的主要不同在于每一层都把前面所有层的输出拼接起来，用作输入</p>
<p>这种密集连接意味着：</p>
<ul>
<li>网络内部的特征是累积的</li>
<li>每一层都依赖前面层的信息</li>
<li>信息流要尽量顺畅、完整、不被破坏</li>
</ul>
<p>平均池化能平滑压缩空间维度，同时保留全局分布特征，不会“只选最亮的像素”</p>
</li>
<li><p>DenseNet的优点之一是其模型参数比ResNet小，为什么呢？</p>
<p>在ResNet中，每一层都要“重新计算”很多通用底层特征(例如边缘、纹理)，而DenseNet 直接复用前面层的特征图，不用重新卷积计算这些特征，因此减少参数</p>
<table>
<thead>
<tr>
<th>模型</th>
<th>层数</th>
<th>参数量 (M)</th>
<th>Top-1 Error (%)</th>
</tr>
</thead>
<tbody><tr>
<td>ResNet-50</td>
<td>50</td>
<td>25.6M</td>
<td>23.9</td>
</tr>
<tr>
<td>DenseNet-121</td>
<td>121</td>
<td>8.0M</td>
<td>25.0</td>
</tr>
<tr>
<td>ResNet-152</td>
<td>152</td>
<td>60.2M</td>
<td>23.0</td>
</tr>
<tr>
<td>DenseNet-169</td>
<td>169</td>
<td>14.1M</td>
<td>24.0</td>
</tr>
</tbody></table>
<p>DenseNet 参数量只有 ResNet 的三分之一甚至更少，却达到相近精度</p>
</li>
<li><p>DenseNet一个诟病的问题是内存或显存消耗过多，为什么？</p>
<p>DenseNet参数少，但中间特征多且需要全部保留参与拼接，在现代GPU上显存的主要消耗主要来源于特征图</p>
<p>假设一个 block 有 4 层，每层输出通道数 = 32</p>
<table>
<thead>
<tr>
<th>层</th>
<th>输入通道 (ResNet)</th>
<th>输入通道 (DenseNet)</th>
</tr>
</thead>
<tbody><tr>
<td>1</td>
<td>64</td>
<td>64</td>
</tr>
<tr>
<td>2</td>
<td>64</td>
<td>96 (=64+32)</td>
</tr>
<tr>
<td>3</td>
<td>64</td>
<td>128 (=64+32×2)</td>
</tr>
<tr>
<td>4</td>
<td>64</td>
<td>160 (=64+32×3)</td>
</tr>
</tbody></table>
<p>在 DenseNet 中，输入通道逐层增加，这意味着卷积层要处理越来越多的特征图</p>
<p>在 ImageNet 级别的模型上，DenseNet-121/169显存消耗比ResNet-50/101高约 1.5～2 倍，这也是 DenseNet 没有被工业界大规模取代 ResNet 的一个重要原因</p>
</li>
</ol>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>只有LeNet输入的是28×28的小尺寸图片，其余的都是在ImageNet上测试的，所以输入均为3×224×224</p>
<table>
<thead>
<tr>
<th>意义模型</th>
<th>年份</th>
<th>核心创新</th>
<th>意义</th>
<th>局限</th>
</tr>
</thead>
<tbody><tr>
<td>LeNet</td>
<td>1998</td>
<td>卷积 + 池化</td>
<td>开创CNN</td>
<td>太浅，Sigmoid饱和</td>
</tr>
<tr>
<td>AlexNet</td>
<td>2012</td>
<td>ReLU + Dropout + GPU</td>
<td>让CNN复活</td>
<td>结构设计经验化，参数多</td>
</tr>
<tr>
<td>VGG</td>
<td>2014</td>
<td>小卷积核深堆叠</td>
<td>简洁、通用</td>
<td>参数暴涨，训练成本高</td>
</tr>
<tr>
<td>NiN</td>
<td>2013</td>
<td>1×1卷积 + GAP</td>
<td>通道融合、轻量</td>
<td>模型深度有限，精度略低</td>
</tr>
<tr>
<td>GoogLeNet</td>
<td>2014</td>
<td>多尺度Inception</td>
<td>高效、强大</td>
<td>结构复杂，设计依赖经验<br>不易泛化到其它任务</td>
</tr>
<tr>
<td>ResNet</td>
<td>2015</td>
<td>残差连接</td>
<td>深度可扩展</td>
<td>依赖BN</td>
</tr>
<tr>
<td>DenseNet</td>
<td>2017</td>
<td>全连接特征流</td>
<td>特征复用、梯度顺畅</td>
<td>显存大</td>
</tr>
</tbody></table>
<p>BN → ReLU → Conv 是ResNet后比较固定的模块</p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta"><i class="fas fa-circle-user fa-fw"></i>文章作者: </span><span class="post-copyright-info"><a href="http://yhblogs.cn">今天睡够了吗</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta"><i class="fas fa-square-arrow-up-right fa-fw"></i>文章链接: </span><span class="post-copyright-info"><a href="http://yhblogs.cn/posts/21309.html">http://yhblogs.cn/posts/21309.html</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta"><i class="fas fa-circle-exclamation fa-fw"></i>版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="http://yhblogs.cn" target="_blank">がんばろう</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/%E2%8C%A8%EF%B8%8Fpython/">⌨️python</a></div><div class="post_share"><div class="social-share" data-image="https://wuyaohui06022.oss-cn-chengdu.aliyuncs.com/blogwebp/wallhaven-7jpjzv_1280x720.webp" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.3/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.3/sharejs/dist/js/social-share.min.js" defer=""></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/posts/7224.html" title="循环神经网络"><img class="cover" src="https://wuyaohui06022.oss-cn-chengdu.aliyuncs.com/blogwebp/wallhaven-d8633m_1280x720.webp" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">循环神经网络</div></div></a></div><div class="next-post pull-right"><a href="/posts/65314.html" title="深度学习计算"><img class="cover" src="https://wuyaohui06022.oss-cn-chengdu.aliyuncs.com/blogwebp/wallhaven-9oddld_1280x720.webp" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">深度学习计算</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><div><a href="/posts/30698.html" title="BERT_Pytorch"><img class="cover" src="https://wuyaohui06022.oss-cn-chengdu.aliyuncs.com/blogwebp/wallhaven-7jjyd9_2560x1440.webp" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2026-01-09</div><div class="title">BERT_Pytorch</div></div></a></div><div><a href="/posts/31208.html" title="FunRec 推荐系统_精排模型"><img class="cover" src="https://wuyaohui06022.oss-cn-chengdu.aliyuncs.com/blogwebp/wallhaven-7j931e_1280x720_(1) (1).png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2026-01-18</div><div class="title">FunRec 推荐系统_精排模型</div></div></a></div><div><a href="/posts/24333.html" title="FunRec推荐系统_召回模型"><img class="cover" src="https://wuyaohui06022.oss-cn-chengdu.aliyuncs.com/blogwebp/wallhaven-vpp725_1280x720_(1).webp" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2026-01-14</div><div class="title">FunRec推荐系统_召回模型</div></div></a></div><div><a href="/posts/58676.html" title="Leetcode100记录"><img class="cover" src="https://wuyaohui06022.oss-cn-chengdu.aliyuncs.com/blogwebp/wallhaven-9ozdyx_1280x720.webp" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2026-01-26</div><div class="title">Leetcode100记录</div></div></a></div><div><a href="/posts/22642.html" title="windows安装ROCm"><img class="cover" src="https://wuyaohui06022.oss-cn-chengdu.aliyuncs.com/blogwebp/ROCm_logo.webp" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2025-10-10</div><div class="title">windows安装ROCm</div></div></a></div><div><a href="/posts/3865533702.html" title="pyqt5简单实践"><img class="cover" src="https://wuyaohui06022.oss-cn-chengdu.aliyuncs.com/blogwebp/202206071521231.webp" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-05-28</div><div class="title">pyqt5简单实践</div></div></a></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="https://wuyaohui06022.oss-cn-chengdu.aliyuncs.com/blogwebp/b_2a1aef95f351a5f7ef72eb81e6838fd6.webp" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"></div><div class="author-info__name">今天睡够了吗</div><div class="author-info__description">相遇是最小单位的奇迹</div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">81</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">15</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">1</div></a></div><div class="card-info-social-icons is-center"><a class="social-icon" href="https://wuyaohui06022.oss-cn-chengdu.aliyuncs.com/blogwebp/202206071549233.webp" target="_blank" title="QQ"><i class="iconfont icon-QQ"></i></a><a class="social-icon" href="https://wuyaohui06022.oss-cn-chengdu.aliyuncs.com/blogwebp/202206071549234.webp" target="_blank" title="微信"><i class="iconfont icon-weixin"></i></a><a class="social-icon" href="https://space.bilibili.com/277953459?spm_id_from=333.1007.0.0" target="_blank" title="bilibili"><i class="iconfont icon-bilibili"></i></a><a class="social-icon" href="https://github.com/YaoHui-Wu06022" target="_blank" title="Github"><i class="iconfont icon-GitHub"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">保持理智，相信明天</div><div class="twopeople"><div class="twopeople"><div class="container" style="height:200px;"><canvas class="illo" width="800" height="800" style="max-width: 200px; max-height: 200px; touch-action: none; width: 640px; height: 640px;"></canvas></div> <script src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN/js/twopeople1.js"></script> <script src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN/js/zdog.dist.js"></script> <script id="rendered-js" src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN/js/twopeople.js"></script> <style>.twopeople{margin:0;align-items:center;justify-content:center;text-align:center}canvas{display:block;margin:0 auto;cursor:move}</style></div></div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BB%8E%E5%85%A8%E8%BF%9E%E6%8E%A5%E5%B1%82%E5%88%B0%E5%8D%B7%E7%A7%AF"><span class="toc-number">1.</span> <span class="toc-text">从全连接层到卷积</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%8D%E5%8F%98%E6%80%A7"><span class="toc-number">1.1.</span> <span class="toc-text">不变性</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%A4%9A%E5%B1%82%E6%84%9F%E7%9F%A5%E6%9C%BA%E7%9A%84%E9%99%90%E5%88%B6"><span class="toc-number">1.2.</span> <span class="toc-text">多层感知机的限制</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%8D%B7%E7%A7%AF"><span class="toc-number">1.3.</span> <span class="toc-text">卷积</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%B9%B3%E7%A7%BB%E4%B8%8D%E5%8F%98%E6%80%A7"><span class="toc-number">1.3.1.</span> <span class="toc-text">平移不变性</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%B1%80%E9%83%A8%E6%80%A7"><span class="toc-number">1.3.2.</span> <span class="toc-text">局部性</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%80%9D%E8%80%83%E9%A2%98"><span class="toc-number">1.4.</span> <span class="toc-text">思考题</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%9B%BE%E5%83%8F%E5%8D%B7%E7%A7%AF"><span class="toc-number">2.</span> <span class="toc-text">图像卷积</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BA%92%E7%9B%B8%E5%85%B3"><span class="toc-number">2.1.</span> <span class="toc-text">互相关</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%8D%B7%E7%A7%AF%E5%B1%82"><span class="toc-number">2.2.</span> <span class="toc-text">卷积层</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%9B%AE%E6%A0%87%E7%9A%84%E8%BE%B9%E7%BC%98%E6%A3%80%E6%B5%8B"><span class="toc-number">2.3.</span> <span class="toc-text">目标的边缘检测</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AD%A6%E4%B9%A0%E5%8D%B7%E7%A7%AF%E6%A0%B8"><span class="toc-number">2.4.</span> <span class="toc-text">学习卷积核</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%89%B9%E5%BE%81%E6%98%A0%E5%B0%84%E5%92%8C%E6%84%9F%E5%8F%97%E9%87%8E"><span class="toc-number">2.5.</span> <span class="toc-text">特征映射和感受野</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%A1%AB%E5%85%85%E5%92%8C%E6%AD%A5%E5%B9%85"><span class="toc-number">3.</span> <span class="toc-text">填充和步幅</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%A1%AB%E5%85%85"><span class="toc-number">3.1.</span> <span class="toc-text">填充</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%AD%A5%E5%B9%85"><span class="toc-number">3.2.</span> <span class="toc-text">步幅</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%A4%9A%E8%BE%93%E5%85%A5%E5%A4%9A%E8%BE%93%E5%87%BA"><span class="toc-number">4.</span> <span class="toc-text">多输入多输出</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%A4%9A%E8%BE%93%E5%85%A5%E9%80%9A%E9%81%93"><span class="toc-number">4.1.</span> <span class="toc-text">多输入通道</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%A4%9A%E8%BE%93%E5%87%BA%E9%80%9A%E9%81%93"><span class="toc-number">4.2.</span> <span class="toc-text">多输出通道</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#1%C3%971%E5%8D%B7%E7%A7%AF%E5%B1%82"><span class="toc-number">4.2.1.</span> <span class="toc-text">1×1卷积层</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%B0%8F%E7%BB%93"><span class="toc-number">4.3.</span> <span class="toc-text">小结</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%80%9D%E8%80%83%E9%A2%98-1"><span class="toc-number">4.4.</span> <span class="toc-text">思考题</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%B1%87%E8%81%9A-%E6%B1%A0%E5%8C%96"><span class="toc-number">5.</span> <span class="toc-text">汇聚/池化</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%B1%87%E8%81%9A%E5%B1%82"><span class="toc-number">5.1.</span> <span class="toc-text">汇聚层</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%A1%AB%E5%85%85%E5%92%8C%E6%AD%A5%E5%B9%85-1"><span class="toc-number">5.2.</span> <span class="toc-text">填充和步幅</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%A4%9A%E4%B8%AA%E9%80%9A%E9%81%93"><span class="toc-number">5.3.</span> <span class="toc-text">多个通道</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%B0%8F%E7%BB%93-1"><span class="toc-number">5.4.</span> <span class="toc-text">小结</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-LeNet"><span class="toc-number">6.</span> <span class="toc-text">卷积神经网络(LeNet)</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84"><span class="toc-number">6.1.</span> <span class="toc-text">网络结构</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83"><span class="toc-number">6.2.</span> <span class="toc-text">模型训练</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%A8%A1%E5%9E%8B%E5%8D%87%E7%BA%A7"><span class="toc-number">6.3.</span> <span class="toc-text">模型升级</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%80%9D%E8%80%83%E9%A2%98-2"><span class="toc-number">6.4.</span> <span class="toc-text">思考题</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%B7%B1%E5%BA%A6%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-AlexNet"><span class="toc-number">7.</span> <span class="toc-text">深度卷积神经网络(AlexNet)</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AD%A6%E4%B9%A0%E8%A1%A8%E5%BE%81"><span class="toc-number">7.1.</span> <span class="toc-text">学习表征</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84-1"><span class="toc-number">7.2.</span> <span class="toc-text">网络结构</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83-1"><span class="toc-number">7.3.</span> <span class="toc-text">模型训练</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%B0%8F%E7%BB%93-2"><span class="toc-number">7.4.</span> <span class="toc-text">小结</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%80%9D%E8%80%83%E9%A2%98-3"><span class="toc-number">7.5.</span> <span class="toc-text">思考题</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BD%BF%E7%94%A8%E5%9D%97%E7%9A%84%E7%BD%91%E7%BB%9C-VGG"><span class="toc-number">8.</span> <span class="toc-text">使用块的网络(VGG)</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#VGG%E5%9D%97"><span class="toc-number">8.1.</span> <span class="toc-text">VGG块</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84-2"><span class="toc-number">8.2.</span> <span class="toc-text">网络结构</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83-2"><span class="toc-number">8.3.</span> <span class="toc-text">模型训练</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%B0%8F%E7%BB%93-3"><span class="toc-number">8.4.</span> <span class="toc-text">小结</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%80%9D%E8%80%83%E9%A2%98-4"><span class="toc-number">8.5.</span> <span class="toc-text">思考题</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%8D%E5%90%8C%E7%9A%84VGG"><span class="toc-number">8.6.</span> <span class="toc-text">不同的VGG</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%BD%91%E7%BB%9C%E4%B8%AD%E7%9A%84%E7%BD%91%E7%BB%9C-NiN"><span class="toc-number">9.</span> <span class="toc-text">网络中的网络(NiN)</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#NiN%E5%9D%97"><span class="toc-number">9.1.</span> <span class="toc-text">NiN块</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84-3"><span class="toc-number">9.2.</span> <span class="toc-text">网络结构</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B"><span class="toc-number">9.3.</span> <span class="toc-text">训练模型</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%B0%8F%E7%BB%93-4"><span class="toc-number">9.4.</span> <span class="toc-text">小结</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%80%9D%E8%80%83%E9%A2%98-5"><span class="toc-number">9.5.</span> <span class="toc-text">思考题</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%90%AB%E5%B9%B6%E8%A1%8C%E8%BF%9E%E7%BB%93%E7%9A%84%E7%BD%91%E7%BB%9C-GoogleNet"><span class="toc-number">10.</span> <span class="toc-text">含并行连结的网络(GoogleNet)</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Inception%E5%9D%97"><span class="toc-number">10.1.</span> <span class="toc-text">Inception块</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84-4"><span class="toc-number">10.2.</span> <span class="toc-text">网络结构</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B-1"><span class="toc-number">10.3.</span> <span class="toc-text">训练模型</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%B0%8F%E7%BB%93-5"><span class="toc-number">10.4.</span> <span class="toc-text">小结</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%80%9D%E8%80%83%E9%A2%98-6"><span class="toc-number">10.5.</span> <span class="toc-text">思考题</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%89%B9%E9%87%8F%E8%A7%84%E8%8C%83%E5%8C%96"><span class="toc-number">11.</span> <span class="toc-text">批量规范化</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AE%9E%E9%99%85%E6%8C%91%E6%88%98"><span class="toc-number">11.1.</span> <span class="toc-text">实际挑战</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%89%B9%E9%87%8F%E8%A7%84%E8%8C%83%E5%8C%96%E5%B1%82"><span class="toc-number">11.2.</span> <span class="toc-text">批量规范化层</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%85%A8%E8%BF%9E%E6%8E%A5%E5%B1%82"><span class="toc-number">11.2.1.</span> <span class="toc-text">全连接层</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%8D%B7%E7%A7%AF%E5%B1%82-1"><span class="toc-number">11.2.2.</span> <span class="toc-text">卷积层</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%A2%84%E6%B5%8B%E8%BF%87%E7%A8%8B"><span class="toc-number">11.2.3.</span> <span class="toc-text">预测过程</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%BA%95%E5%B1%82%E5%AE%9E%E7%8E%B0"><span class="toc-number">11.3.</span> <span class="toc-text">底层实现</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%B8%A6%E5%85%A5LeNet"><span class="toc-number">11.4.</span> <span class="toc-text">带入LeNet</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%AE%80%E6%B4%81%E5%AE%9E%E7%8E%B0"><span class="toc-number">11.5.</span> <span class="toc-text">简洁实现</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BA%89%E8%AE%AE"><span class="toc-number">11.6.</span> <span class="toc-text">争议</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%B0%8F%E7%BB%93-6"><span class="toc-number">11.7.</span> <span class="toc-text">小结</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%80%9D%E8%80%83%E9%A2%98-7"><span class="toc-number">11.8.</span> <span class="toc-text">思考题</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%AE%8B%E5%B7%AE%E7%BD%91%E7%BB%9C-ResNet"><span class="toc-number">12.</span> <span class="toc-text">残差网络(ResNet)</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%87%BD%E6%95%B0%E7%B1%BB"><span class="toc-number">12.1.</span> <span class="toc-text">函数类</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%AE%8B%E5%B7%AE%E5%9D%97"><span class="toc-number">12.2.</span> <span class="toc-text">残差块</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84-5"><span class="toc-number">12.3.</span> <span class="toc-text">网络结构</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B-2"><span class="toc-number">12.4.</span> <span class="toc-text">训练模型</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%B0%8F%E7%BB%93-7"><span class="toc-number">12.5.</span> <span class="toc-text">小结</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%80%9D%E8%80%83%E9%A2%98-8"><span class="toc-number">12.6.</span> <span class="toc-text">思考题</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#ResNet%E5%8F%98%E4%BD%93"><span class="toc-number">12.7.</span> <span class="toc-text">ResNet变体</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%A8%A0%E5%AF%86%E8%BF%9E%E6%8E%A5%E7%BD%91%E7%BB%9C-DenseNet"><span class="toc-number">13.</span> <span class="toc-text">稠密连接网络(DenseNet)</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BB%8EResNet%E5%88%B0DenseNet"><span class="toc-number">13.1.</span> <span class="toc-text">从ResNet到DenseNet</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%A8%A0%E5%AF%86%E5%9D%97%E4%BD%93"><span class="toc-number">13.2.</span> <span class="toc-text">稠密块体</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%BF%87%E6%B8%A1%E5%B1%82"><span class="toc-number">13.3.</span> <span class="toc-text">过渡层</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84-6"><span class="toc-number">13.4.</span> <span class="toc-text">网络结构</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B-3"><span class="toc-number">13.5.</span> <span class="toc-text">训练模型</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%B0%8F%E7%BB%93-8"><span class="toc-number">13.6.</span> <span class="toc-text">小结</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%80%9D%E8%80%83%E9%A2%98-9"><span class="toc-number">13.7.</span> <span class="toc-text">思考题</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%80%BB%E7%BB%93"><span class="toc-number">14.</span> <span class="toc-text">总结</span></a></li></ol></div></div></div></div></main><footer id="footer" style="background: transparent"><div id="footer-wrap"><div class="copyright">©2022 - 2026 By 今天睡够了吗</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div><div class="footer_custom_text">You must always have faith in who you are！</div></div></footer></div><div id="rightside"><div id="rightside-config-hide"></div><div id="rightside-config-show"><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js?v=4.13.0"></script><script src="/js/main.js?v=4.13.0"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui@5.0.33/dist/fancybox/fancybox.umd.min.js"></script><div class="js-pjax"><script>if (!window.MathJax) {
  window.MathJax = {
    tex: {
      inlineMath: [['$', '$'], ['\\(', '\\)']],
      tags: 'ams'
    },
    chtml: {
      scale: 1.1
    },
    options: {
      renderActions: {
        findScript: [10, doc => {
          for (const node of document.querySelectorAll('script[type^="math/tex"]')) {
            const display = !!node.type.match(/; *mode=display/)
            const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display)
            const text = document.createTextNode('')
            node.parentNode.replaceChild(text, node)
            math.start = {node: text, delim: '', n: 0}
            math.end = {node: text, delim: '', n: 0}
            doc.math.push(math)
          }
        }, '']
      }
    }
  }
  
  const script = document.createElement('script')
  script.src = 'https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.min.js'
  script.id = 'MathJax-script'
  script.async = true
  document.head.appendChild(script)
} else {
  MathJax.startup.document.state(0)
  MathJax.texReset()
  MathJax.typesetPromise()
}</script></div><script id="click-heart" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.3/dist/click-heart.min.js" async="async" mobile="false"></script><script async="" data-pjax="" src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="is-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  数据库加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"></div></div><hr><div id="local-search-results"></div><div id="local-search-stats-wrap"></div></div></div><div id="search-mask"></div><script src="/js/search/local-search.js?v=4.13.0"></script></div></div></body></html>